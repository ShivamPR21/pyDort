{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b45628",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3743e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.models as vm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchreid import models\n",
    "from pyDort.representation.image_models import ResnetSimCLRInference, ImageContrastiveRepresentation, ResnetImageRepresentation, ReIdRepresentation\n",
    "from pyDort.representation.point_cloud_models import PointCloudRepresentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1502296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1SigwBE6mPdqiJMqhuIY4aqC7--5CsMal\n",
      "To: /home/shivampr21/Research/MOT-Research/pyDort/pyDort/representation/image_models/chkpts/osnet_ain_x1_0_MSMT.pth\n",
      "100%|██████████| 17.3M/17.3M [00:03<00:00, 5.74MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"/home/shivampr21/.cache/torch/checkpoints/osnet_ain_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "self.model.load_state_dict(ckpt, strict=False) = _IncompatibleKeys(missing_keys=['conv1.conv.weight', 'conv1.bn.weight', 'conv1.bn.bias', 'conv2.0.conv1.conv.weight', 'conv2.0.conv1.bn.weight', 'conv2.0.conv1.bn.bias', 'conv2.0.conv1.bn.running_mean', 'conv2.0.conv1.bn.running_var', 'conv2.0.conv2.0.layers.0.conv1.weight', 'conv2.0.conv2.0.layers.0.conv2.weight', 'conv2.0.conv2.0.layers.0.bn.weight', 'conv2.0.conv2.0.layers.0.bn.bias', 'conv2.0.conv2.0.layers.0.bn.running_mean', 'conv2.0.conv2.0.layers.0.bn.running_var', 'conv2.0.conv2.1.layers.0.conv1.weight', 'conv2.0.conv2.1.layers.0.conv2.weight', 'conv2.0.conv2.1.layers.0.bn.weight', 'conv2.0.conv2.1.layers.0.bn.bias', 'conv2.0.conv2.1.layers.0.bn.running_mean', 'conv2.0.conv2.1.layers.0.bn.running_var', 'conv2.0.conv2.1.layers.1.conv1.weight', 'conv2.0.conv2.1.layers.1.conv2.weight', 'conv2.0.conv2.1.layers.1.bn.weight', 'conv2.0.conv2.1.layers.1.bn.bias', 'conv2.0.conv2.1.layers.1.bn.running_mean', 'conv2.0.conv2.1.layers.1.bn.running_var', 'conv2.0.conv2.2.layers.0.conv1.weight', 'conv2.0.conv2.2.layers.0.conv2.weight', 'conv2.0.conv2.2.layers.0.bn.weight', 'conv2.0.conv2.2.layers.0.bn.bias', 'conv2.0.conv2.2.layers.0.bn.running_mean', 'conv2.0.conv2.2.layers.0.bn.running_var', 'conv2.0.conv2.2.layers.1.conv1.weight', 'conv2.0.conv2.2.layers.1.conv2.weight', 'conv2.0.conv2.2.layers.1.bn.weight', 'conv2.0.conv2.2.layers.1.bn.bias', 'conv2.0.conv2.2.layers.1.bn.running_mean', 'conv2.0.conv2.2.layers.1.bn.running_var', 'conv2.0.conv2.2.layers.2.conv1.weight', 'conv2.0.conv2.2.layers.2.conv2.weight', 'conv2.0.conv2.2.layers.2.bn.weight', 'conv2.0.conv2.2.layers.2.bn.bias', 'conv2.0.conv2.2.layers.2.bn.running_mean', 'conv2.0.conv2.2.layers.2.bn.running_var', 'conv2.0.conv2.3.layers.0.conv1.weight', 'conv2.0.conv2.3.layers.0.conv2.weight', 'conv2.0.conv2.3.layers.0.bn.weight', 'conv2.0.conv2.3.layers.0.bn.bias', 'conv2.0.conv2.3.layers.0.bn.running_mean', 'conv2.0.conv2.3.layers.0.bn.running_var', 'conv2.0.conv2.3.layers.1.conv1.weight', 'conv2.0.conv2.3.layers.1.conv2.weight', 'conv2.0.conv2.3.layers.1.bn.weight', 'conv2.0.conv2.3.layers.1.bn.bias', 'conv2.0.conv2.3.layers.1.bn.running_mean', 'conv2.0.conv2.3.layers.1.bn.running_var', 'conv2.0.conv2.3.layers.2.conv1.weight', 'conv2.0.conv2.3.layers.2.conv2.weight', 'conv2.0.conv2.3.layers.2.bn.weight', 'conv2.0.conv2.3.layers.2.bn.bias', 'conv2.0.conv2.3.layers.2.bn.running_mean', 'conv2.0.conv2.3.layers.2.bn.running_var', 'conv2.0.conv2.3.layers.3.conv1.weight', 'conv2.0.conv2.3.layers.3.conv2.weight', 'conv2.0.conv2.3.layers.3.bn.weight', 'conv2.0.conv2.3.layers.3.bn.bias', 'conv2.0.conv2.3.layers.3.bn.running_mean', 'conv2.0.conv2.3.layers.3.bn.running_var', 'conv2.0.gate.fc1.weight', 'conv2.0.gate.fc1.bias', 'conv2.0.gate.fc2.weight', 'conv2.0.gate.fc2.bias', 'conv2.0.conv3.conv.weight', 'conv2.0.downsample.conv.weight', 'conv2.0.downsample.bn.weight', 'conv2.0.downsample.bn.bias', 'conv2.0.downsample.bn.running_mean', 'conv2.0.downsample.bn.running_var', 'conv2.0.IN.weight', 'conv2.0.IN.bias', 'conv2.1.conv1.conv.weight', 'conv2.1.conv1.bn.weight', 'conv2.1.conv1.bn.bias', 'conv2.1.conv1.bn.running_mean', 'conv2.1.conv1.bn.running_var', 'conv2.1.conv2.0.layers.0.conv1.weight', 'conv2.1.conv2.0.layers.0.conv2.weight', 'conv2.1.conv2.0.layers.0.bn.weight', 'conv2.1.conv2.0.layers.0.bn.bias', 'conv2.1.conv2.0.layers.0.bn.running_mean', 'conv2.1.conv2.0.layers.0.bn.running_var', 'conv2.1.conv2.1.layers.0.conv1.weight', 'conv2.1.conv2.1.layers.0.conv2.weight', 'conv2.1.conv2.1.layers.0.bn.weight', 'conv2.1.conv2.1.layers.0.bn.bias', 'conv2.1.conv2.1.layers.0.bn.running_mean', 'conv2.1.conv2.1.layers.0.bn.running_var', 'conv2.1.conv2.1.layers.1.conv1.weight', 'conv2.1.conv2.1.layers.1.conv2.weight', 'conv2.1.conv2.1.layers.1.bn.weight', 'conv2.1.conv2.1.layers.1.bn.bias', 'conv2.1.conv2.1.layers.1.bn.running_mean', 'conv2.1.conv2.1.layers.1.bn.running_var', 'conv2.1.conv2.2.layers.0.conv1.weight', 'conv2.1.conv2.2.layers.0.conv2.weight', 'conv2.1.conv2.2.layers.0.bn.weight', 'conv2.1.conv2.2.layers.0.bn.bias', 'conv2.1.conv2.2.layers.0.bn.running_mean', 'conv2.1.conv2.2.layers.0.bn.running_var', 'conv2.1.conv2.2.layers.1.conv1.weight', 'conv2.1.conv2.2.layers.1.conv2.weight', 'conv2.1.conv2.2.layers.1.bn.weight', 'conv2.1.conv2.2.layers.1.bn.bias', 'conv2.1.conv2.2.layers.1.bn.running_mean', 'conv2.1.conv2.2.layers.1.bn.running_var', 'conv2.1.conv2.2.layers.2.conv1.weight', 'conv2.1.conv2.2.layers.2.conv2.weight', 'conv2.1.conv2.2.layers.2.bn.weight', 'conv2.1.conv2.2.layers.2.bn.bias', 'conv2.1.conv2.2.layers.2.bn.running_mean', 'conv2.1.conv2.2.layers.2.bn.running_var', 'conv2.1.conv2.3.layers.0.conv1.weight', 'conv2.1.conv2.3.layers.0.conv2.weight', 'conv2.1.conv2.3.layers.0.bn.weight', 'conv2.1.conv2.3.layers.0.bn.bias', 'conv2.1.conv2.3.layers.0.bn.running_mean', 'conv2.1.conv2.3.layers.0.bn.running_var', 'conv2.1.conv2.3.layers.1.conv1.weight', 'conv2.1.conv2.3.layers.1.conv2.weight', 'conv2.1.conv2.3.layers.1.bn.weight', 'conv2.1.conv2.3.layers.1.bn.bias', 'conv2.1.conv2.3.layers.1.bn.running_mean', 'conv2.1.conv2.3.layers.1.bn.running_var', 'conv2.1.conv2.3.layers.2.conv1.weight', 'conv2.1.conv2.3.layers.2.conv2.weight', 'conv2.1.conv2.3.layers.2.bn.weight', 'conv2.1.conv2.3.layers.2.bn.bias', 'conv2.1.conv2.3.layers.2.bn.running_mean', 'conv2.1.conv2.3.layers.2.bn.running_var', 'conv2.1.conv2.3.layers.3.conv1.weight', 'conv2.1.conv2.3.layers.3.conv2.weight', 'conv2.1.conv2.3.layers.3.bn.weight', 'conv2.1.conv2.3.layers.3.bn.bias', 'conv2.1.conv2.3.layers.3.bn.running_mean', 'conv2.1.conv2.3.layers.3.bn.running_var', 'conv2.1.gate.fc1.weight', 'conv2.1.gate.fc1.bias', 'conv2.1.gate.fc2.weight', 'conv2.1.gate.fc2.bias', 'conv2.1.conv3.conv.weight', 'conv2.1.IN.weight', 'conv2.1.IN.bias', 'pool2.0.conv.weight', 'pool2.0.bn.weight', 'pool2.0.bn.bias', 'pool2.0.bn.running_mean', 'pool2.0.bn.running_var', 'conv3.0.conv1.conv.weight', 'conv3.0.conv1.bn.weight', 'conv3.0.conv1.bn.bias', 'conv3.0.conv1.bn.running_mean', 'conv3.0.conv1.bn.running_var', 'conv3.0.conv2.0.layers.0.conv1.weight', 'conv3.0.conv2.0.layers.0.conv2.weight', 'conv3.0.conv2.0.layers.0.bn.weight', 'conv3.0.conv2.0.layers.0.bn.bias', 'conv3.0.conv2.0.layers.0.bn.running_mean', 'conv3.0.conv2.0.layers.0.bn.running_var', 'conv3.0.conv2.1.layers.0.conv1.weight', 'conv3.0.conv2.1.layers.0.conv2.weight', 'conv3.0.conv2.1.layers.0.bn.weight', 'conv3.0.conv2.1.layers.0.bn.bias', 'conv3.0.conv2.1.layers.0.bn.running_mean', 'conv3.0.conv2.1.layers.0.bn.running_var', 'conv3.0.conv2.1.layers.1.conv1.weight', 'conv3.0.conv2.1.layers.1.conv2.weight', 'conv3.0.conv2.1.layers.1.bn.weight', 'conv3.0.conv2.1.layers.1.bn.bias', 'conv3.0.conv2.1.layers.1.bn.running_mean', 'conv3.0.conv2.1.layers.1.bn.running_var', 'conv3.0.conv2.2.layers.0.conv1.weight', 'conv3.0.conv2.2.layers.0.conv2.weight', 'conv3.0.conv2.2.layers.0.bn.weight', 'conv3.0.conv2.2.layers.0.bn.bias', 'conv3.0.conv2.2.layers.0.bn.running_mean', 'conv3.0.conv2.2.layers.0.bn.running_var', 'conv3.0.conv2.2.layers.1.conv1.weight', 'conv3.0.conv2.2.layers.1.conv2.weight', 'conv3.0.conv2.2.layers.1.bn.weight', 'conv3.0.conv2.2.layers.1.bn.bias', 'conv3.0.conv2.2.layers.1.bn.running_mean', 'conv3.0.conv2.2.layers.1.bn.running_var', 'conv3.0.conv2.2.layers.2.conv1.weight', 'conv3.0.conv2.2.layers.2.conv2.weight', 'conv3.0.conv2.2.layers.2.bn.weight', 'conv3.0.conv2.2.layers.2.bn.bias', 'conv3.0.conv2.2.layers.2.bn.running_mean', 'conv3.0.conv2.2.layers.2.bn.running_var', 'conv3.0.conv2.3.layers.0.conv1.weight', 'conv3.0.conv2.3.layers.0.conv2.weight', 'conv3.0.conv2.3.layers.0.bn.weight', 'conv3.0.conv2.3.layers.0.bn.bias', 'conv3.0.conv2.3.layers.0.bn.running_mean', 'conv3.0.conv2.3.layers.0.bn.running_var', 'conv3.0.conv2.3.layers.1.conv1.weight', 'conv3.0.conv2.3.layers.1.conv2.weight', 'conv3.0.conv2.3.layers.1.bn.weight', 'conv3.0.conv2.3.layers.1.bn.bias', 'conv3.0.conv2.3.layers.1.bn.running_mean', 'conv3.0.conv2.3.layers.1.bn.running_var', 'conv3.0.conv2.3.layers.2.conv1.weight', 'conv3.0.conv2.3.layers.2.conv2.weight', 'conv3.0.conv2.3.layers.2.bn.weight', 'conv3.0.conv2.3.layers.2.bn.bias', 'conv3.0.conv2.3.layers.2.bn.running_mean', 'conv3.0.conv2.3.layers.2.bn.running_var', 'conv3.0.conv2.3.layers.3.conv1.weight', 'conv3.0.conv2.3.layers.3.conv2.weight', 'conv3.0.conv2.3.layers.3.bn.weight', 'conv3.0.conv2.3.layers.3.bn.bias', 'conv3.0.conv2.3.layers.3.bn.running_mean', 'conv3.0.conv2.3.layers.3.bn.running_var', 'conv3.0.gate.fc1.weight', 'conv3.0.gate.fc1.bias', 'conv3.0.gate.fc2.weight', 'conv3.0.gate.fc2.bias', 'conv3.0.conv3.conv.weight', 'conv3.0.conv3.bn.weight', 'conv3.0.conv3.bn.bias', 'conv3.0.conv3.bn.running_mean', 'conv3.0.conv3.bn.running_var', 'conv3.0.downsample.conv.weight', 'conv3.0.downsample.bn.weight', 'conv3.0.downsample.bn.bias', 'conv3.0.downsample.bn.running_mean', 'conv3.0.downsample.bn.running_var', 'conv3.1.conv1.conv.weight', 'conv3.1.conv1.bn.weight', 'conv3.1.conv1.bn.bias', 'conv3.1.conv1.bn.running_mean', 'conv3.1.conv1.bn.running_var', 'conv3.1.conv2.0.layers.0.conv1.weight', 'conv3.1.conv2.0.layers.0.conv2.weight', 'conv3.1.conv2.0.layers.0.bn.weight', 'conv3.1.conv2.0.layers.0.bn.bias', 'conv3.1.conv2.0.layers.0.bn.running_mean', 'conv3.1.conv2.0.layers.0.bn.running_var', 'conv3.1.conv2.1.layers.0.conv1.weight', 'conv3.1.conv2.1.layers.0.conv2.weight', 'conv3.1.conv2.1.layers.0.bn.weight', 'conv3.1.conv2.1.layers.0.bn.bias', 'conv3.1.conv2.1.layers.0.bn.running_mean', 'conv3.1.conv2.1.layers.0.bn.running_var', 'conv3.1.conv2.1.layers.1.conv1.weight', 'conv3.1.conv2.1.layers.1.conv2.weight', 'conv3.1.conv2.1.layers.1.bn.weight', 'conv3.1.conv2.1.layers.1.bn.bias', 'conv3.1.conv2.1.layers.1.bn.running_mean', 'conv3.1.conv2.1.layers.1.bn.running_var', 'conv3.1.conv2.2.layers.0.conv1.weight', 'conv3.1.conv2.2.layers.0.conv2.weight', 'conv3.1.conv2.2.layers.0.bn.weight', 'conv3.1.conv2.2.layers.0.bn.bias', 'conv3.1.conv2.2.layers.0.bn.running_mean', 'conv3.1.conv2.2.layers.0.bn.running_var', 'conv3.1.conv2.2.layers.1.conv1.weight', 'conv3.1.conv2.2.layers.1.conv2.weight', 'conv3.1.conv2.2.layers.1.bn.weight', 'conv3.1.conv2.2.layers.1.bn.bias', 'conv3.1.conv2.2.layers.1.bn.running_mean', 'conv3.1.conv2.2.layers.1.bn.running_var', 'conv3.1.conv2.2.layers.2.conv1.weight', 'conv3.1.conv2.2.layers.2.conv2.weight', 'conv3.1.conv2.2.layers.2.bn.weight', 'conv3.1.conv2.2.layers.2.bn.bias', 'conv3.1.conv2.2.layers.2.bn.running_mean', 'conv3.1.conv2.2.layers.2.bn.running_var', 'conv3.1.conv2.3.layers.0.conv1.weight', 'conv3.1.conv2.3.layers.0.conv2.weight', 'conv3.1.conv2.3.layers.0.bn.weight', 'conv3.1.conv2.3.layers.0.bn.bias', 'conv3.1.conv2.3.layers.0.bn.running_mean', 'conv3.1.conv2.3.layers.0.bn.running_var', 'conv3.1.conv2.3.layers.1.conv1.weight', 'conv3.1.conv2.3.layers.1.conv2.weight', 'conv3.1.conv2.3.layers.1.bn.weight', 'conv3.1.conv2.3.layers.1.bn.bias', 'conv3.1.conv2.3.layers.1.bn.running_mean', 'conv3.1.conv2.3.layers.1.bn.running_var', 'conv3.1.conv2.3.layers.2.conv1.weight', 'conv3.1.conv2.3.layers.2.conv2.weight', 'conv3.1.conv2.3.layers.2.bn.weight', 'conv3.1.conv2.3.layers.2.bn.bias', 'conv3.1.conv2.3.layers.2.bn.running_mean', 'conv3.1.conv2.3.layers.2.bn.running_var', 'conv3.1.conv2.3.layers.3.conv1.weight', 'conv3.1.conv2.3.layers.3.conv2.weight', 'conv3.1.conv2.3.layers.3.bn.weight', 'conv3.1.conv2.3.layers.3.bn.bias', 'conv3.1.conv2.3.layers.3.bn.running_mean', 'conv3.1.conv2.3.layers.3.bn.running_var', 'conv3.1.gate.fc1.weight', 'conv3.1.gate.fc1.bias', 'conv3.1.gate.fc2.weight', 'conv3.1.gate.fc2.bias', 'conv3.1.conv3.conv.weight', 'conv3.1.IN.weight', 'conv3.1.IN.bias', 'pool3.0.conv.weight', 'pool3.0.bn.weight', 'pool3.0.bn.bias', 'pool3.0.bn.running_mean', 'pool3.0.bn.running_var', 'conv4.0.conv1.conv.weight', 'conv4.0.conv1.bn.weight', 'conv4.0.conv1.bn.bias', 'conv4.0.conv1.bn.running_mean', 'conv4.0.conv1.bn.running_var', 'conv4.0.conv2.0.layers.0.conv1.weight', 'conv4.0.conv2.0.layers.0.conv2.weight', 'conv4.0.conv2.0.layers.0.bn.weight', 'conv4.0.conv2.0.layers.0.bn.bias', 'conv4.0.conv2.0.layers.0.bn.running_mean', 'conv4.0.conv2.0.layers.0.bn.running_var', 'conv4.0.conv2.1.layers.0.conv1.weight', 'conv4.0.conv2.1.layers.0.conv2.weight', 'conv4.0.conv2.1.layers.0.bn.weight', 'conv4.0.conv2.1.layers.0.bn.bias', 'conv4.0.conv2.1.layers.0.bn.running_mean', 'conv4.0.conv2.1.layers.0.bn.running_var', 'conv4.0.conv2.1.layers.1.conv1.weight', 'conv4.0.conv2.1.layers.1.conv2.weight', 'conv4.0.conv2.1.layers.1.bn.weight', 'conv4.0.conv2.1.layers.1.bn.bias', 'conv4.0.conv2.1.layers.1.bn.running_mean', 'conv4.0.conv2.1.layers.1.bn.running_var', 'conv4.0.conv2.2.layers.0.conv1.weight', 'conv4.0.conv2.2.layers.0.conv2.weight', 'conv4.0.conv2.2.layers.0.bn.weight', 'conv4.0.conv2.2.layers.0.bn.bias', 'conv4.0.conv2.2.layers.0.bn.running_mean', 'conv4.0.conv2.2.layers.0.bn.running_var', 'conv4.0.conv2.2.layers.1.conv1.weight', 'conv4.0.conv2.2.layers.1.conv2.weight', 'conv4.0.conv2.2.layers.1.bn.weight', 'conv4.0.conv2.2.layers.1.bn.bias', 'conv4.0.conv2.2.layers.1.bn.running_mean', 'conv4.0.conv2.2.layers.1.bn.running_var', 'conv4.0.conv2.2.layers.2.conv1.weight', 'conv4.0.conv2.2.layers.2.conv2.weight', 'conv4.0.conv2.2.layers.2.bn.weight', 'conv4.0.conv2.2.layers.2.bn.bias', 'conv4.0.conv2.2.layers.2.bn.running_mean', 'conv4.0.conv2.2.layers.2.bn.running_var', 'conv4.0.conv2.3.layers.0.conv1.weight', 'conv4.0.conv2.3.layers.0.conv2.weight', 'conv4.0.conv2.3.layers.0.bn.weight', 'conv4.0.conv2.3.layers.0.bn.bias', 'conv4.0.conv2.3.layers.0.bn.running_mean', 'conv4.0.conv2.3.layers.0.bn.running_var', 'conv4.0.conv2.3.layers.1.conv1.weight', 'conv4.0.conv2.3.layers.1.conv2.weight', 'conv4.0.conv2.3.layers.1.bn.weight', 'conv4.0.conv2.3.layers.1.bn.bias', 'conv4.0.conv2.3.layers.1.bn.running_mean', 'conv4.0.conv2.3.layers.1.bn.running_var', 'conv4.0.conv2.3.layers.2.conv1.weight', 'conv4.0.conv2.3.layers.2.conv2.weight', 'conv4.0.conv2.3.layers.2.bn.weight', 'conv4.0.conv2.3.layers.2.bn.bias', 'conv4.0.conv2.3.layers.2.bn.running_mean', 'conv4.0.conv2.3.layers.2.bn.running_var', 'conv4.0.conv2.3.layers.3.conv1.weight', 'conv4.0.conv2.3.layers.3.conv2.weight', 'conv4.0.conv2.3.layers.3.bn.weight', 'conv4.0.conv2.3.layers.3.bn.bias', 'conv4.0.conv2.3.layers.3.bn.running_mean', 'conv4.0.conv2.3.layers.3.bn.running_var', 'conv4.0.gate.fc1.weight', 'conv4.0.gate.fc1.bias', 'conv4.0.gate.fc2.weight', 'conv4.0.gate.fc2.bias', 'conv4.0.conv3.conv.weight', 'conv4.0.downsample.conv.weight', 'conv4.0.downsample.bn.weight', 'conv4.0.downsample.bn.bias', 'conv4.0.downsample.bn.running_mean', 'conv4.0.downsample.bn.running_var', 'conv4.0.IN.weight', 'conv4.0.IN.bias', 'conv4.1.conv1.conv.weight', 'conv4.1.conv1.bn.weight', 'conv4.1.conv1.bn.bias', 'conv4.1.conv1.bn.running_mean', 'conv4.1.conv1.bn.running_var', 'conv4.1.conv2.0.layers.0.conv1.weight', 'conv4.1.conv2.0.layers.0.conv2.weight', 'conv4.1.conv2.0.layers.0.bn.weight', 'conv4.1.conv2.0.layers.0.bn.bias', 'conv4.1.conv2.0.layers.0.bn.running_mean', 'conv4.1.conv2.0.layers.0.bn.running_var', 'conv4.1.conv2.1.layers.0.conv1.weight', 'conv4.1.conv2.1.layers.0.conv2.weight', 'conv4.1.conv2.1.layers.0.bn.weight', 'conv4.1.conv2.1.layers.0.bn.bias', 'conv4.1.conv2.1.layers.0.bn.running_mean', 'conv4.1.conv2.1.layers.0.bn.running_var', 'conv4.1.conv2.1.layers.1.conv1.weight', 'conv4.1.conv2.1.layers.1.conv2.weight', 'conv4.1.conv2.1.layers.1.bn.weight', 'conv4.1.conv2.1.layers.1.bn.bias', 'conv4.1.conv2.1.layers.1.bn.running_mean', 'conv4.1.conv2.1.layers.1.bn.running_var', 'conv4.1.conv2.2.layers.0.conv1.weight', 'conv4.1.conv2.2.layers.0.conv2.weight', 'conv4.1.conv2.2.layers.0.bn.weight', 'conv4.1.conv2.2.layers.0.bn.bias', 'conv4.1.conv2.2.layers.0.bn.running_mean', 'conv4.1.conv2.2.layers.0.bn.running_var', 'conv4.1.conv2.2.layers.1.conv1.weight', 'conv4.1.conv2.2.layers.1.conv2.weight', 'conv4.1.conv2.2.layers.1.bn.weight', 'conv4.1.conv2.2.layers.1.bn.bias', 'conv4.1.conv2.2.layers.1.bn.running_mean', 'conv4.1.conv2.2.layers.1.bn.running_var', 'conv4.1.conv2.2.layers.2.conv1.weight', 'conv4.1.conv2.2.layers.2.conv2.weight', 'conv4.1.conv2.2.layers.2.bn.weight', 'conv4.1.conv2.2.layers.2.bn.bias', 'conv4.1.conv2.2.layers.2.bn.running_mean', 'conv4.1.conv2.2.layers.2.bn.running_var', 'conv4.1.conv2.3.layers.0.conv1.weight', 'conv4.1.conv2.3.layers.0.conv2.weight', 'conv4.1.conv2.3.layers.0.bn.weight', 'conv4.1.conv2.3.layers.0.bn.bias', 'conv4.1.conv2.3.layers.0.bn.running_mean', 'conv4.1.conv2.3.layers.0.bn.running_var', 'conv4.1.conv2.3.layers.1.conv1.weight', 'conv4.1.conv2.3.layers.1.conv2.weight', 'conv4.1.conv2.3.layers.1.bn.weight', 'conv4.1.conv2.3.layers.1.bn.bias', 'conv4.1.conv2.3.layers.1.bn.running_mean', 'conv4.1.conv2.3.layers.1.bn.running_var', 'conv4.1.conv2.3.layers.2.conv1.weight', 'conv4.1.conv2.3.layers.2.conv2.weight', 'conv4.1.conv2.3.layers.2.bn.weight', 'conv4.1.conv2.3.layers.2.bn.bias', 'conv4.1.conv2.3.layers.2.bn.running_mean', 'conv4.1.conv2.3.layers.2.bn.running_var', 'conv4.1.conv2.3.layers.3.conv1.weight', 'conv4.1.conv2.3.layers.3.conv2.weight', 'conv4.1.conv2.3.layers.3.bn.weight', 'conv4.1.conv2.3.layers.3.bn.bias', 'conv4.1.conv2.3.layers.3.bn.running_mean', 'conv4.1.conv2.3.layers.3.bn.running_var', 'conv4.1.gate.fc1.weight', 'conv4.1.gate.fc1.bias', 'conv4.1.gate.fc2.weight', 'conv4.1.gate.fc2.bias', 'conv4.1.conv3.conv.weight', 'conv4.1.conv3.bn.weight', 'conv4.1.conv3.bn.bias', 'conv4.1.conv3.bn.running_mean', 'conv4.1.conv3.bn.running_var', 'conv5.conv.weight', 'conv5.bn.weight', 'conv5.bn.bias', 'conv5.bn.running_mean', 'conv5.bn.running_var', 'fc.0.weight', 'fc.0.bias', 'fc.1.weight', 'fc.1.bias', 'fc.1.running_mean', 'fc.1.running_var'], unexpected_keys=['module.conv1.conv.weight', 'module.conv1.bn.weight', 'module.conv1.bn.bias', 'module.conv2.0.conv1.conv.weight', 'module.conv2.0.conv1.bn.weight', 'module.conv2.0.conv1.bn.bias', 'module.conv2.0.conv1.bn.running_mean', 'module.conv2.0.conv1.bn.running_var', 'module.conv2.0.conv1.bn.num_batches_tracked', 'module.conv2.0.conv2.0.layers.0.conv1.weight', 'module.conv2.0.conv2.0.layers.0.conv2.weight', 'module.conv2.0.conv2.0.layers.0.bn.weight', 'module.conv2.0.conv2.0.layers.0.bn.bias', 'module.conv2.0.conv2.0.layers.0.bn.running_mean', 'module.conv2.0.conv2.0.layers.0.bn.running_var', 'module.conv2.0.conv2.0.layers.0.bn.num_batches_tracked', 'module.conv2.0.conv2.1.layers.0.conv1.weight', 'module.conv2.0.conv2.1.layers.0.conv2.weight', 'module.conv2.0.conv2.1.layers.0.bn.weight', 'module.conv2.0.conv2.1.layers.0.bn.bias', 'module.conv2.0.conv2.1.layers.0.bn.running_mean', 'module.conv2.0.conv2.1.layers.0.bn.running_var', 'module.conv2.0.conv2.1.layers.0.bn.num_batches_tracked', 'module.conv2.0.conv2.1.layers.1.conv1.weight', 'module.conv2.0.conv2.1.layers.1.conv2.weight', 'module.conv2.0.conv2.1.layers.1.bn.weight', 'module.conv2.0.conv2.1.layers.1.bn.bias', 'module.conv2.0.conv2.1.layers.1.bn.running_mean', 'module.conv2.0.conv2.1.layers.1.bn.running_var', 'module.conv2.0.conv2.1.layers.1.bn.num_batches_tracked', 'module.conv2.0.conv2.2.layers.0.conv1.weight', 'module.conv2.0.conv2.2.layers.0.conv2.weight', 'module.conv2.0.conv2.2.layers.0.bn.weight', 'module.conv2.0.conv2.2.layers.0.bn.bias', 'module.conv2.0.conv2.2.layers.0.bn.running_mean', 'module.conv2.0.conv2.2.layers.0.bn.running_var', 'module.conv2.0.conv2.2.layers.0.bn.num_batches_tracked', 'module.conv2.0.conv2.2.layers.1.conv1.weight', 'module.conv2.0.conv2.2.layers.1.conv2.weight', 'module.conv2.0.conv2.2.layers.1.bn.weight', 'module.conv2.0.conv2.2.layers.1.bn.bias', 'module.conv2.0.conv2.2.layers.1.bn.running_mean', 'module.conv2.0.conv2.2.layers.1.bn.running_var', 'module.conv2.0.conv2.2.layers.1.bn.num_batches_tracked', 'module.conv2.0.conv2.2.layers.2.conv1.weight', 'module.conv2.0.conv2.2.layers.2.conv2.weight', 'module.conv2.0.conv2.2.layers.2.bn.weight', 'module.conv2.0.conv2.2.layers.2.bn.bias', 'module.conv2.0.conv2.2.layers.2.bn.running_mean', 'module.conv2.0.conv2.2.layers.2.bn.running_var', 'module.conv2.0.conv2.2.layers.2.bn.num_batches_tracked', 'module.conv2.0.conv2.3.layers.0.conv1.weight', 'module.conv2.0.conv2.3.layers.0.conv2.weight', 'module.conv2.0.conv2.3.layers.0.bn.weight', 'module.conv2.0.conv2.3.layers.0.bn.bias', 'module.conv2.0.conv2.3.layers.0.bn.running_mean', 'module.conv2.0.conv2.3.layers.0.bn.running_var', 'module.conv2.0.conv2.3.layers.0.bn.num_batches_tracked', 'module.conv2.0.conv2.3.layers.1.conv1.weight', 'module.conv2.0.conv2.3.layers.1.conv2.weight', 'module.conv2.0.conv2.3.layers.1.bn.weight', 'module.conv2.0.conv2.3.layers.1.bn.bias', 'module.conv2.0.conv2.3.layers.1.bn.running_mean', 'module.conv2.0.conv2.3.layers.1.bn.running_var', 'module.conv2.0.conv2.3.layers.1.bn.num_batches_tracked', 'module.conv2.0.conv2.3.layers.2.conv1.weight', 'module.conv2.0.conv2.3.layers.2.conv2.weight', 'module.conv2.0.conv2.3.layers.2.bn.weight', 'module.conv2.0.conv2.3.layers.2.bn.bias', 'module.conv2.0.conv2.3.layers.2.bn.running_mean', 'module.conv2.0.conv2.3.layers.2.bn.running_var', 'module.conv2.0.conv2.3.layers.2.bn.num_batches_tracked', 'module.conv2.0.conv2.3.layers.3.conv1.weight', 'module.conv2.0.conv2.3.layers.3.conv2.weight', 'module.conv2.0.conv2.3.layers.3.bn.weight', 'module.conv2.0.conv2.3.layers.3.bn.bias', 'module.conv2.0.conv2.3.layers.3.bn.running_mean', 'module.conv2.0.conv2.3.layers.3.bn.running_var', 'module.conv2.0.conv2.3.layers.3.bn.num_batches_tracked', 'module.conv2.0.gate.fc1.weight', 'module.conv2.0.gate.fc1.bias', 'module.conv2.0.gate.fc2.weight', 'module.conv2.0.gate.fc2.bias', 'module.conv2.0.conv3.conv.weight', 'module.conv2.0.downsample.conv.weight', 'module.conv2.0.downsample.bn.weight', 'module.conv2.0.downsample.bn.bias', 'module.conv2.0.downsample.bn.running_mean', 'module.conv2.0.downsample.bn.running_var', 'module.conv2.0.downsample.bn.num_batches_tracked', 'module.conv2.0.IN.weight', 'module.conv2.0.IN.bias', 'module.conv2.1.conv1.conv.weight', 'module.conv2.1.conv1.bn.weight', 'module.conv2.1.conv1.bn.bias', 'module.conv2.1.conv1.bn.running_mean', 'module.conv2.1.conv1.bn.running_var', 'module.conv2.1.conv1.bn.num_batches_tracked', 'module.conv2.1.conv2.0.layers.0.conv1.weight', 'module.conv2.1.conv2.0.layers.0.conv2.weight', 'module.conv2.1.conv2.0.layers.0.bn.weight', 'module.conv2.1.conv2.0.layers.0.bn.bias', 'module.conv2.1.conv2.0.layers.0.bn.running_mean', 'module.conv2.1.conv2.0.layers.0.bn.running_var', 'module.conv2.1.conv2.0.layers.0.bn.num_batches_tracked', 'module.conv2.1.conv2.1.layers.0.conv1.weight', 'module.conv2.1.conv2.1.layers.0.conv2.weight', 'module.conv2.1.conv2.1.layers.0.bn.weight', 'module.conv2.1.conv2.1.layers.0.bn.bias', 'module.conv2.1.conv2.1.layers.0.bn.running_mean', 'module.conv2.1.conv2.1.layers.0.bn.running_var', 'module.conv2.1.conv2.1.layers.0.bn.num_batches_tracked', 'module.conv2.1.conv2.1.layers.1.conv1.weight', 'module.conv2.1.conv2.1.layers.1.conv2.weight', 'module.conv2.1.conv2.1.layers.1.bn.weight', 'module.conv2.1.conv2.1.layers.1.bn.bias', 'module.conv2.1.conv2.1.layers.1.bn.running_mean', 'module.conv2.1.conv2.1.layers.1.bn.running_var', 'module.conv2.1.conv2.1.layers.1.bn.num_batches_tracked', 'module.conv2.1.conv2.2.layers.0.conv1.weight', 'module.conv2.1.conv2.2.layers.0.conv2.weight', 'module.conv2.1.conv2.2.layers.0.bn.weight', 'module.conv2.1.conv2.2.layers.0.bn.bias', 'module.conv2.1.conv2.2.layers.0.bn.running_mean', 'module.conv2.1.conv2.2.layers.0.bn.running_var', 'module.conv2.1.conv2.2.layers.0.bn.num_batches_tracked', 'module.conv2.1.conv2.2.layers.1.conv1.weight', 'module.conv2.1.conv2.2.layers.1.conv2.weight', 'module.conv2.1.conv2.2.layers.1.bn.weight', 'module.conv2.1.conv2.2.layers.1.bn.bias', 'module.conv2.1.conv2.2.layers.1.bn.running_mean', 'module.conv2.1.conv2.2.layers.1.bn.running_var', 'module.conv2.1.conv2.2.layers.1.bn.num_batches_tracked', 'module.conv2.1.conv2.2.layers.2.conv1.weight', 'module.conv2.1.conv2.2.layers.2.conv2.weight', 'module.conv2.1.conv2.2.layers.2.bn.weight', 'module.conv2.1.conv2.2.layers.2.bn.bias', 'module.conv2.1.conv2.2.layers.2.bn.running_mean', 'module.conv2.1.conv2.2.layers.2.bn.running_var', 'module.conv2.1.conv2.2.layers.2.bn.num_batches_tracked', 'module.conv2.1.conv2.3.layers.0.conv1.weight', 'module.conv2.1.conv2.3.layers.0.conv2.weight', 'module.conv2.1.conv2.3.layers.0.bn.weight', 'module.conv2.1.conv2.3.layers.0.bn.bias', 'module.conv2.1.conv2.3.layers.0.bn.running_mean', 'module.conv2.1.conv2.3.layers.0.bn.running_var', 'module.conv2.1.conv2.3.layers.0.bn.num_batches_tracked', 'module.conv2.1.conv2.3.layers.1.conv1.weight', 'module.conv2.1.conv2.3.layers.1.conv2.weight', 'module.conv2.1.conv2.3.layers.1.bn.weight', 'module.conv2.1.conv2.3.layers.1.bn.bias', 'module.conv2.1.conv2.3.layers.1.bn.running_mean', 'module.conv2.1.conv2.3.layers.1.bn.running_var', 'module.conv2.1.conv2.3.layers.1.bn.num_batches_tracked', 'module.conv2.1.conv2.3.layers.2.conv1.weight', 'module.conv2.1.conv2.3.layers.2.conv2.weight', 'module.conv2.1.conv2.3.layers.2.bn.weight', 'module.conv2.1.conv2.3.layers.2.bn.bias', 'module.conv2.1.conv2.3.layers.2.bn.running_mean', 'module.conv2.1.conv2.3.layers.2.bn.running_var', 'module.conv2.1.conv2.3.layers.2.bn.num_batches_tracked', 'module.conv2.1.conv2.3.layers.3.conv1.weight', 'module.conv2.1.conv2.3.layers.3.conv2.weight', 'module.conv2.1.conv2.3.layers.3.bn.weight', 'module.conv2.1.conv2.3.layers.3.bn.bias', 'module.conv2.1.conv2.3.layers.3.bn.running_mean', 'module.conv2.1.conv2.3.layers.3.bn.running_var', 'module.conv2.1.conv2.3.layers.3.bn.num_batches_tracked', 'module.conv2.1.gate.fc1.weight', 'module.conv2.1.gate.fc1.bias', 'module.conv2.1.gate.fc2.weight', 'module.conv2.1.gate.fc2.bias', 'module.conv2.1.conv3.conv.weight', 'module.conv2.1.IN.weight', 'module.conv2.1.IN.bias', 'module.pool2.0.conv.weight', 'module.pool2.0.bn.weight', 'module.pool2.0.bn.bias', 'module.pool2.0.bn.running_mean', 'module.pool2.0.bn.running_var', 'module.pool2.0.bn.num_batches_tracked', 'module.conv3.0.conv1.conv.weight', 'module.conv3.0.conv1.bn.weight', 'module.conv3.0.conv1.bn.bias', 'module.conv3.0.conv1.bn.running_mean', 'module.conv3.0.conv1.bn.running_var', 'module.conv3.0.conv1.bn.num_batches_tracked', 'module.conv3.0.conv2.0.layers.0.conv1.weight', 'module.conv3.0.conv2.0.layers.0.conv2.weight', 'module.conv3.0.conv2.0.layers.0.bn.weight', 'module.conv3.0.conv2.0.layers.0.bn.bias', 'module.conv3.0.conv2.0.layers.0.bn.running_mean', 'module.conv3.0.conv2.0.layers.0.bn.running_var', 'module.conv3.0.conv2.0.layers.0.bn.num_batches_tracked', 'module.conv3.0.conv2.1.layers.0.conv1.weight', 'module.conv3.0.conv2.1.layers.0.conv2.weight', 'module.conv3.0.conv2.1.layers.0.bn.weight', 'module.conv3.0.conv2.1.layers.0.bn.bias', 'module.conv3.0.conv2.1.layers.0.bn.running_mean', 'module.conv3.0.conv2.1.layers.0.bn.running_var', 'module.conv3.0.conv2.1.layers.0.bn.num_batches_tracked', 'module.conv3.0.conv2.1.layers.1.conv1.weight', 'module.conv3.0.conv2.1.layers.1.conv2.weight', 'module.conv3.0.conv2.1.layers.1.bn.weight', 'module.conv3.0.conv2.1.layers.1.bn.bias', 'module.conv3.0.conv2.1.layers.1.bn.running_mean', 'module.conv3.0.conv2.1.layers.1.bn.running_var', 'module.conv3.0.conv2.1.layers.1.bn.num_batches_tracked', 'module.conv3.0.conv2.2.layers.0.conv1.weight', 'module.conv3.0.conv2.2.layers.0.conv2.weight', 'module.conv3.0.conv2.2.layers.0.bn.weight', 'module.conv3.0.conv2.2.layers.0.bn.bias', 'module.conv3.0.conv2.2.layers.0.bn.running_mean', 'module.conv3.0.conv2.2.layers.0.bn.running_var', 'module.conv3.0.conv2.2.layers.0.bn.num_batches_tracked', 'module.conv3.0.conv2.2.layers.1.conv1.weight', 'module.conv3.0.conv2.2.layers.1.conv2.weight', 'module.conv3.0.conv2.2.layers.1.bn.weight', 'module.conv3.0.conv2.2.layers.1.bn.bias', 'module.conv3.0.conv2.2.layers.1.bn.running_mean', 'module.conv3.0.conv2.2.layers.1.bn.running_var', 'module.conv3.0.conv2.2.layers.1.bn.num_batches_tracked', 'module.conv3.0.conv2.2.layers.2.conv1.weight', 'module.conv3.0.conv2.2.layers.2.conv2.weight', 'module.conv3.0.conv2.2.layers.2.bn.weight', 'module.conv3.0.conv2.2.layers.2.bn.bias', 'module.conv3.0.conv2.2.layers.2.bn.running_mean', 'module.conv3.0.conv2.2.layers.2.bn.running_var', 'module.conv3.0.conv2.2.layers.2.bn.num_batches_tracked', 'module.conv3.0.conv2.3.layers.0.conv1.weight', 'module.conv3.0.conv2.3.layers.0.conv2.weight', 'module.conv3.0.conv2.3.layers.0.bn.weight', 'module.conv3.0.conv2.3.layers.0.bn.bias', 'module.conv3.0.conv2.3.layers.0.bn.running_mean', 'module.conv3.0.conv2.3.layers.0.bn.running_var', 'module.conv3.0.conv2.3.layers.0.bn.num_batches_tracked', 'module.conv3.0.conv2.3.layers.1.conv1.weight', 'module.conv3.0.conv2.3.layers.1.conv2.weight', 'module.conv3.0.conv2.3.layers.1.bn.weight', 'module.conv3.0.conv2.3.layers.1.bn.bias', 'module.conv3.0.conv2.3.layers.1.bn.running_mean', 'module.conv3.0.conv2.3.layers.1.bn.running_var', 'module.conv3.0.conv2.3.layers.1.bn.num_batches_tracked', 'module.conv3.0.conv2.3.layers.2.conv1.weight', 'module.conv3.0.conv2.3.layers.2.conv2.weight', 'module.conv3.0.conv2.3.layers.2.bn.weight', 'module.conv3.0.conv2.3.layers.2.bn.bias', 'module.conv3.0.conv2.3.layers.2.bn.running_mean', 'module.conv3.0.conv2.3.layers.2.bn.running_var', 'module.conv3.0.conv2.3.layers.2.bn.num_batches_tracked', 'module.conv3.0.conv2.3.layers.3.conv1.weight', 'module.conv3.0.conv2.3.layers.3.conv2.weight', 'module.conv3.0.conv2.3.layers.3.bn.weight', 'module.conv3.0.conv2.3.layers.3.bn.bias', 'module.conv3.0.conv2.3.layers.3.bn.running_mean', 'module.conv3.0.conv2.3.layers.3.bn.running_var', 'module.conv3.0.conv2.3.layers.3.bn.num_batches_tracked', 'module.conv3.0.gate.fc1.weight', 'module.conv3.0.gate.fc1.bias', 'module.conv3.0.gate.fc2.weight', 'module.conv3.0.gate.fc2.bias', 'module.conv3.0.conv3.conv.weight', 'module.conv3.0.conv3.bn.weight', 'module.conv3.0.conv3.bn.bias', 'module.conv3.0.conv3.bn.running_mean', 'module.conv3.0.conv3.bn.running_var', 'module.conv3.0.conv3.bn.num_batches_tracked', 'module.conv3.0.downsample.conv.weight', 'module.conv3.0.downsample.bn.weight', 'module.conv3.0.downsample.bn.bias', 'module.conv3.0.downsample.bn.running_mean', 'module.conv3.0.downsample.bn.running_var', 'module.conv3.0.downsample.bn.num_batches_tracked', 'module.conv3.1.conv1.conv.weight', 'module.conv3.1.conv1.bn.weight', 'module.conv3.1.conv1.bn.bias', 'module.conv3.1.conv1.bn.running_mean', 'module.conv3.1.conv1.bn.running_var', 'module.conv3.1.conv1.bn.num_batches_tracked', 'module.conv3.1.conv2.0.layers.0.conv1.weight', 'module.conv3.1.conv2.0.layers.0.conv2.weight', 'module.conv3.1.conv2.0.layers.0.bn.weight', 'module.conv3.1.conv2.0.layers.0.bn.bias', 'module.conv3.1.conv2.0.layers.0.bn.running_mean', 'module.conv3.1.conv2.0.layers.0.bn.running_var', 'module.conv3.1.conv2.0.layers.0.bn.num_batches_tracked', 'module.conv3.1.conv2.1.layers.0.conv1.weight', 'module.conv3.1.conv2.1.layers.0.conv2.weight', 'module.conv3.1.conv2.1.layers.0.bn.weight', 'module.conv3.1.conv2.1.layers.0.bn.bias', 'module.conv3.1.conv2.1.layers.0.bn.running_mean', 'module.conv3.1.conv2.1.layers.0.bn.running_var', 'module.conv3.1.conv2.1.layers.0.bn.num_batches_tracked', 'module.conv3.1.conv2.1.layers.1.conv1.weight', 'module.conv3.1.conv2.1.layers.1.conv2.weight', 'module.conv3.1.conv2.1.layers.1.bn.weight', 'module.conv3.1.conv2.1.layers.1.bn.bias', 'module.conv3.1.conv2.1.layers.1.bn.running_mean', 'module.conv3.1.conv2.1.layers.1.bn.running_var', 'module.conv3.1.conv2.1.layers.1.bn.num_batches_tracked', 'module.conv3.1.conv2.2.layers.0.conv1.weight', 'module.conv3.1.conv2.2.layers.0.conv2.weight', 'module.conv3.1.conv2.2.layers.0.bn.weight', 'module.conv3.1.conv2.2.layers.0.bn.bias', 'module.conv3.1.conv2.2.layers.0.bn.running_mean', 'module.conv3.1.conv2.2.layers.0.bn.running_var', 'module.conv3.1.conv2.2.layers.0.bn.num_batches_tracked', 'module.conv3.1.conv2.2.layers.1.conv1.weight', 'module.conv3.1.conv2.2.layers.1.conv2.weight', 'module.conv3.1.conv2.2.layers.1.bn.weight', 'module.conv3.1.conv2.2.layers.1.bn.bias', 'module.conv3.1.conv2.2.layers.1.bn.running_mean', 'module.conv3.1.conv2.2.layers.1.bn.running_var', 'module.conv3.1.conv2.2.layers.1.bn.num_batches_tracked', 'module.conv3.1.conv2.2.layers.2.conv1.weight', 'module.conv3.1.conv2.2.layers.2.conv2.weight', 'module.conv3.1.conv2.2.layers.2.bn.weight', 'module.conv3.1.conv2.2.layers.2.bn.bias', 'module.conv3.1.conv2.2.layers.2.bn.running_mean', 'module.conv3.1.conv2.2.layers.2.bn.running_var', 'module.conv3.1.conv2.2.layers.2.bn.num_batches_tracked', 'module.conv3.1.conv2.3.layers.0.conv1.weight', 'module.conv3.1.conv2.3.layers.0.conv2.weight', 'module.conv3.1.conv2.3.layers.0.bn.weight', 'module.conv3.1.conv2.3.layers.0.bn.bias', 'module.conv3.1.conv2.3.layers.0.bn.running_mean', 'module.conv3.1.conv2.3.layers.0.bn.running_var', 'module.conv3.1.conv2.3.layers.0.bn.num_batches_tracked', 'module.conv3.1.conv2.3.layers.1.conv1.weight', 'module.conv3.1.conv2.3.layers.1.conv2.weight', 'module.conv3.1.conv2.3.layers.1.bn.weight', 'module.conv3.1.conv2.3.layers.1.bn.bias', 'module.conv3.1.conv2.3.layers.1.bn.running_mean', 'module.conv3.1.conv2.3.layers.1.bn.running_var', 'module.conv3.1.conv2.3.layers.1.bn.num_batches_tracked', 'module.conv3.1.conv2.3.layers.2.conv1.weight', 'module.conv3.1.conv2.3.layers.2.conv2.weight', 'module.conv3.1.conv2.3.layers.2.bn.weight', 'module.conv3.1.conv2.3.layers.2.bn.bias', 'module.conv3.1.conv2.3.layers.2.bn.running_mean', 'module.conv3.1.conv2.3.layers.2.bn.running_var', 'module.conv3.1.conv2.3.layers.2.bn.num_batches_tracked', 'module.conv3.1.conv2.3.layers.3.conv1.weight', 'module.conv3.1.conv2.3.layers.3.conv2.weight', 'module.conv3.1.conv2.3.layers.3.bn.weight', 'module.conv3.1.conv2.3.layers.3.bn.bias', 'module.conv3.1.conv2.3.layers.3.bn.running_mean', 'module.conv3.1.conv2.3.layers.3.bn.running_var', 'module.conv3.1.conv2.3.layers.3.bn.num_batches_tracked', 'module.conv3.1.gate.fc1.weight', 'module.conv3.1.gate.fc1.bias', 'module.conv3.1.gate.fc2.weight', 'module.conv3.1.gate.fc2.bias', 'module.conv3.1.conv3.conv.weight', 'module.conv3.1.IN.weight', 'module.conv3.1.IN.bias', 'module.pool3.0.conv.weight', 'module.pool3.0.bn.weight', 'module.pool3.0.bn.bias', 'module.pool3.0.bn.running_mean', 'module.pool3.0.bn.running_var', 'module.pool3.0.bn.num_batches_tracked', 'module.conv4.0.conv1.conv.weight', 'module.conv4.0.conv1.bn.weight', 'module.conv4.0.conv1.bn.bias', 'module.conv4.0.conv1.bn.running_mean', 'module.conv4.0.conv1.bn.running_var', 'module.conv4.0.conv1.bn.num_batches_tracked', 'module.conv4.0.conv2.0.layers.0.conv1.weight', 'module.conv4.0.conv2.0.layers.0.conv2.weight', 'module.conv4.0.conv2.0.layers.0.bn.weight', 'module.conv4.0.conv2.0.layers.0.bn.bias', 'module.conv4.0.conv2.0.layers.0.bn.running_mean', 'module.conv4.0.conv2.0.layers.0.bn.running_var', 'module.conv4.0.conv2.0.layers.0.bn.num_batches_tracked', 'module.conv4.0.conv2.1.layers.0.conv1.weight', 'module.conv4.0.conv2.1.layers.0.conv2.weight', 'module.conv4.0.conv2.1.layers.0.bn.weight', 'module.conv4.0.conv2.1.layers.0.bn.bias', 'module.conv4.0.conv2.1.layers.0.bn.running_mean', 'module.conv4.0.conv2.1.layers.0.bn.running_var', 'module.conv4.0.conv2.1.layers.0.bn.num_batches_tracked', 'module.conv4.0.conv2.1.layers.1.conv1.weight', 'module.conv4.0.conv2.1.layers.1.conv2.weight', 'module.conv4.0.conv2.1.layers.1.bn.weight', 'module.conv4.0.conv2.1.layers.1.bn.bias', 'module.conv4.0.conv2.1.layers.1.bn.running_mean', 'module.conv4.0.conv2.1.layers.1.bn.running_var', 'module.conv4.0.conv2.1.layers.1.bn.num_batches_tracked', 'module.conv4.0.conv2.2.layers.0.conv1.weight', 'module.conv4.0.conv2.2.layers.0.conv2.weight', 'module.conv4.0.conv2.2.layers.0.bn.weight', 'module.conv4.0.conv2.2.layers.0.bn.bias', 'module.conv4.0.conv2.2.layers.0.bn.running_mean', 'module.conv4.0.conv2.2.layers.0.bn.running_var', 'module.conv4.0.conv2.2.layers.0.bn.num_batches_tracked', 'module.conv4.0.conv2.2.layers.1.conv1.weight', 'module.conv4.0.conv2.2.layers.1.conv2.weight', 'module.conv4.0.conv2.2.layers.1.bn.weight', 'module.conv4.0.conv2.2.layers.1.bn.bias', 'module.conv4.0.conv2.2.layers.1.bn.running_mean', 'module.conv4.0.conv2.2.layers.1.bn.running_var', 'module.conv4.0.conv2.2.layers.1.bn.num_batches_tracked', 'module.conv4.0.conv2.2.layers.2.conv1.weight', 'module.conv4.0.conv2.2.layers.2.conv2.weight', 'module.conv4.0.conv2.2.layers.2.bn.weight', 'module.conv4.0.conv2.2.layers.2.bn.bias', 'module.conv4.0.conv2.2.layers.2.bn.running_mean', 'module.conv4.0.conv2.2.layers.2.bn.running_var', 'module.conv4.0.conv2.2.layers.2.bn.num_batches_tracked', 'module.conv4.0.conv2.3.layers.0.conv1.weight', 'module.conv4.0.conv2.3.layers.0.conv2.weight', 'module.conv4.0.conv2.3.layers.0.bn.weight', 'module.conv4.0.conv2.3.layers.0.bn.bias', 'module.conv4.0.conv2.3.layers.0.bn.running_mean', 'module.conv4.0.conv2.3.layers.0.bn.running_var', 'module.conv4.0.conv2.3.layers.0.bn.num_batches_tracked', 'module.conv4.0.conv2.3.layers.1.conv1.weight', 'module.conv4.0.conv2.3.layers.1.conv2.weight', 'module.conv4.0.conv2.3.layers.1.bn.weight', 'module.conv4.0.conv2.3.layers.1.bn.bias', 'module.conv4.0.conv2.3.layers.1.bn.running_mean', 'module.conv4.0.conv2.3.layers.1.bn.running_var', 'module.conv4.0.conv2.3.layers.1.bn.num_batches_tracked', 'module.conv4.0.conv2.3.layers.2.conv1.weight', 'module.conv4.0.conv2.3.layers.2.conv2.weight', 'module.conv4.0.conv2.3.layers.2.bn.weight', 'module.conv4.0.conv2.3.layers.2.bn.bias', 'module.conv4.0.conv2.3.layers.2.bn.running_mean', 'module.conv4.0.conv2.3.layers.2.bn.running_var', 'module.conv4.0.conv2.3.layers.2.bn.num_batches_tracked', 'module.conv4.0.conv2.3.layers.3.conv1.weight', 'module.conv4.0.conv2.3.layers.3.conv2.weight', 'module.conv4.0.conv2.3.layers.3.bn.weight', 'module.conv4.0.conv2.3.layers.3.bn.bias', 'module.conv4.0.conv2.3.layers.3.bn.running_mean', 'module.conv4.0.conv2.3.layers.3.bn.running_var', 'module.conv4.0.conv2.3.layers.3.bn.num_batches_tracked', 'module.conv4.0.gate.fc1.weight', 'module.conv4.0.gate.fc1.bias', 'module.conv4.0.gate.fc2.weight', 'module.conv4.0.gate.fc2.bias', 'module.conv4.0.conv3.conv.weight', 'module.conv4.0.downsample.conv.weight', 'module.conv4.0.downsample.bn.weight', 'module.conv4.0.downsample.bn.bias', 'module.conv4.0.downsample.bn.running_mean', 'module.conv4.0.downsample.bn.running_var', 'module.conv4.0.downsample.bn.num_batches_tracked', 'module.conv4.0.IN.weight', 'module.conv4.0.IN.bias', 'module.conv4.1.conv1.conv.weight', 'module.conv4.1.conv1.bn.weight', 'module.conv4.1.conv1.bn.bias', 'module.conv4.1.conv1.bn.running_mean', 'module.conv4.1.conv1.bn.running_var', 'module.conv4.1.conv1.bn.num_batches_tracked', 'module.conv4.1.conv2.0.layers.0.conv1.weight', 'module.conv4.1.conv2.0.layers.0.conv2.weight', 'module.conv4.1.conv2.0.layers.0.bn.weight', 'module.conv4.1.conv2.0.layers.0.bn.bias', 'module.conv4.1.conv2.0.layers.0.bn.running_mean', 'module.conv4.1.conv2.0.layers.0.bn.running_var', 'module.conv4.1.conv2.0.layers.0.bn.num_batches_tracked', 'module.conv4.1.conv2.1.layers.0.conv1.weight', 'module.conv4.1.conv2.1.layers.0.conv2.weight', 'module.conv4.1.conv2.1.layers.0.bn.weight', 'module.conv4.1.conv2.1.layers.0.bn.bias', 'module.conv4.1.conv2.1.layers.0.bn.running_mean', 'module.conv4.1.conv2.1.layers.0.bn.running_var', 'module.conv4.1.conv2.1.layers.0.bn.num_batches_tracked', 'module.conv4.1.conv2.1.layers.1.conv1.weight', 'module.conv4.1.conv2.1.layers.1.conv2.weight', 'module.conv4.1.conv2.1.layers.1.bn.weight', 'module.conv4.1.conv2.1.layers.1.bn.bias', 'module.conv4.1.conv2.1.layers.1.bn.running_mean', 'module.conv4.1.conv2.1.layers.1.bn.running_var', 'module.conv4.1.conv2.1.layers.1.bn.num_batches_tracked', 'module.conv4.1.conv2.2.layers.0.conv1.weight', 'module.conv4.1.conv2.2.layers.0.conv2.weight', 'module.conv4.1.conv2.2.layers.0.bn.weight', 'module.conv4.1.conv2.2.layers.0.bn.bias', 'module.conv4.1.conv2.2.layers.0.bn.running_mean', 'module.conv4.1.conv2.2.layers.0.bn.running_var', 'module.conv4.1.conv2.2.layers.0.bn.num_batches_tracked', 'module.conv4.1.conv2.2.layers.1.conv1.weight', 'module.conv4.1.conv2.2.layers.1.conv2.weight', 'module.conv4.1.conv2.2.layers.1.bn.weight', 'module.conv4.1.conv2.2.layers.1.bn.bias', 'module.conv4.1.conv2.2.layers.1.bn.running_mean', 'module.conv4.1.conv2.2.layers.1.bn.running_var', 'module.conv4.1.conv2.2.layers.1.bn.num_batches_tracked', 'module.conv4.1.conv2.2.layers.2.conv1.weight', 'module.conv4.1.conv2.2.layers.2.conv2.weight', 'module.conv4.1.conv2.2.layers.2.bn.weight', 'module.conv4.1.conv2.2.layers.2.bn.bias', 'module.conv4.1.conv2.2.layers.2.bn.running_mean', 'module.conv4.1.conv2.2.layers.2.bn.running_var', 'module.conv4.1.conv2.2.layers.2.bn.num_batches_tracked', 'module.conv4.1.conv2.3.layers.0.conv1.weight', 'module.conv4.1.conv2.3.layers.0.conv2.weight', 'module.conv4.1.conv2.3.layers.0.bn.weight', 'module.conv4.1.conv2.3.layers.0.bn.bias', 'module.conv4.1.conv2.3.layers.0.bn.running_mean', 'module.conv4.1.conv2.3.layers.0.bn.running_var', 'module.conv4.1.conv2.3.layers.0.bn.num_batches_tracked', 'module.conv4.1.conv2.3.layers.1.conv1.weight', 'module.conv4.1.conv2.3.layers.1.conv2.weight', 'module.conv4.1.conv2.3.layers.1.bn.weight', 'module.conv4.1.conv2.3.layers.1.bn.bias', 'module.conv4.1.conv2.3.layers.1.bn.running_mean', 'module.conv4.1.conv2.3.layers.1.bn.running_var', 'module.conv4.1.conv2.3.layers.1.bn.num_batches_tracked', 'module.conv4.1.conv2.3.layers.2.conv1.weight', 'module.conv4.1.conv2.3.layers.2.conv2.weight', 'module.conv4.1.conv2.3.layers.2.bn.weight', 'module.conv4.1.conv2.3.layers.2.bn.bias', 'module.conv4.1.conv2.3.layers.2.bn.running_mean', 'module.conv4.1.conv2.3.layers.2.bn.running_var', 'module.conv4.1.conv2.3.layers.2.bn.num_batches_tracked', 'module.conv4.1.conv2.3.layers.3.conv1.weight', 'module.conv4.1.conv2.3.layers.3.conv2.weight', 'module.conv4.1.conv2.3.layers.3.bn.weight', 'module.conv4.1.conv2.3.layers.3.bn.bias', 'module.conv4.1.conv2.3.layers.3.bn.running_mean', 'module.conv4.1.conv2.3.layers.3.bn.running_var', 'module.conv4.1.conv2.3.layers.3.bn.num_batches_tracked', 'module.conv4.1.gate.fc1.weight', 'module.conv4.1.gate.fc1.bias', 'module.conv4.1.gate.fc2.weight', 'module.conv4.1.gate.fc2.bias', 'module.conv4.1.conv3.conv.weight', 'module.conv4.1.conv3.bn.weight', 'module.conv4.1.conv3.bn.bias', 'module.conv4.1.conv3.bn.running_mean', 'module.conv4.1.conv3.bn.running_var', 'module.conv4.1.conv3.bn.num_batches_tracked', 'module.conv5.conv.weight', 'module.conv5.bn.weight', 'module.conv5.bn.bias', 'module.conv5.bn.running_mean', 'module.conv5.bn.running_var', 'module.conv5.bn.num_batches_tracked', 'module.fc.0.weight', 'module.fc.0.bias', 'module.fc.1.weight', 'module.fc.1.bias', 'module.fc.1.running_mean', 'module.fc.1.running_var', 'module.fc.1.num_batches_tracked', 'module.classifier.weight', 'module.classifier.bias'])\n"
     ]
    }
   ],
   "source": [
    "model = ReIdRepresentation('osnet_ain_x1_0_msmt').to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102440f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62f15f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    data = torch.rand(2, 3, 128, 128)\n",
    "    n_views = np.array([2])\n",
    "    e = model(data, n_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc12c254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f560fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb8 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m/home/shivampr21/Downloads/hacnn_market_xent.pth.tar\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.venv/pkgs/pytorch/torch/serialization.py:1030\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1029\u001b[0m         \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1030\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m~/.venv/pkgs/pytorch/torch/serialization.py:1258\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1256\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1257\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1258\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1260\u001b[0m deserialized_storage_keys \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mload(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1262\u001b[0m offset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell() \u001b[39mif\u001b[39;00m f_should_read_directly \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb8 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "torch.load('/home/shivampr21/Downloads/hacnn_market_xent.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b103661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"/home/shivampr21/.cache/torch/checkpoints/osnet_ain_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    }
   ],
   "source": [
    "m = models.build_model(\"osnet_ain_x1_0\", 100, loss='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19f28387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 'conv1.conv.weight'\n",
      "n = 'conv1.bn.weight'\n",
      "n = 'conv1.bn.bias'\n",
      "n = 'conv2.0.conv1.conv.weight'\n",
      "n = 'conv2.0.conv1.bn.weight'\n",
      "n = 'conv2.0.conv1.bn.bias'\n",
      "n = 'conv2.0.conv2.0.layers.0.conv1.weight'\n",
      "n = 'conv2.0.conv2.0.layers.0.conv2.weight'\n",
      "n = 'conv2.0.conv2.0.layers.0.bn.weight'\n",
      "n = 'conv2.0.conv2.0.layers.0.bn.bias'\n",
      "n = 'conv2.0.conv2.1.layers.0.conv1.weight'\n",
      "n = 'conv2.0.conv2.1.layers.0.conv2.weight'\n",
      "n = 'conv2.0.conv2.1.layers.0.bn.weight'\n",
      "n = 'conv2.0.conv2.1.layers.0.bn.bias'\n",
      "n = 'conv2.0.conv2.1.layers.1.conv1.weight'\n",
      "n = 'conv2.0.conv2.1.layers.1.conv2.weight'\n",
      "n = 'conv2.0.conv2.1.layers.1.bn.weight'\n",
      "n = 'conv2.0.conv2.1.layers.1.bn.bias'\n",
      "n = 'conv2.0.conv2.2.layers.0.conv1.weight'\n",
      "n = 'conv2.0.conv2.2.layers.0.conv2.weight'\n",
      "n = 'conv2.0.conv2.2.layers.0.bn.weight'\n",
      "n = 'conv2.0.conv2.2.layers.0.bn.bias'\n",
      "n = 'conv2.0.conv2.2.layers.1.conv1.weight'\n",
      "n = 'conv2.0.conv2.2.layers.1.conv2.weight'\n",
      "n = 'conv2.0.conv2.2.layers.1.bn.weight'\n",
      "n = 'conv2.0.conv2.2.layers.1.bn.bias'\n",
      "n = 'conv2.0.conv2.2.layers.2.conv1.weight'\n",
      "n = 'conv2.0.conv2.2.layers.2.conv2.weight'\n",
      "n = 'conv2.0.conv2.2.layers.2.bn.weight'\n",
      "n = 'conv2.0.conv2.2.layers.2.bn.bias'\n",
      "n = 'conv2.0.conv2.3.layers.0.conv1.weight'\n",
      "n = 'conv2.0.conv2.3.layers.0.conv2.weight'\n",
      "n = 'conv2.0.conv2.3.layers.0.bn.weight'\n",
      "n = 'conv2.0.conv2.3.layers.0.bn.bias'\n",
      "n = 'conv2.0.conv2.3.layers.1.conv1.weight'\n",
      "n = 'conv2.0.conv2.3.layers.1.conv2.weight'\n",
      "n = 'conv2.0.conv2.3.layers.1.bn.weight'\n",
      "n = 'conv2.0.conv2.3.layers.1.bn.bias'\n",
      "n = 'conv2.0.conv2.3.layers.2.conv1.weight'\n",
      "n = 'conv2.0.conv2.3.layers.2.conv2.weight'\n",
      "n = 'conv2.0.conv2.3.layers.2.bn.weight'\n",
      "n = 'conv2.0.conv2.3.layers.2.bn.bias'\n",
      "n = 'conv2.0.conv2.3.layers.3.conv1.weight'\n",
      "n = 'conv2.0.conv2.3.layers.3.conv2.weight'\n",
      "n = 'conv2.0.conv2.3.layers.3.bn.weight'\n",
      "n = 'conv2.0.conv2.3.layers.3.bn.bias'\n",
      "n = 'conv2.0.gate.fc1.weight'\n",
      "n = 'conv2.0.gate.fc1.bias'\n",
      "n = 'conv2.0.gate.fc2.weight'\n",
      "n = 'conv2.0.gate.fc2.bias'\n",
      "n = 'conv2.0.conv3.conv.weight'\n",
      "n = 'conv2.0.downsample.conv.weight'\n",
      "n = 'conv2.0.downsample.bn.weight'\n",
      "n = 'conv2.0.downsample.bn.bias'\n",
      "n = 'conv2.0.IN.weight'\n",
      "n = 'conv2.0.IN.bias'\n",
      "n = 'conv2.1.conv1.conv.weight'\n",
      "n = 'conv2.1.conv1.bn.weight'\n",
      "n = 'conv2.1.conv1.bn.bias'\n",
      "n = 'conv2.1.conv2.0.layers.0.conv1.weight'\n",
      "n = 'conv2.1.conv2.0.layers.0.conv2.weight'\n",
      "n = 'conv2.1.conv2.0.layers.0.bn.weight'\n",
      "n = 'conv2.1.conv2.0.layers.0.bn.bias'\n",
      "n = 'conv2.1.conv2.1.layers.0.conv1.weight'\n",
      "n = 'conv2.1.conv2.1.layers.0.conv2.weight'\n",
      "n = 'conv2.1.conv2.1.layers.0.bn.weight'\n",
      "n = 'conv2.1.conv2.1.layers.0.bn.bias'\n",
      "n = 'conv2.1.conv2.1.layers.1.conv1.weight'\n",
      "n = 'conv2.1.conv2.1.layers.1.conv2.weight'\n",
      "n = 'conv2.1.conv2.1.layers.1.bn.weight'\n",
      "n = 'conv2.1.conv2.1.layers.1.bn.bias'\n",
      "n = 'conv2.1.conv2.2.layers.0.conv1.weight'\n",
      "n = 'conv2.1.conv2.2.layers.0.conv2.weight'\n",
      "n = 'conv2.1.conv2.2.layers.0.bn.weight'\n",
      "n = 'conv2.1.conv2.2.layers.0.bn.bias'\n",
      "n = 'conv2.1.conv2.2.layers.1.conv1.weight'\n",
      "n = 'conv2.1.conv2.2.layers.1.conv2.weight'\n",
      "n = 'conv2.1.conv2.2.layers.1.bn.weight'\n",
      "n = 'conv2.1.conv2.2.layers.1.bn.bias'\n",
      "n = 'conv2.1.conv2.2.layers.2.conv1.weight'\n",
      "n = 'conv2.1.conv2.2.layers.2.conv2.weight'\n",
      "n = 'conv2.1.conv2.2.layers.2.bn.weight'\n",
      "n = 'conv2.1.conv2.2.layers.2.bn.bias'\n",
      "n = 'conv2.1.conv2.3.layers.0.conv1.weight'\n",
      "n = 'conv2.1.conv2.3.layers.0.conv2.weight'\n",
      "n = 'conv2.1.conv2.3.layers.0.bn.weight'\n",
      "n = 'conv2.1.conv2.3.layers.0.bn.bias'\n",
      "n = 'conv2.1.conv2.3.layers.1.conv1.weight'\n",
      "n = 'conv2.1.conv2.3.layers.1.conv2.weight'\n",
      "n = 'conv2.1.conv2.3.layers.1.bn.weight'\n",
      "n = 'conv2.1.conv2.3.layers.1.bn.bias'\n",
      "n = 'conv2.1.conv2.3.layers.2.conv1.weight'\n",
      "n = 'conv2.1.conv2.3.layers.2.conv2.weight'\n",
      "n = 'conv2.1.conv2.3.layers.2.bn.weight'\n",
      "n = 'conv2.1.conv2.3.layers.2.bn.bias'\n",
      "n = 'conv2.1.conv2.3.layers.3.conv1.weight'\n",
      "n = 'conv2.1.conv2.3.layers.3.conv2.weight'\n",
      "n = 'conv2.1.conv2.3.layers.3.bn.weight'\n",
      "n = 'conv2.1.conv2.3.layers.3.bn.bias'\n",
      "n = 'conv2.1.gate.fc1.weight'\n",
      "n = 'conv2.1.gate.fc1.bias'\n",
      "n = 'conv2.1.gate.fc2.weight'\n",
      "n = 'conv2.1.gate.fc2.bias'\n",
      "n = 'conv2.1.conv3.conv.weight'\n",
      "n = 'conv2.1.IN.weight'\n",
      "n = 'conv2.1.IN.bias'\n",
      "n = 'pool2.0.conv.weight'\n",
      "n = 'pool2.0.bn.weight'\n",
      "n = 'pool2.0.bn.bias'\n",
      "n = 'conv3.0.conv1.conv.weight'\n",
      "n = 'conv3.0.conv1.bn.weight'\n",
      "n = 'conv3.0.conv1.bn.bias'\n",
      "n = 'conv3.0.conv2.0.layers.0.conv1.weight'\n",
      "n = 'conv3.0.conv2.0.layers.0.conv2.weight'\n",
      "n = 'conv3.0.conv2.0.layers.0.bn.weight'\n",
      "n = 'conv3.0.conv2.0.layers.0.bn.bias'\n",
      "n = 'conv3.0.conv2.1.layers.0.conv1.weight'\n",
      "n = 'conv3.0.conv2.1.layers.0.conv2.weight'\n",
      "n = 'conv3.0.conv2.1.layers.0.bn.weight'\n",
      "n = 'conv3.0.conv2.1.layers.0.bn.bias'\n",
      "n = 'conv3.0.conv2.1.layers.1.conv1.weight'\n",
      "n = 'conv3.0.conv2.1.layers.1.conv2.weight'\n",
      "n = 'conv3.0.conv2.1.layers.1.bn.weight'\n",
      "n = 'conv3.0.conv2.1.layers.1.bn.bias'\n",
      "n = 'conv3.0.conv2.2.layers.0.conv1.weight'\n",
      "n = 'conv3.0.conv2.2.layers.0.conv2.weight'\n",
      "n = 'conv3.0.conv2.2.layers.0.bn.weight'\n",
      "n = 'conv3.0.conv2.2.layers.0.bn.bias'\n",
      "n = 'conv3.0.conv2.2.layers.1.conv1.weight'\n",
      "n = 'conv3.0.conv2.2.layers.1.conv2.weight'\n",
      "n = 'conv3.0.conv2.2.layers.1.bn.weight'\n",
      "n = 'conv3.0.conv2.2.layers.1.bn.bias'\n",
      "n = 'conv3.0.conv2.2.layers.2.conv1.weight'\n",
      "n = 'conv3.0.conv2.2.layers.2.conv2.weight'\n",
      "n = 'conv3.0.conv2.2.layers.2.bn.weight'\n",
      "n = 'conv3.0.conv2.2.layers.2.bn.bias'\n",
      "n = 'conv3.0.conv2.3.layers.0.conv1.weight'\n",
      "n = 'conv3.0.conv2.3.layers.0.conv2.weight'\n",
      "n = 'conv3.0.conv2.3.layers.0.bn.weight'\n",
      "n = 'conv3.0.conv2.3.layers.0.bn.bias'\n",
      "n = 'conv3.0.conv2.3.layers.1.conv1.weight'\n",
      "n = 'conv3.0.conv2.3.layers.1.conv2.weight'\n",
      "n = 'conv3.0.conv2.3.layers.1.bn.weight'\n",
      "n = 'conv3.0.conv2.3.layers.1.bn.bias'\n",
      "n = 'conv3.0.conv2.3.layers.2.conv1.weight'\n",
      "n = 'conv3.0.conv2.3.layers.2.conv2.weight'\n",
      "n = 'conv3.0.conv2.3.layers.2.bn.weight'\n",
      "n = 'conv3.0.conv2.3.layers.2.bn.bias'\n",
      "n = 'conv3.0.conv2.3.layers.3.conv1.weight'\n",
      "n = 'conv3.0.conv2.3.layers.3.conv2.weight'\n",
      "n = 'conv3.0.conv2.3.layers.3.bn.weight'\n",
      "n = 'conv3.0.conv2.3.layers.3.bn.bias'\n",
      "n = 'conv3.0.gate.fc1.weight'\n",
      "n = 'conv3.0.gate.fc1.bias'\n",
      "n = 'conv3.0.gate.fc2.weight'\n",
      "n = 'conv3.0.gate.fc2.bias'\n",
      "n = 'conv3.0.conv3.conv.weight'\n",
      "n = 'conv3.0.conv3.bn.weight'\n",
      "n = 'conv3.0.conv3.bn.bias'\n",
      "n = 'conv3.0.downsample.conv.weight'\n",
      "n = 'conv3.0.downsample.bn.weight'\n",
      "n = 'conv3.0.downsample.bn.bias'\n",
      "n = 'conv3.1.conv1.conv.weight'\n",
      "n = 'conv3.1.conv1.bn.weight'\n",
      "n = 'conv3.1.conv1.bn.bias'\n",
      "n = 'conv3.1.conv2.0.layers.0.conv1.weight'\n",
      "n = 'conv3.1.conv2.0.layers.0.conv2.weight'\n",
      "n = 'conv3.1.conv2.0.layers.0.bn.weight'\n",
      "n = 'conv3.1.conv2.0.layers.0.bn.bias'\n",
      "n = 'conv3.1.conv2.1.layers.0.conv1.weight'\n",
      "n = 'conv3.1.conv2.1.layers.0.conv2.weight'\n",
      "n = 'conv3.1.conv2.1.layers.0.bn.weight'\n",
      "n = 'conv3.1.conv2.1.layers.0.bn.bias'\n",
      "n = 'conv3.1.conv2.1.layers.1.conv1.weight'\n",
      "n = 'conv3.1.conv2.1.layers.1.conv2.weight'\n",
      "n = 'conv3.1.conv2.1.layers.1.bn.weight'\n",
      "n = 'conv3.1.conv2.1.layers.1.bn.bias'\n",
      "n = 'conv3.1.conv2.2.layers.0.conv1.weight'\n",
      "n = 'conv3.1.conv2.2.layers.0.conv2.weight'\n",
      "n = 'conv3.1.conv2.2.layers.0.bn.weight'\n",
      "n = 'conv3.1.conv2.2.layers.0.bn.bias'\n",
      "n = 'conv3.1.conv2.2.layers.1.conv1.weight'\n",
      "n = 'conv3.1.conv2.2.layers.1.conv2.weight'\n",
      "n = 'conv3.1.conv2.2.layers.1.bn.weight'\n",
      "n = 'conv3.1.conv2.2.layers.1.bn.bias'\n",
      "n = 'conv3.1.conv2.2.layers.2.conv1.weight'\n",
      "n = 'conv3.1.conv2.2.layers.2.conv2.weight'\n",
      "n = 'conv3.1.conv2.2.layers.2.bn.weight'\n",
      "n = 'conv3.1.conv2.2.layers.2.bn.bias'\n",
      "n = 'conv3.1.conv2.3.layers.0.conv1.weight'\n",
      "n = 'conv3.1.conv2.3.layers.0.conv2.weight'\n",
      "n = 'conv3.1.conv2.3.layers.0.bn.weight'\n",
      "n = 'conv3.1.conv2.3.layers.0.bn.bias'\n",
      "n = 'conv3.1.conv2.3.layers.1.conv1.weight'\n",
      "n = 'conv3.1.conv2.3.layers.1.conv2.weight'\n",
      "n = 'conv3.1.conv2.3.layers.1.bn.weight'\n",
      "n = 'conv3.1.conv2.3.layers.1.bn.bias'\n",
      "n = 'conv3.1.conv2.3.layers.2.conv1.weight'\n",
      "n = 'conv3.1.conv2.3.layers.2.conv2.weight'\n",
      "n = 'conv3.1.conv2.3.layers.2.bn.weight'\n",
      "n = 'conv3.1.conv2.3.layers.2.bn.bias'\n",
      "n = 'conv3.1.conv2.3.layers.3.conv1.weight'\n",
      "n = 'conv3.1.conv2.3.layers.3.conv2.weight'\n",
      "n = 'conv3.1.conv2.3.layers.3.bn.weight'\n",
      "n = 'conv3.1.conv2.3.layers.3.bn.bias'\n",
      "n = 'conv3.1.gate.fc1.weight'\n",
      "n = 'conv3.1.gate.fc1.bias'\n",
      "n = 'conv3.1.gate.fc2.weight'\n",
      "n = 'conv3.1.gate.fc2.bias'\n",
      "n = 'conv3.1.conv3.conv.weight'\n",
      "n = 'conv3.1.IN.weight'\n",
      "n = 'conv3.1.IN.bias'\n",
      "n = 'pool3.0.conv.weight'\n",
      "n = 'pool3.0.bn.weight'\n",
      "n = 'pool3.0.bn.bias'\n",
      "n = 'conv4.0.conv1.conv.weight'\n",
      "n = 'conv4.0.conv1.bn.weight'\n",
      "n = 'conv4.0.conv1.bn.bias'\n",
      "n = 'conv4.0.conv2.0.layers.0.conv1.weight'\n",
      "n = 'conv4.0.conv2.0.layers.0.conv2.weight'\n",
      "n = 'conv4.0.conv2.0.layers.0.bn.weight'\n",
      "n = 'conv4.0.conv2.0.layers.0.bn.bias'\n",
      "n = 'conv4.0.conv2.1.layers.0.conv1.weight'\n",
      "n = 'conv4.0.conv2.1.layers.0.conv2.weight'\n",
      "n = 'conv4.0.conv2.1.layers.0.bn.weight'\n",
      "n = 'conv4.0.conv2.1.layers.0.bn.bias'\n",
      "n = 'conv4.0.conv2.1.layers.1.conv1.weight'\n",
      "n = 'conv4.0.conv2.1.layers.1.conv2.weight'\n",
      "n = 'conv4.0.conv2.1.layers.1.bn.weight'\n",
      "n = 'conv4.0.conv2.1.layers.1.bn.bias'\n",
      "n = 'conv4.0.conv2.2.layers.0.conv1.weight'\n",
      "n = 'conv4.0.conv2.2.layers.0.conv2.weight'\n",
      "n = 'conv4.0.conv2.2.layers.0.bn.weight'\n",
      "n = 'conv4.0.conv2.2.layers.0.bn.bias'\n",
      "n = 'conv4.0.conv2.2.layers.1.conv1.weight'\n",
      "n = 'conv4.0.conv2.2.layers.1.conv2.weight'\n",
      "n = 'conv4.0.conv2.2.layers.1.bn.weight'\n",
      "n = 'conv4.0.conv2.2.layers.1.bn.bias'\n",
      "n = 'conv4.0.conv2.2.layers.2.conv1.weight'\n",
      "n = 'conv4.0.conv2.2.layers.2.conv2.weight'\n",
      "n = 'conv4.0.conv2.2.layers.2.bn.weight'\n",
      "n = 'conv4.0.conv2.2.layers.2.bn.bias'\n",
      "n = 'conv4.0.conv2.3.layers.0.conv1.weight'\n",
      "n = 'conv4.0.conv2.3.layers.0.conv2.weight'\n",
      "n = 'conv4.0.conv2.3.layers.0.bn.weight'\n",
      "n = 'conv4.0.conv2.3.layers.0.bn.bias'\n",
      "n = 'conv4.0.conv2.3.layers.1.conv1.weight'\n",
      "n = 'conv4.0.conv2.3.layers.1.conv2.weight'\n",
      "n = 'conv4.0.conv2.3.layers.1.bn.weight'\n",
      "n = 'conv4.0.conv2.3.layers.1.bn.bias'\n",
      "n = 'conv4.0.conv2.3.layers.2.conv1.weight'\n",
      "n = 'conv4.0.conv2.3.layers.2.conv2.weight'\n",
      "n = 'conv4.0.conv2.3.layers.2.bn.weight'\n",
      "n = 'conv4.0.conv2.3.layers.2.bn.bias'\n",
      "n = 'conv4.0.conv2.3.layers.3.conv1.weight'\n",
      "n = 'conv4.0.conv2.3.layers.3.conv2.weight'\n",
      "n = 'conv4.0.conv2.3.layers.3.bn.weight'\n",
      "n = 'conv4.0.conv2.3.layers.3.bn.bias'\n",
      "n = 'conv4.0.gate.fc1.weight'\n",
      "n = 'conv4.0.gate.fc1.bias'\n",
      "n = 'conv4.0.gate.fc2.weight'\n",
      "n = 'conv4.0.gate.fc2.bias'\n",
      "n = 'conv4.0.conv3.conv.weight'\n",
      "n = 'conv4.0.downsample.conv.weight'\n",
      "n = 'conv4.0.downsample.bn.weight'\n",
      "n = 'conv4.0.downsample.bn.bias'\n",
      "n = 'conv4.0.IN.weight'\n",
      "n = 'conv4.0.IN.bias'\n",
      "n = 'conv4.1.conv1.conv.weight'\n",
      "n = 'conv4.1.conv1.bn.weight'\n",
      "n = 'conv4.1.conv1.bn.bias'\n",
      "n = 'conv4.1.conv2.0.layers.0.conv1.weight'\n",
      "n = 'conv4.1.conv2.0.layers.0.conv2.weight'\n",
      "n = 'conv4.1.conv2.0.layers.0.bn.weight'\n",
      "n = 'conv4.1.conv2.0.layers.0.bn.bias'\n",
      "n = 'conv4.1.conv2.1.layers.0.conv1.weight'\n",
      "n = 'conv4.1.conv2.1.layers.0.conv2.weight'\n",
      "n = 'conv4.1.conv2.1.layers.0.bn.weight'\n",
      "n = 'conv4.1.conv2.1.layers.0.bn.bias'\n",
      "n = 'conv4.1.conv2.1.layers.1.conv1.weight'\n",
      "n = 'conv4.1.conv2.1.layers.1.conv2.weight'\n",
      "n = 'conv4.1.conv2.1.layers.1.bn.weight'\n",
      "n = 'conv4.1.conv2.1.layers.1.bn.bias'\n",
      "n = 'conv4.1.conv2.2.layers.0.conv1.weight'\n",
      "n = 'conv4.1.conv2.2.layers.0.conv2.weight'\n",
      "n = 'conv4.1.conv2.2.layers.0.bn.weight'\n",
      "n = 'conv4.1.conv2.2.layers.0.bn.bias'\n",
      "n = 'conv4.1.conv2.2.layers.1.conv1.weight'\n",
      "n = 'conv4.1.conv2.2.layers.1.conv2.weight'\n",
      "n = 'conv4.1.conv2.2.layers.1.bn.weight'\n",
      "n = 'conv4.1.conv2.2.layers.1.bn.bias'\n",
      "n = 'conv4.1.conv2.2.layers.2.conv1.weight'\n",
      "n = 'conv4.1.conv2.2.layers.2.conv2.weight'\n",
      "n = 'conv4.1.conv2.2.layers.2.bn.weight'\n",
      "n = 'conv4.1.conv2.2.layers.2.bn.bias'\n",
      "n = 'conv4.1.conv2.3.layers.0.conv1.weight'\n",
      "n = 'conv4.1.conv2.3.layers.0.conv2.weight'\n",
      "n = 'conv4.1.conv2.3.layers.0.bn.weight'\n",
      "n = 'conv4.1.conv2.3.layers.0.bn.bias'\n",
      "n = 'conv4.1.conv2.3.layers.1.conv1.weight'\n",
      "n = 'conv4.1.conv2.3.layers.1.conv2.weight'\n",
      "n = 'conv4.1.conv2.3.layers.1.bn.weight'\n",
      "n = 'conv4.1.conv2.3.layers.1.bn.bias'\n",
      "n = 'conv4.1.conv2.3.layers.2.conv1.weight'\n",
      "n = 'conv4.1.conv2.3.layers.2.conv2.weight'\n",
      "n = 'conv4.1.conv2.3.layers.2.bn.weight'\n",
      "n = 'conv4.1.conv2.3.layers.2.bn.bias'\n",
      "n = 'conv4.1.conv2.3.layers.3.conv1.weight'\n",
      "n = 'conv4.1.conv2.3.layers.3.conv2.weight'\n",
      "n = 'conv4.1.conv2.3.layers.3.bn.weight'\n",
      "n = 'conv4.1.conv2.3.layers.3.bn.bias'\n",
      "n = 'conv4.1.gate.fc1.weight'\n",
      "n = 'conv4.1.gate.fc1.bias'\n",
      "n = 'conv4.1.gate.fc2.weight'\n",
      "n = 'conv4.1.gate.fc2.bias'\n",
      "n = 'conv4.1.conv3.conv.weight'\n",
      "n = 'conv4.1.conv3.bn.weight'\n",
      "n = 'conv4.1.conv3.bn.bias'\n",
      "n = 'conv5.conv.weight'\n",
      "n = 'conv5.bn.weight'\n",
      "n = 'conv5.bn.bias'\n",
      "n = 'fc.0.weight'\n",
      "n = 'fc.0.bias'\n",
      "n = 'fc.1.weight'\n",
      "n = 'fc.1.bias'\n",
      "n = 'classifier.weight'\n",
      "n = 'classifier.bias'\n"
     ]
    }
   ],
   "source": [
    "for n, p in m.named_parameters():\n",
    "    print(f'{n = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c9ae169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.fc_x = nn.Identity()\n",
    "# m.fc_s = nn.Identity()\n",
    "m.classifier = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e49e0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad625fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    data = torch.rand(2, 3, 128, 128)\n",
    "    e = m(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2348cf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ada6a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDort.representation.point_cloud_models.dgcnn import DGCNN_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "696f25b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'k': 30,\n",
    "    'emb_dims': 1024,\n",
    "    'dropout': False\n",
    "}\n",
    "model = DGCNN_cls(args)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2ff5f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivampr21/.venv/pkgs/vision/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_MobileNet_V3_Large_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/deeplabv3_mobilenet_v3_large-fc3c493d.pth\" to /home/shivampr21/.cache/torch/hub/checkpoints/deeplabv3_mobilenet_v3_large-fc3c493d.pth\n",
      "100%|██████████| 42.3M/42.3M [00:04<00:00, 9.02MB/s]\n"
     ]
    }
   ],
   "source": [
    "weights = vm.segmentation.DeepLabV3_MobileNet_V3_Large_Weights\n",
    "model = vm.segmentation.deeplabv3_mobilenet_v3_large(weights=weights)\n",
    "# (weights=weights, box_score_thresh=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38a0a84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 'backbone.body.conv1.weight'\n",
      "n = 'backbone.body.layer1.0.conv1.weight'\n",
      "n = 'backbone.body.layer1.0.conv2.weight'\n",
      "n = 'backbone.body.layer1.0.conv3.weight'\n",
      "n = 'backbone.body.layer1.0.downsample.0.weight'\n",
      "n = 'backbone.body.layer1.1.conv1.weight'\n",
      "n = 'backbone.body.layer1.1.conv2.weight'\n",
      "n = 'backbone.body.layer1.1.conv3.weight'\n",
      "n = 'backbone.body.layer1.2.conv1.weight'\n",
      "n = 'backbone.body.layer1.2.conv2.weight'\n",
      "n = 'backbone.body.layer1.2.conv3.weight'\n",
      "n = 'backbone.body.layer2.0.conv1.weight'\n",
      "n = 'backbone.body.layer2.0.conv2.weight'\n",
      "n = 'backbone.body.layer2.0.conv3.weight'\n",
      "n = 'backbone.body.layer2.0.downsample.0.weight'\n",
      "n = 'backbone.body.layer2.1.conv1.weight'\n",
      "n = 'backbone.body.layer2.1.conv2.weight'\n",
      "n = 'backbone.body.layer2.1.conv3.weight'\n",
      "n = 'backbone.body.layer2.2.conv1.weight'\n",
      "n = 'backbone.body.layer2.2.conv2.weight'\n",
      "n = 'backbone.body.layer2.2.conv3.weight'\n",
      "n = 'backbone.body.layer2.3.conv1.weight'\n",
      "n = 'backbone.body.layer2.3.conv2.weight'\n",
      "n = 'backbone.body.layer2.3.conv3.weight'\n",
      "n = 'backbone.body.layer3.0.conv1.weight'\n",
      "n = 'backbone.body.layer3.0.conv2.weight'\n",
      "n = 'backbone.body.layer3.0.conv3.weight'\n",
      "n = 'backbone.body.layer3.0.downsample.0.weight'\n",
      "n = 'backbone.body.layer3.1.conv1.weight'\n",
      "n = 'backbone.body.layer3.1.conv2.weight'\n",
      "n = 'backbone.body.layer3.1.conv3.weight'\n",
      "n = 'backbone.body.layer3.2.conv1.weight'\n",
      "n = 'backbone.body.layer3.2.conv2.weight'\n",
      "n = 'backbone.body.layer3.2.conv3.weight'\n",
      "n = 'backbone.body.layer3.3.conv1.weight'\n",
      "n = 'backbone.body.layer3.3.conv2.weight'\n",
      "n = 'backbone.body.layer3.3.conv3.weight'\n",
      "n = 'backbone.body.layer3.4.conv1.weight'\n",
      "n = 'backbone.body.layer3.4.conv2.weight'\n",
      "n = 'backbone.body.layer3.4.conv3.weight'\n",
      "n = 'backbone.body.layer3.5.conv1.weight'\n",
      "n = 'backbone.body.layer3.5.conv2.weight'\n",
      "n = 'backbone.body.layer3.5.conv3.weight'\n",
      "n = 'backbone.body.layer4.0.conv1.weight'\n",
      "n = 'backbone.body.layer4.0.conv2.weight'\n",
      "n = 'backbone.body.layer4.0.conv3.weight'\n",
      "n = 'backbone.body.layer4.0.downsample.0.weight'\n",
      "n = 'backbone.body.layer4.1.conv1.weight'\n",
      "n = 'backbone.body.layer4.1.conv2.weight'\n",
      "n = 'backbone.body.layer4.1.conv3.weight'\n",
      "n = 'backbone.body.layer4.2.conv1.weight'\n",
      "n = 'backbone.body.layer4.2.conv2.weight'\n",
      "n = 'backbone.body.layer4.2.conv3.weight'\n",
      "n = 'backbone.fpn.inner_blocks.0.0.weight'\n",
      "n = 'backbone.fpn.inner_blocks.0.0.bias'\n",
      "n = 'backbone.fpn.inner_blocks.1.0.weight'\n",
      "n = 'backbone.fpn.inner_blocks.1.0.bias'\n",
      "n = 'backbone.fpn.inner_blocks.2.0.weight'\n",
      "n = 'backbone.fpn.inner_blocks.2.0.bias'\n",
      "n = 'backbone.fpn.inner_blocks.3.0.weight'\n",
      "n = 'backbone.fpn.inner_blocks.3.0.bias'\n",
      "n = 'backbone.fpn.layer_blocks.0.0.weight'\n",
      "n = 'backbone.fpn.layer_blocks.0.0.bias'\n",
      "n = 'backbone.fpn.layer_blocks.1.0.weight'\n",
      "n = 'backbone.fpn.layer_blocks.1.0.bias'\n",
      "n = 'backbone.fpn.layer_blocks.2.0.weight'\n",
      "n = 'backbone.fpn.layer_blocks.2.0.bias'\n",
      "n = 'backbone.fpn.layer_blocks.3.0.weight'\n",
      "n = 'backbone.fpn.layer_blocks.3.0.bias'\n",
      "n = 'rpn.head.conv.0.0.weight'\n",
      "n = 'rpn.head.conv.0.0.bias'\n",
      "n = 'rpn.head.cls_logits.weight'\n",
      "n = 'rpn.head.cls_logits.bias'\n",
      "n = 'rpn.head.bbox_pred.weight'\n",
      "n = 'rpn.head.bbox_pred.bias'\n",
      "n = 'roi_heads.box_head.fc6.weight'\n",
      "n = 'roi_heads.box_head.fc6.bias'\n",
      "n = 'roi_heads.box_head.fc7.weight'\n",
      "n = 'roi_heads.box_head.fc7.bias'\n",
      "n = 'roi_heads.box_predictor.cls_score.weight'\n",
      "n = 'roi_heads.box_predictor.cls_score.bias'\n",
      "n = 'roi_heads.box_predictor.bbox_pred.weight'\n",
      "n = 'roi_heads.box_predictor.bbox_pred.bias'\n",
      "n = 'roi_heads.keypoint_head.0.weight'\n",
      "n = 'roi_heads.keypoint_head.0.bias'\n",
      "n = 'roi_heads.keypoint_head.2.weight'\n",
      "n = 'roi_heads.keypoint_head.2.bias'\n",
      "n = 'roi_heads.keypoint_head.4.weight'\n",
      "n = 'roi_heads.keypoint_head.4.bias'\n",
      "n = 'roi_heads.keypoint_head.6.weight'\n",
      "n = 'roi_heads.keypoint_head.6.bias'\n",
      "n = 'roi_heads.keypoint_head.8.weight'\n",
      "n = 'roi_heads.keypoint_head.8.bias'\n",
      "n = 'roi_heads.keypoint_head.10.weight'\n",
      "n = 'roi_heads.keypoint_head.10.bias'\n",
      "n = 'roi_heads.keypoint_head.12.weight'\n",
      "n = 'roi_heads.keypoint_head.12.bias'\n",
      "n = 'roi_heads.keypoint_head.14.weight'\n",
      "n = 'roi_heads.keypoint_head.14.bias'\n",
      "n = 'roi_heads.keypoint_predictor.kps_score_lowres.weight'\n",
      "n = 'roi_heads.keypoint_predictor.kps_score_lowres.bias'\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(f'{n = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dcb378e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeypointRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(640, 672, 704, 736, 768, 800), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "    (keypoint_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (keypoint_head): KeypointRCNNHeads(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "    )\n",
       "    (keypoint_predictor): KeypointRCNNPredictor(\n",
       "      (kps_score_lowres): ConvTranspose2d(512, 17, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d04a20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    data = torch.rand(2, 3, 128, 128)\n",
    "    e = model.backbone(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b2d0596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 960, 8, 8])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e['out'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a8d185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../pyDort/representation/point_cloud_models/ckpts/DGCNN_model.cls.1024.t7\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4a76f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand((20, 3, 30), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "405817d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "res = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d09a9ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('feature_model.conv1.weight',\n",
       "              tensor([[[-0.4641],\n",
       "                       [-0.0185],\n",
       "                       [-0.4473]],\n",
       "              \n",
       "                      [[-0.1623],\n",
       "                       [-0.4286],\n",
       "                       [ 0.3789]],\n",
       "              \n",
       "                      [[-0.4416],\n",
       "                       [-0.0010],\n",
       "                       [ 0.3595]],\n",
       "              \n",
       "                      [[-0.2413],\n",
       "                       [ 0.3653],\n",
       "                       [ 0.1276]],\n",
       "              \n",
       "                      [[ 0.2953],\n",
       "                       [ 0.4451],\n",
       "                       [-0.2676]],\n",
       "              \n",
       "                      [[ 0.2754],\n",
       "                       [-0.2739],\n",
       "                       [ 0.2091]],\n",
       "              \n",
       "                      [[-0.3455],\n",
       "                       [ 0.3159],\n",
       "                       [ 0.1128]],\n",
       "              \n",
       "                      [[-0.2876],\n",
       "                       [-0.2904],\n",
       "                       [ 0.2056]],\n",
       "              \n",
       "                      [[ 0.6339],\n",
       "                       [ 0.2595],\n",
       "                       [-0.0127]],\n",
       "              \n",
       "                      [[-0.2051],\n",
       "                       [ 0.3775],\n",
       "                       [-0.3661]],\n",
       "              \n",
       "                      [[ 0.2096],\n",
       "                       [-0.2504],\n",
       "                       [ 0.3594]],\n",
       "              \n",
       "                      [[-0.2899],\n",
       "                       [ 0.0462],\n",
       "                       [ 0.2404]],\n",
       "              \n",
       "                      [[ 0.4576],\n",
       "                       [ 0.0109],\n",
       "                       [ 0.5478]],\n",
       "              \n",
       "                      [[-0.5674],\n",
       "                       [ 0.0072],\n",
       "                       [-0.5695]],\n",
       "              \n",
       "                      [[-0.0124],\n",
       "                       [ 0.2292],\n",
       "                       [-0.2682]],\n",
       "              \n",
       "                      [[ 0.2323],\n",
       "                       [-0.1634],\n",
       "                       [-0.5595]],\n",
       "              \n",
       "                      [[ 0.4830],\n",
       "                       [ 0.3516],\n",
       "                       [ 0.3312]],\n",
       "              \n",
       "                      [[ 0.4698],\n",
       "                       [ 0.1950],\n",
       "                       [ 0.3940]],\n",
       "              \n",
       "                      [[ 0.4665],\n",
       "                       [-0.2267],\n",
       "                       [-0.4778]],\n",
       "              \n",
       "                      [[-0.3824],\n",
       "                       [-0.1285],\n",
       "                       [-0.0771]],\n",
       "              \n",
       "                      [[-0.0145],\n",
       "                       [ 0.3339],\n",
       "                       [ 0.2647]],\n",
       "              \n",
       "                      [[-0.4100],\n",
       "                       [-0.2108],\n",
       "                       [-0.2351]],\n",
       "              \n",
       "                      [[ 0.3694],\n",
       "                       [-0.1425],\n",
       "                       [-0.3599]],\n",
       "              \n",
       "                      [[-0.1594],\n",
       "                       [-0.1897],\n",
       "                       [-0.2024]],\n",
       "              \n",
       "                      [[-0.5853],\n",
       "                       [ 0.4702],\n",
       "                       [ 0.4072]],\n",
       "              \n",
       "                      [[-0.3358],\n",
       "                       [-0.3695],\n",
       "                       [ 0.0591]],\n",
       "              \n",
       "                      [[ 0.2613],\n",
       "                       [-0.4267],\n",
       "                       [-0.3377]],\n",
       "              \n",
       "                      [[ 0.3420],\n",
       "                       [-0.3472],\n",
       "                       [-0.0890]],\n",
       "              \n",
       "                      [[-0.4441],\n",
       "                       [ 0.5907],\n",
       "                       [ 0.2964]],\n",
       "              \n",
       "                      [[-0.5497],\n",
       "                       [-0.3140],\n",
       "                       [ 0.2762]],\n",
       "              \n",
       "                      [[-0.0496],\n",
       "                       [ 0.1064],\n",
       "                       [-0.6348]],\n",
       "              \n",
       "                      [[-0.3141],\n",
       "                       [ 0.3079],\n",
       "                       [-0.4615]],\n",
       "              \n",
       "                      [[-0.0933],\n",
       "                       [ 0.2579],\n",
       "                       [ 0.3851]],\n",
       "              \n",
       "                      [[ 0.0203],\n",
       "                       [ 0.1870],\n",
       "                       [ 0.3420]],\n",
       "              \n",
       "                      [[-0.1306],\n",
       "                       [-0.1768],\n",
       "                       [ 0.4900]],\n",
       "              \n",
       "                      [[ 0.5913],\n",
       "                       [ 0.2842],\n",
       "                       [-0.2804]],\n",
       "              \n",
       "                      [[-0.5788],\n",
       "                       [-0.5319],\n",
       "                       [ 0.1084]],\n",
       "              \n",
       "                      [[-0.2171],\n",
       "                       [-0.2170],\n",
       "                       [-0.1711]],\n",
       "              \n",
       "                      [[ 0.5358],\n",
       "                       [ 0.5940],\n",
       "                       [-0.1260]],\n",
       "              \n",
       "                      [[-0.2561],\n",
       "                       [ 0.2365],\n",
       "                       [-0.1766]],\n",
       "              \n",
       "                      [[-0.6388],\n",
       "                       [ 0.2084],\n",
       "                       [ 0.5050]],\n",
       "              \n",
       "                      [[-0.4783],\n",
       "                       [-0.1427],\n",
       "                       [ 0.2091]],\n",
       "              \n",
       "                      [[-0.3496],\n",
       "                       [-0.6128],\n",
       "                       [ 0.4350]],\n",
       "              \n",
       "                      [[-0.2328],\n",
       "                       [ 0.3766],\n",
       "                       [ 0.1336]],\n",
       "              \n",
       "                      [[ 0.2497],\n",
       "                       [-0.3610],\n",
       "                       [-0.1545]],\n",
       "              \n",
       "                      [[ 0.4820],\n",
       "                       [ 0.2530],\n",
       "                       [-0.1638]],\n",
       "              \n",
       "                      [[ 0.1581],\n",
       "                       [ 0.4711],\n",
       "                       [-0.5088]],\n",
       "              \n",
       "                      [[ 0.4311],\n",
       "                       [-0.1602],\n",
       "                       [-0.1834]],\n",
       "              \n",
       "                      [[ 0.2744],\n",
       "                       [-0.5650],\n",
       "                       [ 0.0500]],\n",
       "              \n",
       "                      [[ 0.5584],\n",
       "                       [ 0.2673],\n",
       "                       [-0.2374]],\n",
       "              \n",
       "                      [[-0.2771],\n",
       "                       [ 0.4218],\n",
       "                       [ 0.2343]],\n",
       "              \n",
       "                      [[ 0.3902],\n",
       "                       [-0.3731],\n",
       "                       [ 0.2716]],\n",
       "              \n",
       "                      [[ 0.0706],\n",
       "                       [ 0.1612],\n",
       "                       [ 0.5894]],\n",
       "              \n",
       "                      [[ 0.3332],\n",
       "                       [ 0.4360],\n",
       "                       [ 0.2757]],\n",
       "              \n",
       "                      [[ 0.2731],\n",
       "                       [-0.2062],\n",
       "                       [-0.5001]],\n",
       "              \n",
       "                      [[-0.4116],\n",
       "                       [-0.3954],\n",
       "                       [-0.4780]],\n",
       "              \n",
       "                      [[ 0.3688],\n",
       "                       [ 0.1853],\n",
       "                       [-0.1722]],\n",
       "              \n",
       "                      [[-0.4715],\n",
       "                       [ 0.5512],\n",
       "                       [ 0.4766]],\n",
       "              \n",
       "                      [[ 0.2835],\n",
       "                       [ 0.4676],\n",
       "                       [-0.4697]],\n",
       "              \n",
       "                      [[-0.3664],\n",
       "                       [-0.3141],\n",
       "                       [-0.1867]],\n",
       "              \n",
       "                      [[-0.6533],\n",
       "                       [ 0.3603],\n",
       "                       [ 0.0171]],\n",
       "              \n",
       "                      [[ 0.2801],\n",
       "                       [-0.3814],\n",
       "                       [-0.1341]],\n",
       "              \n",
       "                      [[ 0.1247],\n",
       "                       [-0.1889],\n",
       "                       [ 0.5900]],\n",
       "              \n",
       "                      [[-0.3082],\n",
       "                       [ 0.2492],\n",
       "                       [-0.3787]]], device='cuda:0')),\n",
       "             ('feature_model.conv1.bias',\n",
       "              tensor([-0.0217, -0.0449,  0.1473,  0.3210,  0.2056,  0.0818,  0.0346,  0.5690,\n",
       "                       0.0168,  0.4822, -0.2364,  0.2682,  0.3259,  0.4117,  0.5349,  0.0348,\n",
       "                      -0.3953,  0.0580,  0.1647, -0.2909, -0.0210,  0.2659, -0.4800, -0.4858,\n",
       "                      -0.3952,  0.0422, -0.2176,  0.0445,  0.0150, -0.3936, -0.1351,  0.2952,\n",
       "                      -0.4039,  0.3651,  0.2001,  0.7752, -0.5754, -0.8414,  0.3342, -0.6059,\n",
       "                      -0.4871,  0.3262,  0.1284, -0.4718,  0.4463, -0.1686,  0.5338, -0.2363,\n",
       "                      -0.4337, -0.4007, -0.0523, -0.6668, -0.1199, -0.3051, -0.1354,  0.1026,\n",
       "                       0.0051, -0.4542,  0.2020, -0.3839,  0.2061,  0.5408, -0.1109, -0.0697],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.conv2.weight',\n",
       "              tensor([[[ 0.1337],\n",
       "                       [ 0.0071],\n",
       "                       [-0.1673],\n",
       "                       ...,\n",
       "                       [ 0.0590],\n",
       "                       [-0.1124],\n",
       "                       [-0.0124]],\n",
       "              \n",
       "                      [[ 0.1059],\n",
       "                       [ 0.1841],\n",
       "                       [ 0.0569],\n",
       "                       ...,\n",
       "                       [-0.1088],\n",
       "                       [-0.0936],\n",
       "                       [ 0.1180]],\n",
       "              \n",
       "                      [[ 0.2175],\n",
       "                       [ 0.0389],\n",
       "                       [ 0.0727],\n",
       "                       ...,\n",
       "                       [-0.0588],\n",
       "                       [ 0.0103],\n",
       "                       [-0.1901]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.2242],\n",
       "                       [ 0.2051],\n",
       "                       [ 0.1754],\n",
       "                       ...,\n",
       "                       [-0.1996],\n",
       "                       [ 0.0127],\n",
       "                       [-0.0792]],\n",
       "              \n",
       "                      [[ 0.0616],\n",
       "                       [ 0.0713],\n",
       "                       [-0.0958],\n",
       "                       ...,\n",
       "                       [-0.1794],\n",
       "                       [-0.0382],\n",
       "                       [ 0.0945]],\n",
       "              \n",
       "                      [[-0.0541],\n",
       "                       [-0.1550],\n",
       "                       [-0.0286],\n",
       "                       ...,\n",
       "                       [-0.1320],\n",
       "                       [-0.2954],\n",
       "                       [-0.1066]]], device='cuda:0')),\n",
       "             ('feature_model.conv2.bias',\n",
       "              tensor([-0.0576, -0.0134,  0.1423,  0.0892, -0.0097,  0.1465, -0.1165,  0.0523,\n",
       "                      -0.1251, -0.0801, -0.1481,  0.2397, -0.0728,  0.0761,  0.0984,  0.2226,\n",
       "                      -0.0700,  0.0136,  0.0625,  0.0319,  0.1067,  0.1407,  0.1826, -0.0060,\n",
       "                      -0.3421,  0.2142, -0.2746, -0.2196,  0.3638,  0.0267, -0.0434,  0.3083,\n",
       "                      -0.0117,  0.0008, -0.1418,  0.3318,  0.1109,  0.1139,  0.0083, -0.1181,\n",
       "                       0.0087,  0.1358, -0.1663, -0.0120,  0.1163, -0.1454,  0.2273, -0.3887,\n",
       "                       0.2335,  0.1676,  0.0598, -0.0264, -0.1259, -0.1150, -0.1616,  0.0618,\n",
       "                      -0.0731,  0.0119, -0.2182,  0.0086,  0.0075, -0.0064, -0.1791,  0.0956],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.conv3.weight',\n",
       "              tensor([[[-0.2774],\n",
       "                       [ 0.0501],\n",
       "                       [-0.3030],\n",
       "                       ...,\n",
       "                       [-0.2228],\n",
       "                       [ 0.0163],\n",
       "                       [ 0.0363]],\n",
       "              \n",
       "                      [[-0.1521],\n",
       "                       [ 0.0445],\n",
       "                       [-0.0293],\n",
       "                       ...,\n",
       "                       [-0.0333],\n",
       "                       [ 0.1051],\n",
       "                       [-0.1587]],\n",
       "              \n",
       "                      [[-0.1095],\n",
       "                       [ 0.0916],\n",
       "                       [-0.3366],\n",
       "                       ...,\n",
       "                       [-0.1316],\n",
       "                       [-0.1592],\n",
       "                       [-0.2807]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0469],\n",
       "                       [ 0.1219],\n",
       "                       [ 0.0095],\n",
       "                       ...,\n",
       "                       [ 0.0154],\n",
       "                       [-0.0723],\n",
       "                       [-0.0192]],\n",
       "              \n",
       "                      [[ 0.0166],\n",
       "                       [-0.2058],\n",
       "                       [ 0.2094],\n",
       "                       ...,\n",
       "                       [-0.3624],\n",
       "                       [-0.0042],\n",
       "                       [-0.2055]],\n",
       "              \n",
       "                      [[-0.2495],\n",
       "                       [ 0.0120],\n",
       "                       [-0.0939],\n",
       "                       ...,\n",
       "                       [ 0.1785],\n",
       "                       [-0.1096],\n",
       "                       [-0.1250]]], device='cuda:0')),\n",
       "             ('feature_model.conv3.bias',\n",
       "              tensor([ 0.0378,  0.1318, -0.0920,  0.0757, -0.0332, -0.1541, -0.3569,  0.0068,\n",
       "                       0.0493, -0.0715, -0.2256,  0.1031,  0.0590, -0.2007, -0.0690, -0.2033,\n",
       "                      -0.1505,  0.1044, -0.0160, -0.0530, -0.1280, -0.1254,  0.1189,  0.0189,\n",
       "                      -0.1937,  0.1456, -0.1515, -0.0182,  0.0594, -0.1369, -0.0393, -0.0554,\n",
       "                      -0.0719, -0.1515, -0.1323, -0.1162, -0.2157,  0.1539,  0.0094, -0.2800,\n",
       "                      -0.0289, -0.0546, -0.0078,  0.0829, -0.1710,  0.0379, -0.0298, -0.2832,\n",
       "                      -0.1376,  0.2037,  0.0345, -0.1675,  0.0059,  0.0408, -0.3068, -0.0864,\n",
       "                      -0.0361,  0.0189,  0.0597, -0.1874,  0.1241,  0.0058, -0.1813, -0.1012],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.conv4.weight',\n",
       "              tensor([[[ 0.0351],\n",
       "                       [ 0.0006],\n",
       "                       [ 0.0136],\n",
       "                       ...,\n",
       "                       [ 0.1217],\n",
       "                       [ 0.1384],\n",
       "                       [ 0.0406]],\n",
       "              \n",
       "                      [[-0.0275],\n",
       "                       [-0.2825],\n",
       "                       [ 0.2974],\n",
       "                       ...,\n",
       "                       [-0.0437],\n",
       "                       [-0.0312],\n",
       "                       [-0.2504]],\n",
       "              \n",
       "                      [[-0.2894],\n",
       "                       [ 0.0247],\n",
       "                       [-0.0296],\n",
       "                       ...,\n",
       "                       [-0.0551],\n",
       "                       [ 0.1008],\n",
       "                       [ 0.0840]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.2655],\n",
       "                       [ 0.1448],\n",
       "                       [ 0.2434],\n",
       "                       ...,\n",
       "                       [ 0.0051],\n",
       "                       [ 0.1454],\n",
       "                       [-0.1278]],\n",
       "              \n",
       "                      [[ 0.0376],\n",
       "                       [-0.0136],\n",
       "                       [-0.0142],\n",
       "                       ...,\n",
       "                       [-0.0814],\n",
       "                       [-0.1966],\n",
       "                       [-0.0768]],\n",
       "              \n",
       "                      [[ 0.1387],\n",
       "                       [ 0.0979],\n",
       "                       [-0.1211],\n",
       "                       ...,\n",
       "                       [ 0.0669],\n",
       "                       [ 0.1226],\n",
       "                       [ 0.2086]]], device='cuda:0')),\n",
       "             ('feature_model.conv4.bias',\n",
       "              tensor([ 5.6716e-02,  5.2741e-02, -7.3396e-02,  6.1344e-02,  3.4993e-02,\n",
       "                       3.9131e-03, -2.7124e-01,  1.6527e-01,  3.8202e-02,  3.9127e-02,\n",
       "                      -2.4559e-01, -2.1717e-01,  2.2125e-02,  1.8446e-01, -5.9826e-02,\n",
       "                      -7.8381e-02,  1.1474e-01, -2.8052e-01, -6.6213e-02, -1.3692e-01,\n",
       "                      -6.3540e-02,  5.1238e-02, -4.1893e-02,  2.0752e-02, -1.9253e-01,\n",
       "                       6.1554e-02, -7.2917e-02,  1.4419e-01,  2.2833e-02,  6.8855e-02,\n",
       "                      -5.0622e-03, -9.1231e-02, -1.9955e-01, -4.3292e-02,  4.8238e-03,\n",
       "                      -2.4587e-01, -8.5101e-02,  6.4791e-02,  6.3275e-02, -4.6548e-02,\n",
       "                       9.2145e-02, -6.3381e-02, -1.7447e-01,  1.2286e-01, -6.2863e-02,\n",
       "                      -4.1050e-02,  1.0209e-01, -3.2164e-01, -9.1321e-02,  3.1709e-02,\n",
       "                      -7.7604e-02, -1.0139e-01,  1.3110e-01,  5.5663e-02, -2.9788e-02,\n",
       "                      -2.1556e-01,  2.6639e-01,  9.9435e-02, -2.9289e-04,  1.9437e-01,\n",
       "                      -1.2186e-01, -1.4621e-01, -1.7136e-02, -1.9330e-01, -8.7768e-02,\n",
       "                      -7.0641e-02, -1.4188e-01, -5.8003e-02,  9.5429e-03,  1.4701e-01,\n",
       "                      -9.6325e-02, -6.5517e-02,  3.4571e-02,  9.8287e-02,  1.7280e-01,\n",
       "                      -2.7846e-01,  9.0293e-02,  1.1633e-05, -8.7008e-02,  8.4520e-02,\n",
       "                      -4.2833e-02, -2.1876e-01, -4.4940e-02, -4.9539e-02,  4.3776e-02,\n",
       "                       6.4469e-03,  3.7461e-02, -2.7051e-01, -3.9069e-02,  1.2618e-02,\n",
       "                       1.8205e-01,  1.4874e-01,  1.4180e-01,  4.2395e-03,  1.3223e-01,\n",
       "                       2.0447e-02, -3.6350e-02, -1.2822e-01,  1.0348e-01, -2.1261e-01,\n",
       "                      -4.4086e-01, -5.9977e-02,  1.9958e-01,  7.8777e-02, -1.1688e-01,\n",
       "                      -6.7755e-02,  2.3084e-01,  1.1359e-01, -1.2143e-01, -4.2681e-02,\n",
       "                      -1.3940e-01,  4.4324e-02,  1.8566e-01,  1.0925e-01, -9.4542e-02,\n",
       "                      -1.3118e-01,  5.2106e-02,  6.2074e-02,  6.6436e-02,  1.9001e-02,\n",
       "                      -2.1978e-01,  2.1390e-02,  1.8387e-01, -9.4503e-03, -1.2252e-01,\n",
       "                      -5.7536e-02, -1.2459e-01,  7.1397e-02], device='cuda:0')),\n",
       "             ('feature_model.conv5.weight',\n",
       "              tensor([[[ 0.0668],\n",
       "                       [ 0.0458],\n",
       "                       [ 0.0906],\n",
       "                       ...,\n",
       "                       [ 0.1798],\n",
       "                       [-0.1200],\n",
       "                       [-0.0984]],\n",
       "              \n",
       "                      [[ 0.0427],\n",
       "                       [-0.2530],\n",
       "                       [-0.0436],\n",
       "                       ...,\n",
       "                       [ 0.0210],\n",
       "                       [ 0.0393],\n",
       "                       [ 0.0143]],\n",
       "              \n",
       "                      [[ 0.1263],\n",
       "                       [-0.0851],\n",
       "                       [ 0.2640],\n",
       "                       ...,\n",
       "                       [-0.0873],\n",
       "                       [ 0.0523],\n",
       "                       [-0.1535]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0174],\n",
       "                       [-0.0839],\n",
       "                       [-0.2238],\n",
       "                       ...,\n",
       "                       [ 0.2755],\n",
       "                       [ 0.0735],\n",
       "                       [ 0.1111]],\n",
       "              \n",
       "                      [[-0.2418],\n",
       "                       [-0.1258],\n",
       "                       [ 0.0326],\n",
       "                       ...,\n",
       "                       [-0.0202],\n",
       "                       [ 0.1722],\n",
       "                       [-0.1338]],\n",
       "              \n",
       "                      [[ 0.0554],\n",
       "                       [-0.0418],\n",
       "                       [-0.2459],\n",
       "                       ...,\n",
       "                       [ 0.1623],\n",
       "                       [-0.3348],\n",
       "                       [-0.0834]]], device='cuda:0')),\n",
       "             ('feature_model.conv5.bias',\n",
       "              tensor([ 0.1123,  0.0833, -0.1579,  ..., -0.0064, -0.0014, -0.0468],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.bn1.weight',\n",
       "              tensor([1.0411, 1.0759, 0.7560, 0.8911, 0.8060, 1.0448, 0.9024, 1.0481, 0.9927,\n",
       "                      0.9187, 1.0423, 0.9939, 1.1788, 1.0656, 1.0043, 0.9951, 1.1653, 1.1582,\n",
       "                      1.0279, 0.9593, 0.9271, 0.9380, 1.0417, 1.1111, 0.9272, 0.8581, 1.0572,\n",
       "                      0.9568, 0.8491, 1.0628, 1.1194, 1.2365, 1.0247, 0.9664, 0.8435, 1.0224,\n",
       "                      0.8462, 0.9419, 1.0379, 0.9296, 1.0716, 0.8750, 1.1396, 0.9042, 0.8673,\n",
       "                      0.9437, 1.0117, 1.0530, 0.9719, 1.0947, 0.9506, 1.1583, 1.0837, 0.9709,\n",
       "                      1.0339, 1.2060, 0.9481, 1.0153, 1.0601, 0.9805, 0.9319, 0.9063, 1.0464,\n",
       "                      1.2068], device='cuda:0')),\n",
       "             ('feature_model.bn1.bias',\n",
       "              tensor([ 0.0381, -0.0440, -0.0133, -0.0488, -0.0764, -0.0010, -0.0190,  0.0153,\n",
       "                      -0.0275, -0.0489, -0.0340,  0.0193, -0.0431,  0.0337,  0.0457,  0.0105,\n",
       "                      -0.0205,  0.0854,  0.0777, -0.0439, -0.0779, -0.0910, -0.0214, -0.1217,\n",
       "                      -0.0198, -0.0081,  0.0384,  0.0882, -0.0030, -0.0555,  0.1757,  0.1455,\n",
       "                      -0.0787,  0.0531,  0.0336,  0.0459,  0.0847, -0.0756, -0.0326, -0.1014,\n",
       "                      -0.0607,  0.0748,  0.1023, -0.0554,  0.0076,  0.0529,  0.1137,  0.0652,\n",
       "                       0.0957,  0.0438,  0.1425,  0.0418,  0.1040, -0.0101, -0.0078, -0.0143,\n",
       "                       0.0597,  0.0100,  0.1969, -0.0871, -0.0570,  0.0502,  0.0065,  0.0194],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.bn1.running_mean',\n",
       "              tensor([-0.0217, -0.0437,  0.1504,  0.3220,  0.2060,  0.0827,  0.0378,  0.5694,\n",
       "                       0.0151,  0.4835, -0.2351,  0.2709,  0.3230,  0.4126,  0.5339,  0.0388,\n",
       "                      -0.3953,  0.0569,  0.1656, -0.2911, -0.0204,  0.2658, -0.4829, -0.4880,\n",
       "                      -0.3941,  0.0448, -0.2205,  0.0439,  0.0134, -0.3972, -0.1374,  0.2961,\n",
       "                      -0.4019,  0.3663,  0.2000,  0.7770, -0.5721, -0.8473,  0.3336, -0.6054,\n",
       "                      -0.4883,  0.3284,  0.1256, -0.4707,  0.4476, -0.1651,  0.5328, -0.2406,\n",
       "                      -0.4330, -0.3990, -0.0529, -0.6688, -0.1197, -0.3058, -0.1326,  0.1014,\n",
       "                       0.0042, -0.4525,  0.2026, -0.3844,  0.2071,  0.5434, -0.1129, -0.0700],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.bn1.running_var',\n",
       "              tensor([0.0509, 0.0404, 0.0388, 0.0241, 0.0400, 0.0218, 0.0265, 0.0236, 0.0529,\n",
       "                      0.0364, 0.0277, 0.0174, 0.0635, 0.0792, 0.0145, 0.0513, 0.0565, 0.0509,\n",
       "                      0.0615, 0.0193, 0.0230, 0.0320, 0.0352, 0.0129, 0.0871, 0.0283, 0.0448,\n",
       "                      0.0278, 0.0747, 0.0540, 0.0540, 0.0477, 0.0293, 0.0203, 0.0357, 0.0579,\n",
       "                      0.0705, 0.0151, 0.0733, 0.0171, 0.0854, 0.0334, 0.0774, 0.0248, 0.0253,\n",
       "                      0.0364, 0.0587, 0.0284, 0.0438, 0.0498, 0.0369, 0.0408, 0.0508, 0.0458,\n",
       "                      0.0474, 0.0698, 0.0227, 0.0920, 0.0598, 0.0318, 0.0620, 0.0279, 0.0501,\n",
       "                      0.0352], device='cuda:0')),\n",
       "             ('feature_model.bn1.num_batches_tracked',\n",
       "              tensor(17806, device='cuda:0')),\n",
       "             ('feature_model.bn2.weight',\n",
       "              tensor([0.9831, 0.8106, 0.9703, 0.8957, 1.0912, 1.1661, 1.0948, 0.9325, 1.2872,\n",
       "                      0.8634, 1.1825, 0.9063, 0.8790, 0.9766, 1.0599, 0.8672, 0.8127, 0.7179,\n",
       "                      1.0345, 1.0316, 1.0460, 0.9581, 0.9928, 1.0661, 1.0704, 1.0989, 1.1353,\n",
       "                      0.7814, 0.8064, 0.8837, 0.9428, 1.0148, 1.0434, 0.9689, 0.8760, 1.1527,\n",
       "                      0.8674, 0.8562, 1.2002, 0.9520, 0.8069, 1.1183, 1.1560, 0.9980, 1.0851,\n",
       "                      0.7667, 0.9740, 1.0607, 0.9460, 1.1517, 0.9841, 1.0475, 0.9767, 0.9581,\n",
       "                      1.0250, 0.9279, 1.1086, 0.8728, 0.9244, 0.9823, 1.1406, 1.1704, 1.1149,\n",
       "                      0.9838], device='cuda:0')),\n",
       "             ('feature_model.bn2.bias',\n",
       "              tensor([ 0.0853, -0.1475, -0.0778,  0.0643, -0.1847, -0.0253, -0.1441, -0.2244,\n",
       "                      -0.0627,  0.0068, -0.0483,  0.0047, -0.1197, -0.1372,  0.0272, -0.1278,\n",
       "                      -0.0913, -0.2071, -0.2093, -0.0376, -0.1981, -0.1300, -0.0347,  0.1512,\n",
       "                      -0.0676, -0.1759, -0.0756, -0.2169, -0.0338, -0.1950, -0.1189, -0.2014,\n",
       "                      -0.0230,  0.1338, -0.1953,  0.1106, -0.1054, -0.1030, -0.0870, -0.0974,\n",
       "                      -0.0683, -0.1134, -0.0847, -0.0913, -0.1974, -0.1636, -0.1628, -0.2994,\n",
       "                      -0.0576, -0.0006, -0.1311, -0.1336, -0.1358, -0.1406, -0.0116,  0.0173,\n",
       "                      -0.0439, -0.0439, -0.1208, -0.0333, -0.1541, -0.0924, -0.0683,  0.0193],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.bn2.running_mean',\n",
       "              tensor([ 1.2302,  1.0307,  0.2015, -0.5128, -0.3674, -1.5926, -1.3374, -1.9996,\n",
       "                      -0.9283, -0.0171, -1.6548,  1.1504, -0.0309,  0.9224,  1.1750, -0.2120,\n",
       "                      -1.1347, -1.1666,  3.0145,  2.8606, -0.8912,  0.5257, -1.0766, -0.3853,\n",
       "                      -1.7170,  0.9272, -2.3632,  0.5842, -0.2340,  0.8534,  0.8868, -0.5176,\n",
       "                      -0.9596, -0.7436,  1.5973, -0.2184, -0.9301, -1.3877,  2.0455, -0.9104,\n",
       "                      -1.2168,  2.6262, -1.1197, -0.9547, -0.7407, -1.5716, -0.9541, -2.3161,\n",
       "                      -0.2523, -0.7461, -0.9690, -0.7947, -0.9893, -1.2789,  1.5205,  1.3795,\n",
       "                      -1.9054,  0.3063,  0.4783, -1.4733, -1.3920, -0.8098,  0.0642, -0.4366],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.bn2.running_var',\n",
       "              tensor([2.1267, 2.9166, 1.8578, 1.0894, 2.0154, 1.3916, 1.3623, 4.5149, 2.3547,\n",
       "                      2.8893, 1.7919, 1.1201, 3.7942, 1.8605, 2.7661, 3.3155, 7.5678, 5.2186,\n",
       "                      1.6822, 1.7248, 2.1173, 1.4066, 1.2490, 1.1568, 2.6239, 2.1027, 3.7017,\n",
       "                      3.0013, 5.0340, 2.5218, 2.9782, 1.2910, 2.2573, 5.7568, 3.9068, 1.2141,\n",
       "                      2.6430, 4.0933, 1.3359, 4.5057, 5.9088, 1.9984, 2.2214, 1.8475, 3.2210,\n",
       "                      4.5462, 2.4260, 2.2048, 1.9547, 1.1643, 2.6131, 1.1526, 2.2167, 2.8434,\n",
       "                      2.7571, 3.9270, 3.5653, 1.8130, 2.7760, 3.0118, 1.2773, 2.2171, 1.8675,\n",
       "                      3.3745], device='cuda:0')),\n",
       "             ('feature_model.bn2.num_batches_tracked',\n",
       "              tensor(17806, device='cuda:0')),\n",
       "             ('feature_model.bn3.weight',\n",
       "              tensor([0.9944, 1.0991, 0.8763, 0.9752, 0.9640, 1.0466, 1.1325, 0.8850, 1.0401,\n",
       "                      1.0717, 0.9761, 1.2869, 0.9804, 1.1878, 1.0621, 1.0256, 1.0354, 1.0415,\n",
       "                      0.9108, 0.9102, 0.8614, 1.2295, 1.0019, 1.1493, 1.0227, 0.8440, 1.0290,\n",
       "                      0.8726, 1.0475, 1.2118, 0.9310, 1.0545, 1.0418, 1.0795, 0.9280, 1.0470,\n",
       "                      0.9151, 0.9229, 1.1219, 0.9134, 1.1734, 0.8525, 0.9732, 0.9474, 1.1091,\n",
       "                      0.8779, 0.7730, 1.1025, 0.8465, 0.9707, 1.0988, 1.1948, 1.1834, 0.9976,\n",
       "                      1.1748, 1.0382, 0.9140, 0.9434, 0.9499, 0.8497, 0.9313, 0.7137, 0.9475,\n",
       "                      1.0845], device='cuda:0')),\n",
       "             ('feature_model.bn3.bias',\n",
       "              tensor([-0.1901, -0.0610, -0.1187, -0.1299, -0.2077,  0.0800, -0.1192,  0.0416,\n",
       "                      -0.0410, -0.0698, -0.0625,  0.0243, -0.0916, -0.0787,  0.0182, -0.1397,\n",
       "                      -0.2150, -0.1634, -0.1016,  0.0623, -0.1029, -0.0633, -0.0923, -0.0748,\n",
       "                      -0.0688, -0.1875, -0.0032, -0.0705,  0.0650, -0.0691, -0.0144, -0.2284,\n",
       "                      -0.1639, -0.1411,  0.0339, -0.2032, -0.2418, -0.0436, -0.0671, -0.1136,\n",
       "                       0.0013, -0.1854, -0.1787,  0.0454, -0.0740, -0.1785,  0.0212, -0.0231,\n",
       "                      -0.1127, -0.0401, -0.1887, -0.0976,  0.0045, -0.1006,  0.0440, -0.0696,\n",
       "                      -0.0435,  0.1458, -0.0493, -0.2201, -0.1441, -0.1820, -0.0577, -0.0790],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.bn3.running_mean',\n",
       "              tensor([-0.8510, -1.4596, -0.7043,  1.1908, -1.1605, -0.8097, -1.7244, -0.1378,\n",
       "                      -0.3322, -0.7363, -1.0377, -1.2873, -0.3390, -1.6552,  0.9552,  0.8177,\n",
       "                      -1.3083,  0.2451, -1.1398, -0.2142,  0.1568, -0.6726, -0.8049,  0.1735,\n",
       "                      -0.3954, -1.0862,  0.1024, -1.2892, -0.5550, -0.7631,  0.0386, -1.4140,\n",
       "                       1.2412, -1.0864, -0.8620, -0.6852, -0.6310,  0.4002, -1.2087, -0.0327,\n",
       "                       0.4264, -0.1272, -0.2857, -0.0966, -0.2815, -2.1433,  0.0767, -1.4828,\n",
       "                      -1.2221, -0.9334, -0.5659, -1.6209, -0.2707, -1.8100, -1.0170, -0.8735,\n",
       "                      -1.2865,  0.2053, -0.9243, -0.4853,  0.7066, -0.2382, -1.4880, -1.1389],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.bn3.running_var',\n",
       "              tensor([0.9758, 1.0327, 1.8186, 2.0821, 1.2179, 1.3557, 1.2577, 1.0759, 0.6332,\n",
       "                      1.1350, 1.4899, 1.0928, 0.8980, 1.5107, 1.7079, 1.9198, 1.0132, 1.1440,\n",
       "                      2.4882, 2.1176, 1.5390, 1.4103, 1.7150, 1.2230, 1.3489, 0.8839, 1.0959,\n",
       "                      1.8990, 1.4772, 1.1297, 1.8654, 1.3838, 1.3894, 1.0319, 1.6403, 1.2103,\n",
       "                      0.9077, 1.5535, 1.0162, 1.5049, 1.4085, 1.5124, 1.4510, 1.2570, 1.9865,\n",
       "                      1.3121, 2.0953, 1.3925, 1.5292, 2.2641, 1.4290, 0.8640, 3.2768, 2.0955,\n",
       "                      0.8763, 1.7398, 1.4107, 1.0213, 1.7046, 1.4952, 1.8794, 1.2112, 0.7550,\n",
       "                      1.2359], device='cuda:0')),\n",
       "             ('feature_model.bn3.num_batches_tracked',\n",
       "              tensor(17806, device='cuda:0')),\n",
       "             ('feature_model.bn4.weight',\n",
       "              tensor([1.1351, 0.9145, 1.1834, 1.3020, 1.0697, 0.9545, 1.0092, 1.0628, 0.8843,\n",
       "                      1.0330, 1.0259, 1.4930, 0.9144, 0.8712, 0.9255, 0.9576, 1.0507, 0.8442,\n",
       "                      0.9351, 0.9798, 1.0620, 1.1084, 0.7187, 1.0277, 1.0293, 1.0089, 0.8034,\n",
       "                      0.8683, 1.0083, 1.0875, 1.0316, 1.0424, 1.2126, 1.0398, 1.0205, 0.8709,\n",
       "                      0.7592, 1.0323, 1.0900, 1.2144, 0.7164, 0.8200, 0.9962, 1.0485, 0.8403,\n",
       "                      1.0741, 1.1019, 1.2006, 0.8558, 0.8842, 0.8145, 0.9265, 0.9004, 0.9854,\n",
       "                      1.1636, 0.9298, 0.8718, 0.9908, 1.1504, 1.2702, 0.9334, 0.8855, 1.0719,\n",
       "                      1.2173, 0.8015, 0.9926, 0.8721, 1.1190, 0.9241, 1.1774, 1.0437, 1.1829,\n",
       "                      0.9839, 1.2627, 1.3087, 0.9366, 0.9195, 0.9860, 0.9632, 1.0715, 1.0583,\n",
       "                      1.0677, 0.9650, 1.2401, 0.8718, 1.0365, 0.8655, 0.8047, 0.9447, 1.1860,\n",
       "                      0.8719, 0.9430, 1.1897, 1.1582, 0.9177, 1.1720, 0.9798, 0.8939, 0.9345,\n",
       "                      1.0162, 0.8109, 0.8817, 1.1575, 1.2216, 0.8201, 1.0947, 0.9566, 0.8665,\n",
       "                      0.9975, 1.0182, 0.9169, 1.2364, 1.0990, 1.2887, 1.1690, 0.9131, 0.8502,\n",
       "                      1.1281, 1.1688, 0.7562, 0.9949, 0.8904, 1.3903, 0.9857, 0.9573, 0.9659,\n",
       "                      1.0372, 1.0089], device='cuda:0')),\n",
       "             ('feature_model.bn4.bias',\n",
       "              tensor([-0.0734, -0.2107, -0.0387, -0.0345, -0.0139, -0.2357, -0.1651,  0.1057,\n",
       "                      -0.1130, -0.0128, -0.1269,  0.0056, -0.1683, -0.1497, -0.0929, -0.0219,\n",
       "                      -0.0509, -0.1940, -0.0198, -0.1841, -0.2073, -0.1162, -0.2363, -0.2236,\n",
       "                      -0.2267,  0.0293, -0.1042, -0.2417, -0.1183,  0.0152,  0.0809, -0.1424,\n",
       "                       0.1216,  0.0503,  0.0383, -0.0597, -0.2182, -0.0984, -0.0990, -0.1429,\n",
       "                      -0.2772, -0.1508, -0.1142, -0.0828, -0.0161,  0.1862, -0.1410, -0.0092,\n",
       "                      -0.1032, -0.1000, -0.1525, -0.1888, -0.2669, -0.2452, -0.0984, -0.1477,\n",
       "                      -0.0889, -0.0703, -0.0950, -0.0703, -0.0259, -0.2657, -0.1034, -0.0368,\n",
       "                      -0.1936, -0.2147, -0.1333,  0.0740, -0.0122, -0.0948, -0.2525,  0.2184,\n",
       "                      -0.1748,  0.0093,  0.0334, -0.0447, -0.0577,  0.0445, -0.1836, -0.1873,\n",
       "                      -0.1492, -0.0600, -0.0620, -0.0898, -0.2271, -0.0028, -0.1231, -0.1324,\n",
       "                      -0.1289, -0.1260, -0.1909, -0.1123, -0.0097,  0.1017, -0.0268, -0.0573,\n",
       "                      -0.0224, -0.1313, -0.0409, -0.0529, -0.0785, -0.1307, -0.0999, -0.0812,\n",
       "                       0.0051,  0.1382,  0.0332, -0.0442, -0.0583,  0.0778, -0.2292, -0.1231,\n",
       "                      -0.1184, -0.0921,  0.0106, -0.1159, -0.2191, -0.0587, -0.0117, -0.1494,\n",
       "                      -0.2196, -0.2061,  0.2412,  0.1342, -0.1152, -0.0068, -0.0507,  0.1071],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.bn4.running_mean',\n",
       "              tensor([-0.0601, -0.2954, -0.8288, -0.4478, -0.1095,  0.9907,  0.3795, -0.3021,\n",
       "                       0.3533, -1.4083, -1.2171, -0.3874, -1.4984,  0.4623, -1.5750, -0.4357,\n",
       "                       0.0257, -0.5715, -1.4288,  0.0497, -0.6809, -0.9261, -0.5896, -1.1887,\n",
       "                       0.2629, -1.0163, -2.0351, -0.5948, -0.3488, -0.7392, -1.1565, -1.4975,\n",
       "                      -1.0560, -0.4780, -0.1817, -1.0415, -1.4056, -0.2611, -0.9541, -0.5959,\n",
       "                       0.7959, -0.8024, -0.6779, -0.4238,  0.3359, -0.7547, -0.4407, -1.9074,\n",
       "                      -0.1579, -0.8541,  0.4603, -0.4843, -1.6264, -1.1003,  0.0811, -0.0459,\n",
       "                      -0.5543,  0.2755, -1.0880,  0.3004, -1.1704, -0.6238, -0.6034,  0.6176,\n",
       "                      -0.6931, -0.1613, -0.4785, -0.3772, -0.1604, -0.9685, -0.0092, -1.2101,\n",
       "                      -0.0953, -1.2589, -0.4092, -0.0577,  0.0894, -0.2704,  1.1390,  0.6666,\n",
       "                       0.2762, -0.8671,  0.1762, -0.3816, -0.5003,  0.0532, -0.8791, -0.6874,\n",
       "                      -0.8013, -0.1679, -0.0152, -0.0033, -0.8775, -1.0715, -1.1358, -1.7472,\n",
       "                       0.3369,  0.2678, -0.6955, -0.5317, -0.0835,  0.8045, -0.7103, -1.3060,\n",
       "                      -0.4543, -0.4671, -0.4023,  0.1034, -0.6467, -0.5568, -0.0081,  0.1094,\n",
       "                      -1.3869, -1.5044, -0.1420,  0.7044, -0.0226, -0.5980, -0.4064, -0.1568,\n",
       "                      -1.0645,  0.1636, -0.8470,  0.0624,  0.2406,  0.2408, -0.9258,  1.2701],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.bn4.running_var',\n",
       "              tensor([1.1906, 1.2870, 1.0274, 0.7773, 1.2717, 0.7233, 1.4144, 0.7537, 1.4035,\n",
       "                      1.0578, 0.7672, 1.5372, 0.9046, 1.1576, 0.5990, 0.8007, 0.6806, 0.9466,\n",
       "                      1.2116, 1.0887, 0.6984, 0.8492, 1.2053, 0.6420, 0.6165, 0.9632, 0.8174,\n",
       "                      1.1286, 0.5786, 0.8728, 0.5056, 0.7380, 0.8555, 1.6867, 0.8793, 0.6290,\n",
       "                      1.1896, 0.7640, 0.5931, 0.6072, 1.1241, 1.5263, 0.4128, 0.6979, 0.7190,\n",
       "                      0.9776, 0.8891, 0.9092, 2.1330, 0.9693, 0.8680, 0.9910, 1.2715, 0.7084,\n",
       "                      0.8304, 0.4196, 1.1083, 1.1133, 0.9705, 0.4932, 0.9579, 1.0532, 0.6685,\n",
       "                      0.8172, 0.8252, 1.2778, 0.6918, 0.9435, 0.8819, 0.8823, 0.4948, 1.5389,\n",
       "                      0.7773, 1.0671, 0.8640, 0.8479, 0.8616, 1.9348, 1.2081, 0.6886, 0.7230,\n",
       "                      0.7554, 0.7600, 1.1979, 1.6633, 0.6858, 1.1197, 1.2724, 0.4889, 0.6098,\n",
       "                      1.5372, 1.1142, 0.6331, 0.5505, 0.9106, 0.5978, 0.7853, 1.0751, 0.8627,\n",
       "                      0.6474, 0.6157, 0.6472, 1.6713, 0.6256, 1.5660, 0.8911, 1.3078, 0.9942,\n",
       "                      0.7986, 0.5279, 0.8175, 0.9273, 1.1145, 0.8350, 0.6240, 1.1084, 0.5657,\n",
       "                      0.6834, 0.4794, 1.6195, 0.9087, 1.0179, 0.7218, 0.9421, 1.3226, 1.0337,\n",
       "                      0.8804, 0.5568], device='cuda:0')),\n",
       "             ('feature_model.bn4.num_batches_tracked',\n",
       "              tensor(17806, device='cuda:0')),\n",
       "             ('feature_model.bn5.weight',\n",
       "              tensor([1.1428, 0.8174, 0.9991,  ..., 0.8852, 0.5923, 0.7017], device='cuda:0')),\n",
       "             ('feature_model.bn5.bias',\n",
       "              tensor([-0.0763, -0.0706,  0.0556,  ..., -0.0293,  0.1572,  0.0964],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.bn5.running_mean',\n",
       "              tensor([-0.0646, -2.6574, -1.9496,  ..., -2.2857, -3.8855, -2.6267],\n",
       "                     device='cuda:0')),\n",
       "             ('feature_model.bn5.running_var',\n",
       "              tensor([2.0883, 4.3950, 4.0670,  ..., 2.7512, 5.6978, 5.2261], device='cuda:0')),\n",
       "             ('feature_model.bn5.num_batches_tracked',\n",
       "              tensor(17806, device='cuda:0')),\n",
       "             ('linear1.weight',\n",
       "              tensor([[ 0.0643,  0.1317, -0.1630,  ...,  0.0617, -0.0879, -0.0431],\n",
       "                      [-0.0598, -0.1235,  0.0232,  ...,  0.1136, -0.0485,  0.1287],\n",
       "                      [-0.0250,  0.0078, -0.2006,  ...,  0.1032, -0.1774,  0.0100],\n",
       "                      ...,\n",
       "                      [ 0.0086,  0.0459,  0.0634,  ...,  0.0503, -0.0050,  0.0298],\n",
       "                      [-0.1107,  0.1073, -0.1442,  ...,  0.0372, -0.1125, -0.0366],\n",
       "                      [ 0.0152,  0.2451, -0.1794,  ..., -0.0006, -0.0729, -0.0964]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear1.bias',\n",
       "              tensor([ 1.9001e-01,  8.6652e-02, -2.6354e-02, -9.4417e-02, -9.4495e-02,\n",
       "                       6.9236e-02, -9.9551e-02, -1.8536e-01, -3.6447e-03,  4.3572e-02,\n",
       "                      -2.9581e-02, -1.8003e-02,  8.7127e-02,  3.1974e-03, -8.5280e-02,\n",
       "                      -8.1260e-02, -8.1592e-02,  3.7219e-02, -5.4921e-02, -3.5115e-02,\n",
       "                       6.9816e-02, -9.0036e-02,  8.5578e-02, -6.9165e-02, -6.5567e-02,\n",
       "                       5.9056e-02,  1.1080e-02,  2.4153e-02,  9.0630e-03,  8.8504e-02,\n",
       "                       1.2433e-01, -3.2364e-02, -6.8181e-03,  3.0613e-03, -8.3131e-02,\n",
       "                       8.4283e-03, -2.8322e-02, -1.3479e-01, -7.5603e-02, -4.4130e-02,\n",
       "                      -4.6508e-02,  7.5271e-02,  2.5271e-02,  5.0368e-03,  7.9260e-02,\n",
       "                       7.7744e-02, -1.3292e-02, -1.2666e-01, -1.7166e-01, -1.4266e-01,\n",
       "                      -2.0379e-02,  3.4526e-02,  2.3681e-02, -1.1311e-01, -1.4033e-01,\n",
       "                       1.6908e-01,  2.4438e-01, -2.6924e-02,  5.0239e-05, -4.8912e-02,\n",
       "                      -6.4641e-02, -1.3112e-01,  2.0755e-01,  9.1550e-02, -1.0283e-01,\n",
       "                       1.1935e-01,  2.0255e-02,  4.1825e-02,  1.6654e-01, -2.5353e-02,\n",
       "                       5.2396e-02,  6.4173e-02,  7.1125e-02, -1.1718e-01, -1.7911e-02,\n",
       "                      -3.1203e-02,  1.5672e-01,  5.9565e-02, -1.2625e-01, -6.9892e-02,\n",
       "                      -4.6704e-02,  1.8838e-02,  2.2014e-02, -2.7128e-02, -5.4766e-02,\n",
       "                      -2.2891e-02, -1.4040e-02,  6.0713e-02, -2.2093e-01,  4.0149e-02,\n",
       "                       6.4457e-02,  7.6444e-02,  3.6174e-02,  6.9237e-02, -6.2925e-02,\n",
       "                       2.5716e-01, -7.6536e-02,  1.6085e-01,  6.0314e-02,  5.6609e-02,\n",
       "                      -1.2393e-02, -9.6981e-02,  8.7547e-02, -8.8803e-02, -1.5637e-02,\n",
       "                      -5.3959e-02,  1.2248e-01, -1.6354e-02,  3.2710e-02,  3.2748e-02,\n",
       "                      -1.6982e-02,  4.5287e-02, -1.1690e-01, -2.1344e-02,  8.8453e-02,\n",
       "                      -1.1202e-01, -1.2168e-01, -4.3922e-03,  6.2536e-02, -3.4418e-02,\n",
       "                      -4.7979e-02, -6.1300e-02, -6.0725e-02,  1.5732e-01, -5.1360e-03,\n",
       "                       9.5663e-02, -3.4913e-03, -8.7521e-02, -1.2755e-01, -3.1972e-02,\n",
       "                      -6.8531e-02, -1.7776e-02,  6.4122e-02,  1.2320e-01, -1.0564e-01,\n",
       "                       1.3833e-01,  1.5397e-02,  1.2146e-01,  1.8386e-02, -2.2588e-02,\n",
       "                       5.3486e-02,  1.5369e-01,  8.5368e-02,  9.5135e-03, -1.4633e-01,\n",
       "                      -1.3206e-01,  7.4919e-02,  1.6780e-01, -8.9836e-02,  5.8336e-02,\n",
       "                       4.3545e-02,  5.7047e-02,  1.4819e-01,  1.1425e-01,  8.4191e-02,\n",
       "                      -3.3662e-02, -1.3778e-01, -4.3975e-02,  5.2900e-02,  3.1727e-02,\n",
       "                       4.8741e-02, -3.8910e-02, -1.1548e-02, -9.8246e-03,  1.0354e-01,\n",
       "                       2.1459e-02,  9.2097e-04, -1.9476e-02,  1.2164e-01, -1.2281e-01,\n",
       "                       9.7766e-02,  1.2331e-01, -5.3252e-02,  2.7981e-02, -3.6780e-02,\n",
       "                       3.1929e-02, -1.6661e-01, -7.1217e-02,  1.3618e-01,  1.9685e-01,\n",
       "                      -4.1243e-02,  6.1918e-02,  4.2665e-02, -3.6475e-02, -1.2054e-01,\n",
       "                      -7.8252e-02, -9.1257e-02,  3.3662e-02,  1.3603e-02,  4.0441e-02,\n",
       "                      -1.1598e-01, -9.4562e-02,  1.4872e-02, -3.8931e-02,  7.6599e-02,\n",
       "                       4.6844e-02,  9.1136e-02, -9.0814e-02, -6.9906e-02, -9.8183e-02,\n",
       "                       7.3471e-02,  4.4810e-02,  5.8310e-02,  1.5936e-01,  1.4827e-01,\n",
       "                      -1.4134e-02,  6.7727e-03, -2.5369e-02, -2.1167e-01,  5.9710e-02,\n",
       "                      -1.4879e-01,  6.7411e-02,  5.7863e-02, -2.7396e-02, -1.6905e-02,\n",
       "                      -1.6683e-02,  1.8743e-02,  3.5326e-02,  9.9088e-03,  1.9335e-01,\n",
       "                      -8.9877e-02,  9.4361e-02,  2.7331e-02,  2.8940e-02, -7.7398e-02,\n",
       "                       1.4029e-02,  2.4866e-03, -6.4416e-02,  1.7140e-01,  1.0430e-02,\n",
       "                      -1.5046e-01,  1.0268e-01, -6.2634e-02, -8.0561e-02, -6.0899e-02,\n",
       "                      -4.9290e-02, -5.3327e-02,  3.3942e-03, -1.2217e-02,  4.3578e-02,\n",
       "                       8.1510e-02,  7.4831e-02,  4.7040e-03, -3.0808e-02, -1.7911e-01,\n",
       "                       2.1256e-02, -1.2301e-01, -8.5022e-02, -2.9436e-02,  1.4711e-01,\n",
       "                      -4.1613e-02,  2.0191e-01, -5.2357e-02, -3.6650e-02,  1.0237e-01,\n",
       "                       9.4547e-03,  5.0290e-02, -1.2564e-02,  1.4442e-01, -6.5547e-03,\n",
       "                      -1.8701e-02,  1.4289e-02,  1.9403e-02,  4.6514e-02, -9.2798e-02,\n",
       "                       2.2791e-02, -7.5101e-02,  2.1866e-02, -6.4861e-02,  4.3718e-02,\n",
       "                       2.1791e-02,  3.4257e-02,  5.2708e-02,  9.8930e-02, -1.3152e-01,\n",
       "                       5.0839e-02, -1.4063e-01,  9.6210e-02, -3.0792e-02, -6.8754e-02,\n",
       "                       5.4569e-02,  3.6515e-02, -5.9921e-02, -2.6670e-02,  4.9593e-03,\n",
       "                       1.7510e-01, -1.1982e-02,  1.5797e-01,  2.5896e-02,  1.8106e-01,\n",
       "                      -6.0459e-02, -1.9122e-01,  6.5330e-02, -2.2650e-02,  8.7883e-02,\n",
       "                       2.2928e-02, -3.0241e-02, -6.6733e-02,  3.3836e-02,  1.2593e-01,\n",
       "                       1.7755e-01,  1.8913e-01, -1.3767e-03,  1.8035e-02,  2.5952e-01,\n",
       "                       9.0766e-02, -1.2884e-01,  1.1044e-01, -1.5222e-01, -1.2623e-03,\n",
       "                       2.2817e-02,  9.7792e-02, -4.2859e-03,  1.2743e-01,  1.7253e-01,\n",
       "                      -1.0711e-01,  1.6081e-02,  9.1892e-03,  3.7317e-02,  9.1546e-02,\n",
       "                      -7.2592e-02, -4.6863e-02,  2.4959e-02,  4.4980e-02, -1.7271e-01,\n",
       "                      -4.3083e-02,  9.4222e-02, -8.9532e-02,  1.5768e-02, -8.0748e-02,\n",
       "                       1.0231e-01, -1.0005e-01, -8.9645e-02, -6.4248e-02,  1.1629e-01,\n",
       "                      -6.8470e-02,  1.3498e-01,  5.2957e-02,  1.8855e-02,  2.5773e-02,\n",
       "                      -6.3214e-02, -7.7580e-03, -6.5491e-03, -1.3171e-01,  5.5206e-02,\n",
       "                       4.1095e-02,  7.2614e-02,  4.2021e-02, -1.8675e-01, -4.0066e-02,\n",
       "                       1.0124e-01,  5.7550e-02,  8.3160e-02, -5.0350e-02, -7.2358e-02,\n",
       "                       4.0071e-02,  1.8755e-02, -1.0322e-01,  5.3350e-02, -4.0702e-02,\n",
       "                       5.0165e-02, -9.4550e-02,  7.4418e-02, -6.2232e-02,  3.3516e-02,\n",
       "                       2.8238e-02,  2.0396e-01, -6.2692e-02,  6.9537e-02,  6.2231e-02,\n",
       "                      -6.8945e-02, -2.9113e-02, -2.9118e-02,  5.6700e-02,  2.5824e-02,\n",
       "                      -5.1885e-02,  5.7591e-02,  3.5364e-02,  1.3846e-01,  4.0324e-02,\n",
       "                      -6.5090e-02, -3.3498e-02, -2.3130e-02, -6.7066e-02, -1.5689e-02,\n",
       "                      -5.3444e-02, -6.2782e-02, -1.2165e-01,  2.8700e-02,  1.2673e-02,\n",
       "                       4.6686e-02, -2.6150e-02, -3.1053e-02, -3.0708e-03, -7.8215e-02,\n",
       "                      -8.6229e-03,  1.1467e-01,  2.4744e-01,  4.3943e-02,  2.8987e-02,\n",
       "                       4.0280e-02,  5.2818e-02,  2.0787e-02, -1.0286e-01, -5.9522e-02,\n",
       "                       2.6794e-01,  7.0530e-02, -8.6065e-03, -2.9314e-02,  1.3938e-01,\n",
       "                      -6.7613e-02,  2.8112e-02, -8.9430e-02, -2.3677e-02, -2.1941e-02,\n",
       "                      -6.6439e-02,  3.6581e-02, -1.1858e-01,  6.5541e-02, -2.7157e-02,\n",
       "                      -1.6114e-02,  1.2464e-01,  1.7028e-01, -2.3806e-02,  3.7166e-02,\n",
       "                       4.3956e-02,  8.0218e-02,  1.2538e-02, -6.1512e-02, -1.9816e-02,\n",
       "                      -1.8313e-02,  8.7742e-02,  6.7904e-02,  1.2181e-02, -1.6926e-02,\n",
       "                       2.0999e-01,  4.1027e-03, -7.4305e-02,  9.4131e-03, -3.1771e-02,\n",
       "                      -4.8403e-03, -1.2990e-01,  8.3119e-02, -5.1169e-02, -3.2144e-02,\n",
       "                       6.5753e-02,  1.2740e-02,  2.3265e-02, -1.0904e-02,  4.8691e-02,\n",
       "                      -4.8086e-02,  5.9444e-02,  1.4690e-02, -1.1414e-01,  9.0562e-02,\n",
       "                       8.8051e-02, -3.3239e-02, -5.9297e-02,  1.4178e-03, -5.7274e-02,\n",
       "                       3.2170e-03, -4.7441e-02,  9.9921e-02,  4.7750e-02, -1.6276e-01,\n",
       "                       9.2593e-03,  3.0006e-02, -1.3692e-01,  6.7417e-02, -1.2388e-01,\n",
       "                      -1.4807e-01,  1.8546e-01, -1.7504e-02,  2.3334e-02, -6.0019e-02,\n",
       "                      -1.0318e-02,  5.2531e-02, -1.6352e-02, -1.4366e-01,  2.2771e-02,\n",
       "                       1.0546e-01,  1.5550e-02,  1.8790e-02,  6.6501e-02,  5.3893e-03,\n",
       "                       1.3931e-02,  2.6434e-02,  6.4644e-02, -2.5900e-01, -4.9575e-02,\n",
       "                      -1.5399e-01,  3.5657e-02, -5.7035e-02, -1.1087e-01, -5.1206e-02,\n",
       "                       2.7295e-02,  1.2892e-01, -5.0467e-02,  4.0339e-02, -4.0621e-02,\n",
       "                      -3.8617e-02,  6.1303e-02, -5.2096e-02, -3.0644e-02, -1.5238e-02,\n",
       "                      -7.6037e-03,  1.0803e-01, -5.5183e-02,  1.2552e-03,  9.8901e-02,\n",
       "                      -8.0386e-02,  5.7164e-03], device='cuda:0')),\n",
       "             ('bn1.weight',\n",
       "              tensor([0.9585, 0.9276, 0.8560, 1.0562, 1.0008, 0.8604, 0.9991, 0.9219, 0.9988,\n",
       "                      0.9583, 0.9844, 0.9376, 1.0298, 1.0450, 0.9910, 0.9712, 1.0785, 1.0845,\n",
       "                      0.8978, 0.8463, 0.9619, 0.9254, 0.9154, 1.0856, 0.8972, 1.0046, 1.0495,\n",
       "                      1.0221, 0.9890, 1.1074, 1.0197, 0.9060, 0.9819, 0.9670, 0.9068, 0.8962,\n",
       "                      0.9162, 1.0127, 1.0860, 0.8915, 0.8958, 1.0029, 1.0090, 0.9006, 0.9225,\n",
       "                      1.0392, 0.9621, 0.9999, 0.9216, 1.0182, 0.9884, 0.9165, 1.1584, 1.0707,\n",
       "                      1.0242, 1.0001, 0.9598, 0.9580, 1.0172, 0.9652, 1.0418, 1.0118, 1.0652,\n",
       "                      0.8131, 0.8828, 0.9370, 0.9863, 1.0668, 1.0682, 0.9273, 1.0006, 1.0443,\n",
       "                      0.9584, 0.9940, 0.8192, 0.9823, 1.0110, 1.1089, 0.9991, 0.9920, 0.8528,\n",
       "                      1.0358, 0.9036, 1.0047, 0.9880, 0.9623, 0.9151, 1.0446, 1.0090, 0.8981,\n",
       "                      0.9607, 0.8730, 0.8668, 0.8967, 0.8686, 0.9935, 0.9060, 1.1129, 1.0690,\n",
       "                      1.1038, 0.9444, 1.0274, 1.0695, 0.8921, 0.8995, 0.9586, 0.9528, 1.0462,\n",
       "                      0.9994, 1.0372, 0.9551, 0.9138, 1.0896, 1.0446, 0.9349, 0.7800, 1.0236,\n",
       "                      0.9598, 1.0095, 1.0178, 0.9700, 1.0118, 0.9300, 1.1270, 0.9645, 0.9195,\n",
       "                      0.9041, 1.0051, 0.9444, 0.9619, 0.9285, 1.0016, 0.9798, 0.9627, 1.0104,\n",
       "                      1.0451, 1.0335, 0.9613, 1.0123, 0.9099, 0.8762, 0.9548, 0.9542, 0.9506,\n",
       "                      0.9387, 1.0708, 1.0337, 0.9123, 1.1046, 0.8249, 1.0201, 0.9541, 0.9892,\n",
       "                      1.0011, 0.9718, 1.0313, 0.9107, 0.9515, 0.9754, 1.0439, 1.0094, 0.9077,\n",
       "                      1.1262, 0.9217, 0.8531, 0.9285, 0.8489, 0.9310, 1.0796, 1.1121, 1.0517,\n",
       "                      0.9709, 1.0381, 0.9030, 0.9646, 1.0716, 1.0090, 1.0476, 1.0803, 1.0549,\n",
       "                      0.8465, 0.9594, 1.1318, 0.8263, 0.9612, 0.8554, 0.9752, 1.1072, 1.0194,\n",
       "                      0.9015, 0.8378, 1.0330, 1.0744, 0.8430, 0.9865, 0.9758, 0.9841, 0.9635,\n",
       "                      1.0023, 0.9532, 1.0674, 0.9956, 0.9649, 1.0775, 1.0683, 1.0441, 1.0325,\n",
       "                      1.0527, 0.9691, 0.8842, 0.9543, 0.9782, 1.0892, 1.1860, 0.9153, 0.9978,\n",
       "                      1.0204, 0.9383, 0.9238, 0.9572, 0.8898, 0.8830, 1.0872, 0.9011, 1.0686,\n",
       "                      1.0177, 0.9019, 0.9496, 1.0352, 0.9828, 0.9492, 1.0606, 0.8660, 0.9485,\n",
       "                      0.9323, 1.0721, 0.9654, 0.9663, 0.9733, 0.9730, 1.0242, 0.9496, 0.9543,\n",
       "                      0.9380, 0.9402, 0.9817, 0.9617, 0.9653, 0.9461, 0.9168, 0.9270, 1.0310,\n",
       "                      0.9852, 0.9881, 0.8427, 0.9491, 0.8773, 0.9605, 0.9604, 0.8871, 0.8808,\n",
       "                      0.9465, 0.8731, 0.9129, 0.8559, 1.0455, 1.0126, 1.0491, 0.9525, 1.0469,\n",
       "                      1.0396, 0.9234, 1.0283, 0.9433, 1.1161, 0.9675, 1.0293, 1.1006, 0.8480,\n",
       "                      0.9838, 0.8651, 0.9706, 0.9594, 0.9245, 0.9814, 0.9756, 1.0199, 1.0410,\n",
       "                      0.8984, 0.9540, 0.9685, 0.9776, 1.0284, 0.8135, 0.9686, 0.9554, 0.9379,\n",
       "                      0.9623, 0.9014, 0.9504, 0.9965, 0.9382, 0.9235, 1.0710, 0.9616, 0.8902,\n",
       "                      1.0064, 0.8625, 1.0607, 0.9826, 1.0254, 1.0175, 0.9254, 0.9331, 1.0885,\n",
       "                      0.8518, 0.9797, 0.9133, 0.9722, 1.1246, 0.9706, 0.9398, 0.9329, 1.0121,\n",
       "                      0.9815, 0.9099, 0.9705, 1.0289, 0.8999, 0.8946, 0.9458, 0.9457, 0.9801,\n",
       "                      0.9630, 0.9016, 0.8921, 0.8667, 0.9603, 0.9697, 0.9266, 0.9272, 1.0886,\n",
       "                      0.9428, 1.0375, 1.0381, 1.0351, 0.8936, 0.9268, 0.9832, 1.1676, 0.9092,\n",
       "                      0.9025, 0.9494, 0.9833, 1.0299, 0.9625, 0.9557, 1.0306, 0.9141, 1.0059,\n",
       "                      0.8400, 0.8673, 1.0001, 1.0824, 0.9053, 1.0020, 0.9762, 0.9821, 0.9931,\n",
       "                      0.9032, 1.0161, 0.9303, 0.8989, 0.9399, 0.8515, 0.9457, 0.8872, 0.9774,\n",
       "                      0.9355, 1.1316, 1.0354, 1.0533, 1.0643, 1.0147, 1.0096, 0.9314, 0.9560,\n",
       "                      1.0654, 0.9232, 0.9298, 1.0689, 0.9041, 0.9231, 1.0152, 1.1752, 0.8519,\n",
       "                      1.0242, 1.0033, 1.0811, 1.0843, 0.9000, 1.1102, 1.0219, 0.8681, 0.8679,\n",
       "                      1.0584, 1.0068, 0.9901, 0.8805, 0.9280, 0.9851, 0.9187, 1.0333, 0.8337,\n",
       "                      0.9433, 0.9294, 0.9298, 0.9541, 1.0497, 0.9413, 0.8926, 0.9944, 0.9557,\n",
       "                      0.8801, 1.0553, 0.9061, 1.0584, 1.1287, 0.8785, 1.0180, 0.9222, 1.0138,\n",
       "                      0.8969, 0.8627, 1.0866, 0.9595, 0.9369, 1.0916, 0.9265, 0.9794, 1.0176,\n",
       "                      0.9280, 0.9271, 0.8334, 1.0368, 0.9268, 0.9759, 0.9510, 1.0466, 0.9622,\n",
       "                      0.7893, 1.0609, 1.0446, 0.9647, 0.9481, 0.9119, 1.0324, 0.8355, 0.9976,\n",
       "                      1.0827, 0.9486, 0.9189, 0.9946, 1.1020, 0.9777, 0.9841, 0.9366, 1.0986,\n",
       "                      0.9770, 1.0153, 0.8530, 1.0996, 1.0986, 0.9553, 0.8930, 1.0030, 0.9991,\n",
       "                      0.8967, 0.9938, 1.0138, 0.9832, 0.9028, 0.9172, 1.0412, 1.0085, 0.9392,\n",
       "                      0.9220, 1.1414, 0.8978, 0.8708, 0.9512, 0.8963, 1.0662, 1.0726, 1.1163,\n",
       "                      1.0222, 0.8329, 0.8577, 0.9678, 0.9893, 1.0830, 0.9346, 0.9974, 0.9091,\n",
       "                      0.9690, 0.9194, 1.1397, 0.9406, 1.1123, 0.9744, 0.9090, 0.9411],\n",
       "                     device='cuda:0')),\n",
       "             ('bn1.bias',\n",
       "              tensor([-0.3357, -0.3487, -0.4128, -0.3032, -0.4564, -0.3013, -0.2553, -0.3390,\n",
       "                      -0.4447, -0.4240, -0.4449, -0.3279, -0.4359, -0.3628, -0.2767, -0.2698,\n",
       "                      -0.2775, -0.3325, -0.1794, -0.3748, -0.1927, -0.3388, -0.3739, -0.2924,\n",
       "                      -0.4505, -0.3764, -0.2637, -0.3260, -0.3840, -0.4319, -0.3548, -0.2154,\n",
       "                      -0.3841, -0.3876, -0.3451, -0.3406, -0.3630, -0.3780, -0.1936, -0.5405,\n",
       "                      -0.2886, -0.1264, -0.3393, -0.4710, -0.4193, -0.2360, -0.1527, -0.4192,\n",
       "                      -0.3166, -0.2602, -0.3076, -0.4218, -0.2979, -0.3267, -0.2897, -0.3234,\n",
       "                      -0.3073, -0.2699, -0.2596, -0.2754, -0.3553, -0.2412, -0.3379, -0.3133,\n",
       "                      -0.5149, -0.2261, -0.3014, -0.3358, -0.4132, -0.2440, -0.1869, -0.2856,\n",
       "                      -0.3720, -0.4374, -0.2223, -0.3102, -0.4715, -0.3077, -0.3598, -0.3081,\n",
       "                      -0.1906, -0.3445, -0.4311, -0.3042, -0.3790, -0.2554, -0.3180, -0.1280,\n",
       "                      -0.3802, -0.3085, -0.2742, -0.3579, -0.3504, -0.4022, -0.3763, -0.3344,\n",
       "                      -0.2863, -0.3151, -0.2393, -0.4553, -0.3312, -0.3264, -0.2471, -0.4242,\n",
       "                      -0.3045, -0.4582, -0.2698, -0.3430, -0.2352, -0.2476, -0.4232, -0.4741,\n",
       "                      -0.3914, -0.1696, -0.3217, -0.1718, -0.4188, -0.3211, -0.2987, -0.3884,\n",
       "                      -0.4937, -0.2617, -0.3033, -0.1708, -0.3199, -0.3317, -0.4024, -0.3173,\n",
       "                      -0.3174, -0.3377, -0.4234, -0.1448, -0.3785, -0.3693, -0.4054, -0.0787,\n",
       "                      -0.2909, -0.4540, -0.3751, -0.3845, -0.3508, -0.4297, -0.2845, -0.2604,\n",
       "                      -0.3959, -0.1640, -0.5021, -0.4336, -0.3778, -0.4101, -0.2790, -0.4386,\n",
       "                      -0.3377, -0.4673, -0.3733, -0.1877, -0.3651, -0.3111, -0.2827, -0.2565,\n",
       "                      -0.3203, -0.3310, -0.3915, -0.2403, -0.5393, -0.2835, -0.3825, -0.1917,\n",
       "                      -0.2720, -0.2083, -0.2445, -0.3264, -0.2999, -0.5275, -0.4100, -0.2340,\n",
       "                      -0.3430, -0.1880, -0.2778, -0.3956, -0.5486,  0.0016, -0.3902, -0.4116,\n",
       "                      -0.4216, -0.3960, -0.2173, -0.3190, -0.3559, -0.3002, -0.3944, -0.1819,\n",
       "                      -0.3243, -0.4884, -0.3996, -0.2277, -0.2524, -0.3166, -0.3631, -0.2733,\n",
       "                      -0.2904, -0.3647, -0.2813, -0.3496, -0.2611, -0.3480, -0.2780, -0.3409,\n",
       "                      -0.1384, -0.2751, -0.2568, -0.3441, -0.2781, -0.3006, -0.3522, -0.4137,\n",
       "                      -0.2935, -0.3945, -0.3543, -0.4116, -0.4108, -0.2686, -0.2751, -0.4792,\n",
       "                      -0.2042, -0.2111, -0.4511, -0.2912, -0.3434, -0.3191, -0.2517, -0.3133,\n",
       "                      -0.3386, -0.3601, -0.3144, -0.2518, -0.4127, -0.2347, -0.2653, -0.3206,\n",
       "                      -0.1678, -0.2635, -0.3733, -0.2887, -0.4821, -0.3219, -0.4035, -0.2321,\n",
       "                      -0.2320, -0.3438, -0.4412, -0.3211, -0.2802, -0.2779, -0.4344, -0.3631,\n",
       "                      -0.3195, -0.4421, -0.3579, -0.1872, -0.3876, -0.3650, -0.3296, -0.2463,\n",
       "                      -0.2891, -0.3459, -0.3469, -0.2428, -0.1733, -0.4242, -0.2066, -0.3095,\n",
       "                      -0.2186, -0.4094, -0.2470, -0.4405, -0.4314, -0.3771, -0.2586, -0.3131,\n",
       "                      -0.2721, -0.1874, -0.3608, -0.3426, -0.3920, -0.3313, -0.3158, -0.3773,\n",
       "                      -0.2220, -0.2750, -0.1419, -0.3569, -0.3292, -0.3568, -0.2713, -0.3263,\n",
       "                      -0.3175, -0.3874, -0.4010, -0.4539, -0.4952, -0.4281, -0.1548, -0.2291,\n",
       "                      -0.4029, -0.2913, -0.3034, -0.2401, -0.3756, -0.3302, -0.4572, -0.3648,\n",
       "                      -0.3741, -0.3739, -0.2182, -0.4636, -0.4127, -0.3862, -0.2013, -0.2862,\n",
       "                      -0.5216, -0.3690, -0.3507, -0.3449, -0.3527, -0.2241, -0.2912, -0.3535,\n",
       "                      -0.3753, -0.3103, -0.3938, -0.3350, -0.3039, -0.2400, -0.4617, -0.3008,\n",
       "                      -0.3436, -0.3662, -0.3152, -0.2415, -0.3804, -0.2755, -0.3068, -0.3476,\n",
       "                      -0.3498, -0.1700, -0.4606, -0.3006, -0.2364, -0.1548, -0.3955, -0.4274,\n",
       "                      -0.2696, -0.2375, -0.3592, -0.4083, -0.3852, -0.3748, -0.3388, -0.3816,\n",
       "                      -0.3718, -0.4307, -0.3843, -0.2623, -0.2675, -0.3236, -0.3877, -0.2821,\n",
       "                      -0.3958, -0.3432, -0.2285, -0.3029, -0.3913, -0.4678, -0.3362, -0.2885,\n",
       "                      -0.2835, -0.1688, -0.3270, -0.3174, -0.2856, -0.2827, -0.4266, -0.3492,\n",
       "                      -0.3774, -0.3194, -0.5323, -0.3296, -0.3069, -0.3195, -0.0394, -0.3652,\n",
       "                      -0.2839, -0.4470, -0.3722, -0.3888, -0.2068, -0.2818, -0.3429, -0.2044,\n",
       "                      -0.4303, -0.3235, -0.4252, -0.2535, -0.3682, -0.1845, -0.3893, -0.3102,\n",
       "                      -0.2746, -0.3611, -0.3624, -0.2529, -0.2991, -0.3567, -0.2264, -0.3827,\n",
       "                      -0.4162, -0.3660, -0.3182, -0.4933, -0.3463, -0.2903, -0.2299, -0.2393,\n",
       "                      -0.3597, -0.3666, -0.3626, -0.2674, -0.3495, -0.3886, -0.4537, -0.3760,\n",
       "                      -0.2028, -0.3045, -0.3071, -0.4140, -0.2460, -0.2327, -0.2483, -0.4610,\n",
       "                      -0.4252, -0.4095, -0.3967, -0.3406, -0.2139, -0.2484, -0.3134, -0.0948,\n",
       "                      -0.2337, -0.2899, -0.3283, -0.3207, -0.4492, -0.3357, -0.3529, -0.3486,\n",
       "                      -0.3359, -0.4682, -0.3023, -0.1905, -0.1887, -0.2731, -0.2704, -0.2068,\n",
       "                      -0.3091, -0.3569, -0.2393, -0.1794, -0.3014, -0.3089, -0.5029, -0.3864,\n",
       "                      -0.3236, -0.3888, -0.2492, -0.2427, -0.1930, -0.3335, -0.3464, -0.4027,\n",
       "                      -0.4224, -0.4152, -0.1986, -0.3464, -0.3980, -0.3718, -0.1561, -0.2739,\n",
       "                      -0.3867, -0.3589, -0.4492, -0.5019, -0.3162, -0.1569, -0.3760, -0.3844,\n",
       "                      -0.2803, -0.3734, -0.2963, -0.3560, -0.4257, -0.2893, -0.3674, -0.3320,\n",
       "                      -0.4291, -0.3945, -0.3148, -0.3541, -0.2629, -0.2341, -0.3763, -0.2861],\n",
       "                     device='cuda:0')),\n",
       "             ('bn1.running_mean',\n",
       "              tensor([ 6.7190e+01, -1.0605e+01,  2.1513e+00,  2.0958e+01,  6.0309e+01,\n",
       "                      -3.1172e+01,  1.7979e+01, -1.9933e+01,  1.2119e-01,  3.3326e+01,\n",
       "                       4.6922e+01,  8.9868e+00,  2.4864e+01, -8.0041e+00,  2.9162e+01,\n",
       "                       3.5549e+01,  2.8279e+01,  1.8115e+01,  3.1240e+01,  9.2481e-01,\n",
       "                       2.7835e+01,  8.2464e+00, -2.5010e+01,  1.6847e+01, -5.0116e+00,\n",
       "                       1.8000e+01,  3.5745e+01,  3.7585e+00,  3.7454e+01,  3.2813e+01,\n",
       "                      -7.0812e+00,  4.3825e+00,  2.7387e+01,  7.6586e+00,  9.2255e+01,\n",
       "                       3.3732e+01, -3.2861e+00,  3.2861e+01,  1.3966e+01,  3.2001e+01,\n",
       "                      -1.9741e+01, -2.6508e+01,  2.6951e+01, -2.8916e+01, -1.1114e+00,\n",
       "                       5.2266e+01,  2.8862e+01, -5.1242e-01, -4.4589e+01,  2.2356e+01,\n",
       "                       2.6719e+01,  1.8128e+01,  3.3709e+01,  4.2833e+01,  2.3482e+01,\n",
       "                       9.9261e+00, -7.6035e-01, -2.6592e+00,  1.1188e+01,  9.9584e-01,\n",
       "                       3.8741e+00,  5.5468e+01,  1.8470e+01, -1.7771e+01,  1.4529e+00,\n",
       "                      -1.5279e+01,  1.7865e+01,  1.1752e+01,  1.0038e+01,  7.1344e+00,\n",
       "                       3.4306e+01,  3.3218e+01,  2.4039e+01,  1.7239e+01, -1.2419e+01,\n",
       "                       6.2837e+01, -4.1010e+00,  4.4612e+01,  1.2844e+01,  1.4411e+01,\n",
       "                      -2.1882e+01,  3.2290e+01,  1.6290e+01,  7.5948e+01,  1.1548e+01,\n",
       "                       3.7879e+01,  2.0958e+01,  1.1993e+01,  6.8920e+01,  1.4156e+00,\n",
       "                       1.9211e+01, -3.8336e+01, -6.2777e+00,  3.1318e+01, -2.0155e+01,\n",
       "                       4.5444e+01,  2.6978e+00,  3.0828e+01,  3.5195e+01,  2.9445e+01,\n",
       "                       3.8993e+01,  2.0482e+01,  1.3227e+01, -1.5957e+01,  1.4424e+00,\n",
       "                      -2.0791e+00, -6.3648e+00,  5.3624e+01,  3.7227e+01,  1.7610e+01,\n",
       "                       2.0034e+01, -4.2111e+01,  4.3306e+01,  9.1491e+00, -3.7963e+00,\n",
       "                      -5.4136e+01,  3.8008e+01,  3.8648e+01,  3.3923e+01,  4.6959e+01,\n",
       "                       3.5708e+01,  1.7138e+01,  6.5543e+01,  2.5930e+01,  7.7201e+00,\n",
       "                      -1.7727e+01,  2.1283e+01, -1.4654e+00, -5.8931e+01,  3.3681e+00,\n",
       "                       5.6282e+01,  2.3880e+01, -1.3681e+01,  7.8575e+01,  3.7873e+00,\n",
       "                       1.3612e+01,  5.7917e+01,  5.7986e+01, -1.0677e+01, -9.9592e+00,\n",
       "                       2.7041e+01,  7.4204e+01,  5.3655e+01,  2.3202e+01,  1.0822e-01,\n",
       "                       1.7293e+01,  2.8710e+01,  9.9464e+00,  2.2659e+01, -6.0781e+01,\n",
       "                       1.8114e+01, -3.2708e+01,  5.9549e+01, -5.8589e+00,  2.4653e+01,\n",
       "                       4.8397e+01, -5.5636e+01,  1.2749e+01,  6.2093e+01,  2.0288e+01,\n",
       "                       1.8394e+01,  2.5522e+01,  2.5314e+01, -4.3280e+01,  9.7860e+00,\n",
       "                      -9.9002e+00, -4.3877e+01,  3.1428e+01,  4.7628e+01,  7.4805e+01,\n",
       "                       3.5050e+01, -6.2050e+00,  1.2780e+01,  5.2569e+01,  3.6144e+01,\n",
       "                       5.1681e+01,  3.0789e+01,  4.5478e+01,  2.4195e+01,  3.2174e+01,\n",
       "                       1.6656e+01, -1.5663e+01, -1.2620e+01, -7.0759e+01,  4.3397e+01,\n",
       "                       2.8724e+01,  2.1864e+00,  7.1451e+00,  2.7393e+01, -3.8473e+01,\n",
       "                       1.5567e+01,  3.8941e+01,  1.8608e+01,  7.9041e+00, -3.5672e-01,\n",
       "                       8.3293e+00,  5.6198e+01,  3.1920e+01, -1.6547e+01,  6.4601e+01,\n",
       "                       4.3982e+01,  4.6226e+01, -1.2923e+01,  1.0121e+02, -1.4750e+00,\n",
       "                       3.5465e+01,  2.5073e+01,  4.4271e+01,  8.3322e+00, -2.2251e+01,\n",
       "                       1.7393e+01,  2.7386e+01,  1.4797e+01, -5.4193e-02, -1.1896e+01,\n",
       "                       6.4217e+01, -4.0749e+00,  1.2928e+01,  1.8194e+01,  4.4953e+01,\n",
       "                       5.1594e+01,  3.8710e+01, -2.9419e+00,  2.2457e+01,  5.6546e+01,\n",
       "                       2.2303e+01,  5.1016e+01,  1.8212e+01,  5.0519e+01, -1.8423e+00,\n",
       "                       2.9152e+01,  2.2609e+01, -2.2960e+01,  5.1522e+01, -1.5299e+01,\n",
       "                      -9.3426e+00,  4.1016e+01,  4.7564e+01,  2.6786e+01,  1.1669e+00,\n",
       "                       3.3575e+01,  4.3795e+01,  3.5877e-01,  3.7812e+01,  4.3457e+00,\n",
       "                       2.8769e+01, -2.9478e+01,  6.4108e+01,  1.6557e+00, -2.9784e+00,\n",
       "                       3.4921e+01,  5.7891e+01,  1.2309e+01,  1.5723e+01,  3.8300e+01,\n",
       "                       1.1785e+01, -6.9824e+01,  5.4144e+01,  1.5713e+00, -3.4585e+01,\n",
       "                       5.7927e+01, -1.3317e+01, -2.6339e+01,  3.4651e+01, -3.1721e+01,\n",
       "                       2.4912e+01, -9.1975e+00,  3.2809e+01,  3.0265e+01,  2.6879e+01,\n",
       "                      -1.4353e+00, -1.7304e+01,  6.7258e+01,  1.9399e+01,  1.5562e+01,\n",
       "                      -7.3862e+00,  2.3929e+01,  2.9671e+01, -2.2671e+01, -1.9022e+01,\n",
       "                      -1.1515e+01,  1.8741e+01, -3.4444e+00,  8.5660e+00,  4.2554e+01,\n",
       "                       3.6339e+01,  2.3885e+01,  3.3966e+01, -1.5734e+00,  9.8864e+00,\n",
       "                       5.1771e+00,  5.4759e+01,  3.9209e+01,  3.0327e+00, -9.0582e+00,\n",
       "                       3.1105e+01,  2.1846e+01,  1.7049e+01, -2.8825e+00,  1.8310e+01,\n",
       "                      -1.2652e+01,  2.3594e+01,  1.2872e+01,  2.2710e+01,  1.3179e+00,\n",
       "                      -2.9068e+01,  2.0758e+01,  8.6223e+00,  3.8380e+01,  2.9644e+01,\n",
       "                       3.6821e+01,  2.6043e+01,  1.8752e+01, -1.9387e+01,  1.1020e+01,\n",
       "                       2.5268e+01,  4.3460e+01,  6.2600e+00,  5.2609e+01,  1.7857e+01,\n",
       "                       2.2949e+01, -1.9350e+01, -1.7008e+01,  6.4376e+01,  2.1275e+01,\n",
       "                      -2.5814e+01,  2.9818e+01,  6.4869e+01,  8.9851e+00, -8.2729e+00,\n",
       "                      -1.7004e+01,  2.7288e+01,  2.2648e+01,  5.1846e+00, -4.6534e+01,\n",
       "                       1.7645e+01,  5.3522e+00, -1.6508e+00,  7.2475e+01,  5.1806e+00,\n",
       "                       3.2652e+01,  2.2774e+01,  1.0446e+01,  5.2895e+00, -4.6180e+00,\n",
       "                       3.3203e+01,  6.3476e+01,  1.8706e+01,  7.1490e+01,  4.0465e+01,\n",
       "                       1.4872e+01,  1.4948e+01,  4.2624e+01,  4.1181e+01,  1.3654e+01,\n",
       "                       1.8468e+01,  2.9169e+01,  1.0390e+01, -6.3579e+00,  7.1839e+01,\n",
       "                      -5.0962e+01,  5.4763e+01, -7.8724e+00,  2.8553e+01,  9.8310e+00,\n",
       "                       2.6827e+01,  3.1663e+01,  5.4388e+01,  3.4676e+01,  3.3451e+01,\n",
       "                       2.8299e+01,  1.1647e+01, -2.6941e+01,  1.8418e+01,  3.0471e+01,\n",
       "                       5.8387e+01,  3.1715e+00, -7.1653e+00,  2.9975e+01,  2.5165e+01,\n",
       "                       2.1987e+01,  1.5861e+01,  5.4887e+01,  4.0134e+01, -1.2283e+01,\n",
       "                       2.2780e+01, -2.2457e+01,  3.5984e+01,  2.5509e+01,  1.8330e+01,\n",
       "                       3.0839e+01,  3.5665e+00, -6.8059e+00,  4.9728e+01,  3.8629e+01,\n",
       "                      -3.9057e+01,  2.0245e+01,  5.1222e+01,  6.7214e+01,  3.5467e+01,\n",
       "                       1.2872e+00,  3.2529e+01, -2.9095e+00, -1.5533e+01,  2.9673e+01,\n",
       "                       3.2787e+01,  1.6166e+01,  8.0007e+00,  5.2421e+01,  3.1863e+01,\n",
       "                       2.3731e+01, -1.5123e+01,  3.0487e+01,  3.5927e+01,  1.7918e+01,\n",
       "                       4.7008e+00,  4.2221e+01,  1.5848e+01,  3.8849e+01, -3.4560e+01,\n",
       "                      -2.3971e+01,  6.4855e+01,  3.0771e+01, -1.9554e+01,  3.2367e+01,\n",
       "                       6.0678e+00,  5.2397e+01,  3.1172e+00,  3.6271e+01,  3.7170e+01,\n",
       "                      -3.6160e+01,  2.9733e+01, -6.1110e+01,  1.1305e+01,  1.1287e+01,\n",
       "                       3.6538e+01,  1.3487e+01,  1.9755e+01,  2.2937e+01, -5.1565e+01,\n",
       "                      -7.2450e+00,  9.4332e+00,  3.3224e+01, -2.3864e+01,  1.5412e+01,\n",
       "                       3.5634e+00,  7.2876e+00, -3.8100e+01,  3.5605e+01,  9.6059e+00,\n",
       "                      -4.5072e+01,  6.0516e+01,  8.6320e+00,  4.1147e+01, -3.4161e+00,\n",
       "                       4.1134e+01,  4.7110e+01,  4.4053e+01,  3.8596e+01,  1.3998e+01,\n",
       "                       2.9403e+00,  2.9219e+01,  2.8916e+01,  2.1400e+01,  3.9052e+01,\n",
       "                       6.9176e+00,  2.4951e+01,  4.6362e+01, -5.4555e+01,  2.7425e+01,\n",
       "                      -6.5958e+00,  2.0959e+01,  3.0473e+01,  1.6202e+01,  7.4556e+00,\n",
       "                      -1.0481e+01,  1.8140e+01,  8.9503e-01,  4.2629e+01, -1.8084e+01,\n",
       "                      -4.1230e+00,  2.5803e+01,  5.2346e+00,  2.1991e+01,  2.4846e+01,\n",
       "                       2.1550e+01,  3.9441e+01,  2.2712e+01,  1.0390e+01,  1.5096e+01,\n",
       "                       1.7821e+01, -3.4924e+01, -3.5490e+00,  5.7543e+01,  1.0655e+01,\n",
       "                      -1.1628e+00, -2.6310e+01,  5.1271e+01,  8.7327e+00,  3.0058e+01,\n",
       "                       4.0883e+01, -4.6776e+00, -1.1192e+01, -2.5717e+00,  4.3528e+01,\n",
       "                       1.6422e+01,  1.3785e+01,  2.6416e+01,  2.7229e+01,  1.4895e+00,\n",
       "                      -1.1895e+01,  3.0888e+01], device='cuda:0')),\n",
       "             ('bn1.running_var',\n",
       "              tensor([35.0565, 38.1641, 31.9974, 21.7880, 43.3573, 34.6664, 40.6360, 45.0484,\n",
       "                      17.6905, 20.8609, 31.8191, 34.7655, 27.9613, 29.9106, 26.7012, 24.0136,\n",
       "                      28.4536, 27.5000, 41.1334, 20.3178, 25.6265, 26.7445, 49.8538, 32.0816,\n",
       "                      39.2024, 33.2461, 31.5373, 14.2632, 21.8574, 20.1561, 43.9119, 25.7325,\n",
       "                      30.2304, 41.6527, 46.4662, 31.1636, 32.5194, 43.2427, 37.3722, 22.1194,\n",
       "                      27.2901, 32.6475, 22.6466, 34.5276, 37.4337, 33.5640, 33.3460, 29.6184,\n",
       "                      33.2901, 35.0486, 23.1477, 33.4409, 31.6887, 25.3694, 34.5857, 24.1420,\n",
       "                      31.0843, 21.8856, 36.2337, 26.4155, 28.2310, 35.6220, 23.7475, 24.8752,\n",
       "                      30.0986, 30.6058, 29.3028, 33.9373, 24.0084, 17.4776, 37.4969, 26.8897,\n",
       "                      28.3172, 25.3929, 52.6782, 35.8204, 26.6360, 30.3232, 22.0726, 23.2046,\n",
       "                      28.6628, 31.7294, 28.4232, 71.8874, 30.3753, 36.1872, 32.7779, 20.3810,\n",
       "                      36.6008, 27.2077, 26.6228, 33.7004, 31.0013, 39.4458, 25.5211, 28.5514,\n",
       "                      27.3939, 35.9915, 47.3533, 24.2785, 27.5994, 26.7256, 32.3722, 23.6999,\n",
       "                      44.7437, 20.3914, 29.0589, 30.9290, 30.0439, 42.6905, 21.7735, 19.9613,\n",
       "                      34.2189, 23.0871, 27.7122, 54.6356, 33.0476, 24.6185, 28.3859, 30.5288,\n",
       "                      19.3636, 42.5879, 58.0678, 32.6522, 30.7632, 38.6345, 24.5900, 40.8139,\n",
       "                      46.2957, 18.5207, 36.4459, 36.5896, 33.1568, 58.8143, 24.0396, 34.3182,\n",
       "                      31.4972, 26.3408, 23.1487, 26.5348, 29.0664, 48.3299, 36.5727, 40.2595,\n",
       "                      37.4076, 24.7873, 25.8084, 23.1316, 22.5564, 46.7772, 27.2196, 22.1269,\n",
       "                      36.8020, 39.7700, 18.9566, 32.5412, 29.2919, 26.9989, 45.4072, 24.0487,\n",
       "                      38.7776, 22.9575, 36.5409, 56.2548, 45.6186, 33.2192, 30.0642, 48.8855,\n",
       "                      33.0645, 35.9916, 34.5097, 25.7109, 45.3243, 44.0962, 19.5515, 38.5437,\n",
       "                      21.7158, 36.5264, 24.9317, 27.0781, 22.3823, 36.3944, 31.8041, 49.8162,\n",
       "                      51.7883, 26.4627, 32.3624, 30.0797, 23.8134, 27.6311, 22.2371, 24.7569,\n",
       "                      37.5263, 20.9947, 34.2509, 24.0898, 38.4275, 21.2586, 36.5223, 31.4922,\n",
       "                      28.8137, 26.6060, 28.5000, 71.3244, 25.4386, 31.9545, 27.8419, 38.1386,\n",
       "                      48.8657, 39.1921, 22.2439, 23.4933, 19.1422, 38.1581, 20.8134, 41.1444,\n",
       "                      30.3871, 31.0478, 30.9974, 19.8697, 69.3665, 36.2296, 32.2209, 21.0971,\n",
       "                      31.6804, 34.3908, 28.9842, 30.9982, 32.6704, 20.7147, 29.5557, 31.8021,\n",
       "                      51.2779, 38.2903, 19.8039, 31.9070, 22.4929, 34.2172, 67.7881, 24.5065,\n",
       "                      55.6093, 62.0512, 42.7110, 30.6897, 18.7367, 28.6554, 27.1599, 41.4407,\n",
       "                      38.1372, 23.4378, 21.6883, 28.3470, 27.4495, 17.5936, 37.5094, 27.1396,\n",
       "                      45.4324, 41.4782, 31.8923, 39.7807, 38.3307, 19.3593, 32.5880, 34.8537,\n",
       "                      42.6391, 28.8964, 22.6873, 39.8586, 29.0280, 22.4451, 30.8644, 24.5672,\n",
       "                      38.3038, 23.9501, 38.0578, 29.7415, 24.0663, 22.7428, 27.1190, 27.6758,\n",
       "                      35.8399, 29.0399, 27.8077, 30.3242, 36.6570, 35.9975, 27.3587, 23.6646,\n",
       "                      32.0264, 23.1784, 18.6961, 36.5868, 31.1183, 20.2115, 31.4105, 28.5849,\n",
       "                      37.7977, 36.1175, 36.8897, 41.4474, 30.4203, 32.8995, 40.9494, 17.6743,\n",
       "                      26.7458, 27.8005, 32.1911, 27.8636, 32.5787, 33.3040, 21.2094, 31.9408,\n",
       "                      54.3808, 23.3577, 18.3323, 24.5694, 28.4776, 42.0893, 37.1440, 21.8503,\n",
       "                      26.4103, 43.7843, 39.6231, 47.5739, 39.1074, 64.6793, 25.0284, 31.4455,\n",
       "                      31.4950, 24.8943, 26.6704, 26.6052, 28.4902, 30.7749, 17.6444, 24.5495,\n",
       "                      30.2374, 17.3323, 39.7233, 31.1259, 22.4827, 34.0907, 28.6546, 23.3526,\n",
       "                      27.1796, 31.0184, 28.6633, 38.8638, 50.0837, 21.1327, 29.4211, 25.0045,\n",
       "                      29.2447, 47.7006, 22.0678, 26.1274, 31.9066, 24.8473, 27.4439, 43.8913,\n",
       "                      39.9272, 38.0480, 22.3449, 34.9515, 28.7615, 18.9932, 34.3281, 50.2100,\n",
       "                      32.8309, 15.9202, 22.6105, 23.7602, 22.5853, 22.7219, 16.8396, 40.8487,\n",
       "                      43.6521, 33.5341, 42.7813, 19.5225, 30.7135, 24.1869, 24.3006, 30.7254,\n",
       "                      18.6366, 25.1730, 20.8230, 16.9395, 28.9191, 36.7133, 33.8733, 30.2471,\n",
       "                      30.5105, 27.5166, 29.0373, 23.0079, 26.2624, 27.7046, 34.9523, 28.3291,\n",
       "                      27.5159, 29.7848, 21.5811, 55.1102, 23.4852, 29.6902, 24.2426, 37.1113,\n",
       "                      33.9425, 19.8402, 20.2245, 59.5771, 27.1462, 30.8568, 30.0256, 31.5152,\n",
       "                      23.2581, 34.6124, 28.5095, 26.3777, 37.9415, 29.0446, 39.0322, 43.6035,\n",
       "                      39.0629, 22.5722, 37.8904, 18.3954, 37.2218, 23.1498, 32.8777, 20.2082,\n",
       "                      47.2572, 40.4569, 32.6515, 16.0758, 33.3119, 28.5473, 44.8569, 40.0255,\n",
       "                      32.4688, 26.0252, 27.1106, 29.4192, 27.2597, 31.0503, 20.3673, 35.7237,\n",
       "                      30.0961, 34.4128, 36.6268, 42.0656, 21.9044, 26.1530, 34.4618, 41.9631,\n",
       "                      36.4876, 30.9963, 32.4118, 19.6388, 27.2226, 33.7977, 52.6224, 24.0947,\n",
       "                      33.0108, 20.6754, 22.1337, 37.4591, 32.3801, 22.0571, 23.7913, 26.2834,\n",
       "                      27.5625, 21.9293, 25.5277, 18.8975, 33.1762, 42.3036, 48.2218, 56.9601,\n",
       "                      37.2746, 34.0892, 50.5791, 20.3249, 41.6217, 21.4690, 32.9879, 36.7006,\n",
       "                      28.5918, 21.4903, 20.2418, 45.5639, 26.3258, 36.4225, 20.4125, 20.1377,\n",
       "                      44.5519, 41.8768, 35.7434, 43.4955, 27.1560, 22.3470, 21.1179, 28.5281,\n",
       "                      26.3375, 30.8784, 24.6512, 40.2385, 27.2700, 34.1388, 15.2446, 25.2072],\n",
       "                     device='cuda:0')),\n",
       "             ('bn1.num_batches_tracked', tensor(17806, device='cuda:0')),\n",
       "             ('linear2.weight',\n",
       "              tensor([[-0.0992,  0.0574,  0.1226,  ...,  0.0822, -0.0450,  0.0755],\n",
       "                      [-0.2091, -0.0999, -0.1129,  ...,  0.0228, -0.0463,  0.0187],\n",
       "                      [-0.0082, -0.0838,  0.0679,  ..., -0.0949, -0.0404,  0.0118],\n",
       "                      ...,\n",
       "                      [-0.1226,  0.0125, -0.0556,  ..., -0.0426, -0.2090, -0.0193],\n",
       "                      [-0.0299, -0.0506, -0.0907,  ...,  0.0959, -0.1623, -0.0257],\n",
       "                      [ 0.0650, -0.0201, -0.0566,  ...,  0.0885, -0.2148, -0.1500]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear2.bias',\n",
       "              tensor([-0.0141,  0.0035,  0.0222,  0.0467,  0.0970, -0.0291, -0.0269,  0.0227,\n",
       "                      -0.0095, -0.0546,  0.0065, -0.0238, -0.0494,  0.0188,  0.0162,  0.0003,\n",
       "                       0.0022,  0.0745, -0.0935,  0.0469,  0.0467,  0.0267,  0.0481, -0.0191,\n",
       "                       0.0053,  0.0310,  0.0625,  0.0129, -0.0129,  0.0748, -0.0514,  0.0875,\n",
       "                       0.0414, -0.0159, -0.0317,  0.0496, -0.0123, -0.0478, -0.0561, -0.0744,\n",
       "                      -0.0704,  0.0655,  0.0412, -0.0007, -0.0197, -0.0104, -0.1069,  0.0188,\n",
       "                      -0.0118, -0.0292,  0.0030, -0.0265, -0.1089,  0.0074, -0.0119,  0.0147,\n",
       "                       0.1574,  0.0672, -0.0827,  0.0160, -0.0200,  0.0140,  0.0286, -0.0390,\n",
       "                      -0.0287,  0.0470,  0.0235, -0.0296, -0.0634, -0.0189,  0.0871, -0.0022,\n",
       "                       0.1089, -0.0520, -0.0371,  0.0526, -0.0810, -0.0724,  0.0227, -0.0027,\n",
       "                       0.0333,  0.0998,  0.0300,  0.0185,  0.0691, -0.0542,  0.1106,  0.0893,\n",
       "                       0.1326,  0.1059,  0.0116,  0.1260, -0.1323, -0.0049, -0.0221,  0.0566,\n",
       "                       0.0243, -0.0177,  0.1130, -0.0053,  0.0920, -0.0215, -0.0065, -0.0063,\n",
       "                      -0.0891,  0.0136,  0.0521, -0.0334, -0.0227,  0.0047,  0.0587,  0.0685,\n",
       "                      -0.0371,  0.0242, -0.0691,  0.0077, -0.1003, -0.0185, -0.0857,  0.0694,\n",
       "                       0.0378,  0.0046,  0.0186, -0.0536, -0.0685,  0.0674,  0.0802, -0.0105,\n",
       "                      -0.0978, -0.0512,  0.0147,  0.0382, -0.0801,  0.1225, -0.0601,  0.0004,\n",
       "                      -0.0468,  0.0483, -0.0039, -0.1012,  0.0396,  0.1109,  0.0708,  0.0003,\n",
       "                       0.0744,  0.1455,  0.0782,  0.1120, -0.0032,  0.0024, -0.0251, -0.0588,\n",
       "                      -0.1408,  0.0629,  0.1815,  0.0406, -0.1346, -0.0560,  0.0925,  0.0967,\n",
       "                      -0.1019,  0.0439,  0.0137, -0.0654, -0.0403, -0.0455,  0.0073,  0.1511,\n",
       "                       0.0576,  0.0049,  0.0791, -0.0678,  0.1081,  0.0616,  0.0138,  0.0489,\n",
       "                       0.0384,  0.0921,  0.0875, -0.0315,  0.0593,  0.0390,  0.1019,  0.1041,\n",
       "                      -0.0313, -0.0511, -0.0341,  0.0595,  0.0352,  0.0085, -0.0032,  0.0261,\n",
       "                       0.0449,  0.0254, -0.0924, -0.0365,  0.0183,  0.0097,  0.0205, -0.0600,\n",
       "                      -0.0755, -0.0282, -0.0859, -0.0171,  0.0397, -0.0193, -0.0950,  0.0598,\n",
       "                       0.0986,  0.0304, -0.0095,  0.0916,  0.0722,  0.0634,  0.0407, -0.0105,\n",
       "                      -0.0357,  0.0298,  0.0361, -0.0149, -0.0794, -0.0124, -0.0225, -0.0312,\n",
       "                       0.0284, -0.0171, -0.1148,  0.0643,  0.0731, -0.0337, -0.1320,  0.0008,\n",
       "                      -0.0401, -0.0559, -0.0318,  0.0155, -0.0938,  0.0433,  0.0900,  0.0522,\n",
       "                      -0.0995,  0.0467, -0.0289, -0.0192,  0.1190,  0.0451, -0.0995,  0.0545,\n",
       "                      -0.0252, -0.0171, -0.0661, -0.0519,  0.0942, -0.0376, -0.0472,  0.0033],\n",
       "                     device='cuda:0')),\n",
       "             ('bn2.weight',\n",
       "              tensor([0.9951, 1.2346, 1.0058, 1.0605, 1.0548, 0.9889, 0.9854, 1.0069, 1.0686,\n",
       "                      0.9215, 1.1194, 1.0949, 1.0054, 0.9169, 1.0122, 1.0960, 1.0485, 1.0198,\n",
       "                      1.1691, 0.9304, 1.1086, 1.0465, 1.1831, 1.2225, 0.9690, 1.0497, 1.0255,\n",
       "                      0.8581, 0.9644, 0.9918, 1.0250, 0.9686, 1.0375, 0.9858, 1.1107, 0.9862,\n",
       "                      0.9395, 1.0395, 1.2440, 1.1126, 1.1501, 1.0612, 1.0969, 0.9310, 1.1055,\n",
       "                      0.9745, 1.2333, 1.0033, 1.1681, 1.0407, 0.8905, 1.0384, 1.0709, 1.1566,\n",
       "                      0.9003, 1.1006, 1.0527, 0.9541, 0.9785, 1.0438, 0.9484, 0.9586, 0.9449,\n",
       "                      1.0253, 1.0452, 1.2018, 1.0435, 1.0656, 1.2379, 1.1623, 0.9825, 0.9764,\n",
       "                      1.1184, 0.9687, 1.1673, 1.0071, 1.0638, 1.0272, 1.0338, 1.0699, 1.0989,\n",
       "                      0.8821, 0.9786, 1.1548, 1.0448, 0.9839, 1.0023, 1.0801, 1.0602, 0.9900,\n",
       "                      0.9270, 0.8869, 1.0484, 1.0267, 0.9671, 0.9936, 1.1428, 1.0607, 1.1961,\n",
       "                      1.0442, 1.0208, 1.0853, 1.1915, 1.0004, 1.1735, 1.0007, 0.9097, 0.9889,\n",
       "                      1.0324, 0.9042, 1.1792, 1.0199, 1.0168, 0.9730, 0.9520, 0.9413, 1.1190,\n",
       "                      1.0305, 1.0332, 0.9637, 1.0940, 1.0365, 0.8810, 1.1104, 1.1175, 1.0077,\n",
       "                      0.9839, 1.1791, 1.0804, 0.9862, 1.0326, 1.0307, 0.8983, 1.2507, 1.0091,\n",
       "                      1.1843, 0.9663, 0.9850, 1.1109, 1.0063, 1.0112, 1.1102, 1.0924, 1.1961,\n",
       "                      1.0484, 1.1620, 0.9997, 0.9757, 1.0213, 0.9348, 0.9969, 1.0439, 1.0880,\n",
       "                      0.9095, 1.0859, 1.0659, 0.9533, 1.2756, 1.0842, 1.0460, 1.1784, 1.2768,\n",
       "                      1.0386, 1.0493, 0.9740, 1.0551, 1.0177, 0.9493, 0.9556, 1.1518, 1.1234,\n",
       "                      0.9096, 0.9901, 0.9927, 1.0676, 1.1045, 0.9752, 1.0820, 1.0353, 1.0309,\n",
       "                      0.9990, 1.1225, 1.0440, 1.1694, 1.1095, 1.0032, 1.0118, 0.9718, 0.9437,\n",
       "                      0.9045, 1.1487, 0.9976, 1.0023, 1.0572, 1.0066, 0.9873, 0.9929, 1.0322,\n",
       "                      1.1164, 1.1550, 0.9246, 1.0647, 0.9965, 1.0997, 0.9783, 1.0749, 1.1866,\n",
       "                      0.9818, 0.9478, 0.9937, 1.0865, 1.0821, 1.1032, 1.0270, 0.9169, 1.1051,\n",
       "                      1.0034, 0.9550, 0.9773, 1.0367, 1.0319, 1.0957, 0.9799, 1.1545, 1.3057,\n",
       "                      1.0719, 1.0272, 1.0360, 1.0066, 1.0959, 1.1422, 0.8732, 0.9938, 1.0888,\n",
       "                      1.1150, 1.0830, 1.1358, 1.0476, 0.9634, 1.2656, 1.0494, 1.1527, 1.0700,\n",
       "                      1.0655, 1.1438, 1.0079, 0.9794, 1.0389, 1.0547, 1.0314, 1.0405, 1.0020,\n",
       "                      1.0289, 0.9952, 1.0408, 0.9446], device='cuda:0')),\n",
       "             ('bn2.bias',\n",
       "              tensor([-9.8756e-02,  8.9547e-02, -1.3587e-01,  3.5417e-02, -1.1450e-01,\n",
       "                      -4.7834e-02, -8.8321e-02,  2.7516e-02, -2.2970e-03,  1.8864e-02,\n",
       "                      -1.3431e-01, -1.0360e-01, -4.8601e-02, -1.1912e-01, -6.6085e-02,\n",
       "                      -2.5144e-02,  7.8103e-02,  9.2239e-02,  2.1865e-02, -2.9483e-02,\n",
       "                      -8.3949e-02, -2.2685e-02,  1.8833e-03, -1.0975e-01, -1.0829e-01,\n",
       "                      -9.8559e-02, -2.0414e-02,  2.0310e-01, -5.4816e-02,  1.6491e-02,\n",
       "                       2.4390e-02, -2.0017e-02, -2.2515e-02, -8.6552e-02,  1.5480e-01,\n",
       "                      -1.2070e-01,  5.8868e-02,  1.3852e-02,  8.0095e-02,  1.0010e-01,\n",
       "                      -3.8512e-02, -2.0247e-02,  1.4694e-01, -5.4688e-02,  9.2012e-02,\n",
       "                      -2.0513e-02,  2.3486e-01, -6.8236e-02, -3.2850e-02, -6.6102e-02,\n",
       "                      -1.6391e-02,  6.0065e-02,  1.1623e-01,  8.3250e-02,  4.7106e-02,\n",
       "                       3.9149e-03, -8.8783e-02, -1.2740e-01,  2.6237e-01,  5.3575e-02,\n",
       "                      -6.2227e-03, -7.0116e-02, -3.0936e-01,  7.5778e-02,  7.9364e-03,\n",
       "                       1.5733e-01, -1.5426e-01,  9.0751e-02,  1.1816e-01, -2.1965e-01,\n",
       "                      -2.1708e-02, -2.1186e-02, -1.0366e-01, -2.1525e-01,  4.9527e-02,\n",
       "                       3.7274e-02,  2.7567e-03, -1.0919e-01,  2.9273e-02, -1.6051e-01,\n",
       "                       3.3002e-02, -1.2823e-01, -1.6385e-01, -7.2514e-02, -1.0821e-03,\n",
       "                       1.9700e-01,  1.5233e-01,  1.6995e-02, -4.9426e-03, -6.0824e-02,\n",
       "                       1.0010e-01, -6.1879e-03, -1.7586e-02,  6.7542e-02, -5.2933e-02,\n",
       "                       1.7790e-01, -2.4762e-03, -9.8034e-02,  2.8340e-02,  2.4900e-02,\n",
       "                       1.3397e-02,  2.8545e-02, -4.6841e-02, -1.3243e-01,  7.1038e-02,\n",
       "                      -2.3505e-02, -6.2361e-02,  1.4963e-03, -1.8089e-01,  5.9092e-02,\n",
       "                       7.9381e-02,  3.4219e-02,  1.6047e-02, -5.7811e-02, -1.8041e-01,\n",
       "                      -9.7416e-02,  1.5791e-01, -4.3672e-02, -1.3329e-01, -2.0811e-01,\n",
       "                      -5.4864e-02,  8.1394e-02,  1.9454e-02,  7.4654e-02,  2.5964e-02,\n",
       "                       5.7884e-02, -9.6827e-02,  1.2281e-01, -3.2817e-02, -1.2148e-01,\n",
       "                      -6.8159e-02, -1.0418e-01, -2.1498e-02,  9.6149e-02, -1.9091e-02,\n",
       "                      -1.3261e-02, -1.3381e-01,  1.1892e-01,  1.1665e-01, -2.4526e-02,\n",
       "                      -1.0422e-02, -2.0681e-02,  5.9380e-04,  3.3921e-02, -5.4370e-02,\n",
       "                       9.5523e-02, -5.8876e-02, -7.2337e-02,  2.2255e-01, -1.2749e-01,\n",
       "                       2.3507e-01, -1.3925e-02,  6.1300e-02, -1.1424e-01,  4.6821e-03,\n",
       "                      -1.1408e-01,  1.6556e-02,  1.5495e-02,  6.0947e-02, -5.6054e-02,\n",
       "                      -8.9925e-02,  1.5213e-01, -1.8430e-01,  1.0514e-01, -4.9372e-02,\n",
       "                      -7.1079e-02,  3.2902e-02, -5.8565e-02, -2.1572e-02, -8.9081e-05,\n",
       "                      -4.5087e-02, -6.8840e-02,  3.4821e-02, -9.0800e-02, -4.3510e-02,\n",
       "                       1.2778e-01,  1.7058e-01, -6.0518e-02, -2.0886e-01, -1.7783e-01,\n",
       "                      -8.6750e-02, -4.8585e-03,  1.1163e-01,  7.9796e-02,  8.2798e-02,\n",
       "                      -2.6601e-02, -5.4875e-02, -1.8814e-02,  1.2663e-01,  2.2857e-02,\n",
       "                       2.2964e-02, -1.4234e-01,  1.9109e-02, -3.6594e-02,  7.9166e-03,\n",
       "                       7.7212e-02, -1.1567e-01, -1.2581e-01,  1.4014e-01,  3.4464e-02,\n",
       "                      -7.3983e-02, -9.3652e-02, -1.0433e-01,  2.7484e-02,  1.4431e-02,\n",
       "                       1.3250e-01,  1.0409e-01, -1.5255e-01, -3.6355e-03, -3.2824e-02,\n",
       "                       7.1545e-02,  5.6391e-02, -1.3062e-01, -6.8772e-03, -9.4503e-02,\n",
       "                       8.6861e-02,  7.0947e-02, -2.9493e-02, -5.6855e-02, -9.7153e-02,\n",
       "                       4.0782e-02, -5.8910e-02, -1.8133e-02, -8.7329e-03,  1.7240e-01,\n",
       "                      -1.2785e-01,  1.2337e-01, -8.6915e-02, -1.6821e-02,  5.3749e-02,\n",
       "                      -6.4829e-03, -9.3585e-02,  8.1413e-02,  1.9894e-01,  1.1106e-01,\n",
       "                       1.0927e-01,  1.3972e-01, -1.6829e-01, -6.7189e-02,  2.4015e-01,\n",
       "                       6.4107e-03,  3.3836e-02,  8.7302e-02,  2.1000e-02, -1.0590e-02,\n",
       "                      -1.3033e-01, -1.0875e-01, -5.5609e-02, -7.5374e-02, -6.5388e-02,\n",
       "                       1.9275e-01, -1.3028e-01,  2.7706e-01, -8.8777e-02,  7.4779e-02,\n",
       "                       1.0727e-01], device='cuda:0')),\n",
       "             ('bn2.running_mean',\n",
       "              tensor([-1.3178e+00,  4.6027e-01, -1.7524e+00,  2.6967e+00, -6.4816e-01,\n",
       "                      -4.0282e-01,  4.9003e-01, -6.6817e-02, -1.2814e+00,  4.2137e-01,\n",
       "                       1.2785e+00, -2.5668e+00, -9.2930e-01, -1.3026e+00, -1.5263e+00,\n",
       "                      -1.3825e+00,  1.4212e+00, -9.0912e-02,  1.2875e+00,  1.5141e+00,\n",
       "                      -1.1573e+00, -5.0673e-01,  1.3644e-01,  8.0501e-01,  4.0437e-02,\n",
       "                      -1.2893e+00, -4.9939e-01,  3.8126e+00, -2.2313e+00,  4.4703e-01,\n",
       "                       1.4612e+00,  1.6567e+00, -5.1399e-01, -1.6091e+00,  3.3167e-01,\n",
       "                       5.0952e-01,  7.0038e-01, -4.0239e-01,  1.3356e+00,  1.8119e+00,\n",
       "                      -1.0145e+00, -1.0850e+00,  2.8643e-01,  2.3809e-01, -3.9454e-01,\n",
       "                      -7.0438e-01,  8.9470e-01, -6.6814e-01,  1.0018e+00, -1.9803e+00,\n",
       "                      -2.4593e+00,  1.7993e+00,  3.0234e+00,  1.4598e+00,  1.0260e+00,\n",
       "                      -1.8677e+00, -9.8258e-01,  7.4395e-01, -6.8416e-02,  7.3017e-01,\n",
       "                      -7.7126e-01,  1.4362e+00,  7.7642e-02, -2.1723e+00,  2.8998e-01,\n",
       "                       2.6344e+00, -1.3200e+00,  3.8226e+00, -3.2471e-01, -3.7649e-01,\n",
       "                       7.8090e-01, -2.0633e-01, -9.5132e-01, -2.7157e-01, -6.3044e-01,\n",
       "                      -9.5932e-01, -1.8681e-01, -1.2148e+00, -8.2347e-01, -3.3494e+00,\n",
       "                      -1.0263e+00, -1.0650e+00, -2.3971e+00, -2.7180e+00,  4.7298e-01,\n",
       "                       3.1469e+00,  2.8959e+00, -1.1821e+00,  1.0652e+00, -2.1404e+00,\n",
       "                       9.0950e-01,  6.1119e-01, -1.9164e+00, -1.5009e-02, -2.3978e+00,\n",
       "                       1.2038e+00,  1.0087e+00, -4.2754e+00, -1.8971e+00,  1.0071e+00,\n",
       "                      -4.0472e-02,  2.2369e+00, -2.9061e+00, -3.7679e-01,  9.1543e-01,\n",
       "                       7.7322e-02, -1.0660e+00,  6.8849e-01, -1.0485e+00,  2.4517e+00,\n",
       "                       1.6773e-01,  1.4132e-01, -9.2798e-01, -2.8072e+00, -2.0568e+00,\n",
       "                       8.2009e-01,  1.7007e+00, -6.2057e-01, -2.9077e+00, -9.3700e-01,\n",
       "                      -6.8470e-01,  1.3010e+00,  9.0705e-01,  1.1773e-01, -8.5031e-01,\n",
       "                       1.0187e+00, -2.9258e+00,  3.6282e-01, -1.2103e+00, -2.0300e+00,\n",
       "                      -2.2106e+00, -2.7911e+00,  1.2295e+00,  2.4583e+00, -1.9247e+00,\n",
       "                      -7.1587e-01, -2.5703e+00,  1.8882e+00,  1.2919e-01, -1.5125e-01,\n",
       "                      -6.5937e-01,  6.4004e-01, -2.9679e-01,  3.5783e-02, -5.0112e-01,\n",
       "                      -1.9201e+00,  2.4016e+00, -5.5496e-01,  3.8250e-02,  1.1564e-01,\n",
       "                      -2.2747e-03, -3.2857e+00, -1.3068e-02, -5.9401e-01, -1.1120e+00,\n",
       "                      -3.8153e+00,  7.9603e-01, -2.5860e-01,  2.8570e-01, -2.7497e+00,\n",
       "                      -1.0933e+00,  2.0920e+00, -2.2044e-01,  1.8538e+00, -5.5613e-01,\n",
       "                      -2.5829e-01,  3.6562e+00,  9.8754e-01,  1.2353e+00, -1.7386e+00,\n",
       "                      -3.1066e-01,  2.1823e-01,  1.3959e+00, -3.6254e+00, -9.8541e-02,\n",
       "                      -3.0301e-01, -9.2731e-01, -3.1775e+00, -2.4951e+00, -1.5945e+00,\n",
       "                      -3.9889e-01, -3.2625e-01,  8.7100e-01,  6.0440e-01,  1.0980e+00,\n",
       "                       5.8794e-02,  2.7795e+00, -9.8785e-01,  1.2806e+00,  1.7380e+00,\n",
       "                      -8.3048e-01,  1.1784e+00,  2.9209e+00,  2.1431e+00, -3.4389e-01,\n",
       "                       6.6683e-01, -1.7971e+00, -1.6215e+00, -9.2911e-01,  1.3720e+00,\n",
       "                       1.3090e+00, -1.4361e+00,  6.1384e-02, -6.2885e-01,  1.7510e-01,\n",
       "                       8.5115e-01,  5.9038e-01, -8.0458e-01, -4.2153e-01, -1.3651e+00,\n",
       "                       1.2652e-01,  1.5205e+00, -3.0610e-02, -1.2086e+00, -3.1521e-01,\n",
       "                       4.9643e-01,  2.8224e+00,  2.1368e+00, -4.2176e-01, -2.3192e+00,\n",
       "                       1.4993e+00, -6.8897e-01, -8.4199e-01,  2.1256e+00,  9.7687e-01,\n",
       "                      -6.4895e-02,  9.1944e-01,  1.1835e+00, -3.6327e-01,  1.2480e-01,\n",
       "                      -5.3222e-02, -2.2150e-01, -3.9591e-01,  1.0193e+00,  7.8013e-01,\n",
       "                       3.2900e-01,  1.0265e+00, -4.7076e+00, -1.1646e+00,  1.6554e+00,\n",
       "                       5.2868e-01,  6.0715e-01, -1.1667e+00, -1.5989e+00,  1.1115e+00,\n",
       "                      -2.2054e+00, -2.7385e+00,  3.8703e-01, -2.9876e+00, -1.0051e+00,\n",
       "                       3.1822e+00, -6.1060e-01,  3.4953e+00,  7.4546e-01,  2.0980e-01,\n",
       "                       1.4081e+00], device='cuda:0')),\n",
       "             ('bn2.running_var',\n",
       "              tensor([19.6700, 26.6306, 25.6866, 29.8884, 21.3561, 26.6800, 29.8265, 30.6175,\n",
       "                      25.6175, 24.5944, 32.5674, 26.3427, 25.8135, 26.7021, 26.2177, 27.5501,\n",
       "                      28.9298, 26.6758, 24.6897, 31.1226, 26.2953, 24.9018, 22.9513, 34.5734,\n",
       "                      26.3210, 27.0706, 25.8641, 26.3708, 28.4302, 27.4867, 23.4760, 28.2733,\n",
       "                      29.5361, 23.9665, 28.4886, 24.4059, 40.4725, 24.1317, 32.2570, 28.3764,\n",
       "                      29.3066, 31.7895, 29.2520, 29.0921, 33.6168, 24.7449, 28.3015, 26.2683,\n",
       "                      27.1710, 27.5366, 26.4729, 35.5962, 29.4304, 30.8148, 28.3783, 26.2795,\n",
       "                      27.6135, 26.8659, 31.2026, 35.8570, 20.5905, 25.6943, 24.6676, 25.1376,\n",
       "                      26.2457, 27.2997, 29.7279, 27.9015, 32.6962, 34.0078, 31.1462, 28.1612,\n",
       "                      26.8515, 28.4395, 30.3656, 24.5705, 26.0115, 25.6627, 25.5591, 28.9180,\n",
       "                      24.7431, 22.3947, 25.4534, 26.9334, 25.8903, 23.8032, 26.8951, 33.6800,\n",
       "                      21.4142, 20.6424, 25.5079, 23.2544, 34.4838, 23.3172, 34.8130, 29.2713,\n",
       "                      31.5210, 37.6890, 31.6453, 30.3871, 27.8683, 26.9775, 33.1239, 23.7880,\n",
       "                      31.2184, 22.8945, 21.9576, 20.9937, 27.6305, 37.0340, 33.0194, 26.0072,\n",
       "                      33.6895, 20.0173, 25.1033, 21.7059, 29.7529, 26.4762, 30.1998, 25.1852,\n",
       "                      30.5382, 29.1881, 21.2890, 27.6270, 32.1456, 21.9367, 30.7375, 26.2433,\n",
       "                      24.9437, 31.8755, 31.9123, 31.0686, 27.0795, 40.7593, 29.4100, 28.8914,\n",
       "                      29.6131, 28.8183, 26.8952, 29.7832, 34.2471, 19.4197, 28.1549, 35.5314,\n",
       "                      28.6451, 29.0963, 27.9621, 29.8063, 31.3093, 25.9450, 24.8389, 32.1157,\n",
       "                      26.6913, 24.9906, 24.7639, 32.5087, 34.9516, 36.1793, 35.8754, 31.7225,\n",
       "                      31.5672, 30.4069, 24.0816, 27.9841, 26.0405, 27.3236, 28.0370, 30.2717,\n",
       "                      29.5595, 33.3203, 24.4246, 20.3965, 27.0277, 30.0806, 24.6909, 31.4730,\n",
       "                      28.4801, 29.4517, 29.8910, 26.2081, 28.9934, 28.0767, 29.3796, 29.3569,\n",
       "                      33.1196, 24.9272, 26.0261, 22.7019, 29.0633, 26.2308, 29.8501, 25.3762,\n",
       "                      25.4888, 27.8247, 26.6954, 24.2909, 28.0637, 27.6434, 26.0185, 33.2320,\n",
       "                      22.4742, 23.9859, 25.6436, 25.7338, 25.1908, 27.3333, 27.9297, 28.8523,\n",
       "                      25.6656, 27.8656, 25.2194, 24.6448, 27.6231, 25.2608, 26.4595, 27.0731,\n",
       "                      34.9616, 27.3039, 23.6739, 22.8734, 27.3011, 30.8686, 33.9254, 26.9422,\n",
       "                      31.5722, 29.9832, 38.8483, 28.2561, 26.6948, 33.6738, 27.1839, 24.8720,\n",
       "                      23.1604, 34.9719, 28.6486, 33.2135, 29.9220, 36.5775, 33.1782, 30.3672,\n",
       "                      34.2677, 31.3196, 35.7768, 28.7924, 34.1423, 31.3697, 24.4444, 31.8477,\n",
       "                      29.2252, 26.3467, 30.1744, 29.5862, 32.0560, 28.8393, 26.1652, 35.6827],\n",
       "                     device='cuda:0')),\n",
       "             ('bn2.num_batches_tracked', tensor(17806, device='cuda:0')),\n",
       "             ('linear3.weight',\n",
       "              tensor([[-0.0398,  0.0653, -0.1016,  ..., -0.5259,  0.1518, -0.3990],\n",
       "                      [-0.3598, -0.3835,  0.1496,  ..., -0.3079,  0.0748, -0.4195],\n",
       "                      [ 0.1104,  0.0904,  0.0701,  ..., -0.3964,  0.1246, -0.4256],\n",
       "                      ...,\n",
       "                      [ 0.0411, -0.2117,  0.0206,  ...,  0.0464, -0.1588,  0.0490],\n",
       "                      [-0.1374, -0.4110, -0.5244,  ...,  0.0708, -0.0474,  0.0118],\n",
       "                      [-0.1239, -0.4271, -0.2385,  ...,  0.0734,  0.0436, -0.0023]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear3.bias',\n",
       "              tensor([-0.2698,  0.1405, -0.0837, -0.2915, -0.0390,  0.1571, -0.2494, -0.1596,\n",
       "                      -0.2316, -0.3657,  0.0123,  0.1655, -0.0896,  0.1005,  0.2425, -0.4258,\n",
       "                       0.2388, -0.2525, -0.0525,  0.1958, -0.2442, -0.0132, -0.0242,  0.0981,\n",
       "                       0.0801,  0.0664, -0.0045,  0.0808,  0.0073,  0.1269, -0.1082,  0.0510,\n",
       "                       0.1029, -0.0693,  0.2115, -0.2506, -0.0013,  0.1681,  0.0735,  0.0850],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"../pyDort/representation/point_cloud_models/ckpts/pointnet_model.t7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7b47dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDort.representation.point_cloud_models.pointnets import PointNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c1fbc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointNetClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a0268d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../pyDort/representation/point_cloud_models/ckpts/pointnet_model.t7\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67a486bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand((20, 3, 30), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2da31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba44050c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "740af946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ae47892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (\"s\", \"p\", \"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "35e03974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(s, p, k):\n",
    "    return s, p, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f4db3eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d58d49fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[3.08680594e-01, 5.34805655e-01, 4.06700492e-01, ...,\n",
       "          9.45859551e-02, 5.29216528e-02, 2.39325285e-01],\n",
       "         [9.84572053e-01, 8.71834517e-01, 7.02013969e-01, ...,\n",
       "          5.61568141e-02, 6.14163280e-01, 7.33017087e-01],\n",
       "         [4.45285916e-01, 6.02182806e-01, 8.01640034e-01, ...,\n",
       "          4.65211987e-01, 1.73826575e-01, 8.43264103e-01],\n",
       "         ...,\n",
       "         [3.85945141e-01, 6.76034451e-01, 9.23705697e-02, ...,\n",
       "          1.84198260e-01, 6.29604816e-01, 9.31230366e-01],\n",
       "         [1.27181172e-01, 2.41804719e-02, 2.83106267e-01, ...,\n",
       "          2.85246611e-01, 6.36413813e-01, 6.36086524e-01],\n",
       "         [6.57436788e-01, 9.52582657e-01, 5.82556725e-01, ...,\n",
       "          3.66612256e-01, 2.73775578e-01, 4.29188848e-01]],\n",
       "\n",
       "        [[6.64741695e-01, 4.94661927e-01, 6.74821734e-02, ...,\n",
       "          5.35973310e-01, 6.13836944e-01, 4.54138398e-01],\n",
       "         [8.21121454e-01, 9.98733699e-01, 2.29509532e-01, ...,\n",
       "          6.64414227e-01, 2.84086049e-01, 2.56884098e-02],\n",
       "         [6.75252140e-01, 8.81890714e-01, 2.89471328e-01, ...,\n",
       "          1.50372744e-01, 8.29591691e-01, 8.43690872e-01],\n",
       "         ...,\n",
       "         [9.81118262e-01, 8.89312029e-01, 1.11296833e-01, ...,\n",
       "          3.50877464e-01, 1.41866326e-01, 2.17115641e-01],\n",
       "         [3.53243172e-01, 4.04771268e-01, 5.04992068e-01, ...,\n",
       "          2.94586957e-01, 8.89517307e-01, 9.03106987e-01],\n",
       "         [9.05065536e-02, 2.15214968e-01, 5.04798055e-01, ...,\n",
       "          7.29758501e-01, 8.36893380e-01, 6.88119173e-01]],\n",
       "\n",
       "        [[1.07065558e-01, 9.73199964e-01, 2.92924285e-01, ...,\n",
       "          6.04883194e-01, 1.07034206e-01, 1.41815126e-01],\n",
       "         [8.49480093e-01, 8.91174316e-01, 1.13444090e-01, ...,\n",
       "          2.30820954e-01, 7.29549110e-01, 2.22880721e-01],\n",
       "         [5.04516840e-01, 6.10585868e-01, 3.82347703e-02, ...,\n",
       "          6.25147760e-01, 6.07174933e-01, 1.15004420e-01],\n",
       "         ...,\n",
       "         [9.26472366e-01, 6.60716295e-02, 7.83901930e-01, ...,\n",
       "          8.60574961e-01, 1.11464977e-01, 7.34524786e-01],\n",
       "         [1.39464676e-01, 8.40286434e-01, 6.22465611e-01, ...,\n",
       "          7.41870999e-01, 8.18902016e-01, 2.08180845e-01],\n",
       "         [9.58402276e-01, 5.29553533e-01, 6.39341354e-01, ...,\n",
       "          2.14857280e-01, 8.02214146e-01, 8.07242215e-01]]],\n",
       "\n",
       "\n",
       "       [[[3.60097468e-01, 7.19395041e-01, 2.16760635e-01, ...,\n",
       "          4.88467515e-01, 1.47703409e-01, 7.82537937e-01],\n",
       "         [6.26647472e-02, 5.49788356e-01, 4.71688986e-01, ...,\n",
       "          7.80199587e-01, 4.66232717e-01, 2.84015059e-01],\n",
       "         [1.06683791e-01, 4.41629827e-01, 8.79952788e-01, ...,\n",
       "          7.89671779e-01, 4.60846663e-01, 2.08839417e-01],\n",
       "         ...,\n",
       "         [7.89618671e-01, 8.21463823e-01, 6.74653053e-02, ...,\n",
       "          4.99933541e-01, 7.15196133e-04, 1.70312822e-01],\n",
       "         [9.33853686e-01, 6.13562703e-01, 2.99678445e-02, ...,\n",
       "          5.30519366e-01, 4.03461397e-01, 4.48556602e-01],\n",
       "         [8.91999662e-01, 5.35440803e-01, 4.08139229e-02, ...,\n",
       "          5.56363046e-01, 5.64404070e-01, 8.99732053e-01]],\n",
       "\n",
       "        [[2.04691887e-01, 2.76859224e-01, 4.22047913e-01, ...,\n",
       "          5.38445413e-01, 5.67498803e-02, 1.82607174e-02],\n",
       "         [4.11591530e-01, 8.79181623e-02, 9.94447291e-01, ...,\n",
       "          7.94417322e-01, 6.47462606e-02, 3.31854403e-01],\n",
       "         [8.67351711e-01, 4.50002313e-01, 7.07083702e-01, ...,\n",
       "          5.56897938e-01, 9.46878910e-01, 3.99529517e-01],\n",
       "         ...,\n",
       "         [6.57635212e-01, 1.77399755e-01, 4.66108918e-01, ...,\n",
       "          2.72103190e-01, 4.97110307e-01, 5.66508591e-01],\n",
       "         [7.66904294e-01, 4.36148226e-01, 5.18996596e-01, ...,\n",
       "          8.36591780e-01, 2.61904120e-01, 5.14275432e-02],\n",
       "         [7.96199262e-01, 1.67141438e-01, 6.13049984e-01, ...,\n",
       "          4.41400647e-01, 5.50787985e-01, 9.95780528e-01]],\n",
       "\n",
       "        [[3.10963988e-02, 5.46365380e-01, 5.23318529e-01, ...,\n",
       "          6.55718684e-01, 6.97653949e-01, 8.24376643e-01],\n",
       "         [9.83446121e-01, 8.55295360e-01, 2.29189157e-01, ...,\n",
       "          6.33886576e-01, 4.13575768e-02, 8.64633977e-01],\n",
       "         [4.62830663e-01, 2.09205747e-01, 8.27468514e-01, ...,\n",
       "          2.42996633e-01, 4.87878323e-01, 7.91444659e-01],\n",
       "         ...,\n",
       "         [6.64899051e-01, 8.92649293e-01, 9.04511511e-01, ...,\n",
       "          7.13183224e-01, 2.82309055e-02, 8.65031660e-01],\n",
       "         [2.07673132e-01, 4.14583325e-01, 4.29038286e-01, ...,\n",
       "          9.43971217e-01, 5.65304101e-01, 8.87374580e-01],\n",
       "         [5.73941529e-01, 1.74182594e-01, 2.80317128e-01, ...,\n",
       "          8.43934000e-01, 1.45946145e-02, 7.62600005e-01]]],\n",
       "\n",
       "\n",
       "       [[[7.27399588e-02, 9.52659011e-01, 6.02806270e-01, ...,\n",
       "          7.85420835e-01, 5.82974076e-01, 2.96914935e-01],\n",
       "         [3.25214446e-01, 5.77410877e-01, 9.51524377e-02, ...,\n",
       "          3.74700129e-01, 6.61175549e-01, 6.64612651e-02],\n",
       "         [1.87014401e-01, 7.80472755e-01, 9.14771318e-01, ...,\n",
       "          4.33700144e-01, 9.92750704e-01, 5.45993030e-01],\n",
       "         ...,\n",
       "         [8.96706581e-01, 3.27060342e-01, 7.83943355e-01, ...,\n",
       "          9.05305922e-01, 3.22589636e-01, 2.37716615e-01],\n",
       "         [2.98952281e-01, 6.59215450e-02, 9.00649607e-01, ...,\n",
       "          1.05907321e-01, 4.72855330e-01, 3.63833785e-01],\n",
       "         [9.73802567e-01, 2.24186003e-01, 9.00744617e-01, ...,\n",
       "          6.51052058e-01, 4.36247885e-01, 8.03837717e-01]],\n",
       "\n",
       "        [[3.49819124e-01, 4.75729048e-01, 5.05205393e-02, ...,\n",
       "          8.91849577e-01, 9.03238893e-01, 5.56558609e-01],\n",
       "         [2.11623073e-01, 3.13901305e-02, 6.90710723e-01, ...,\n",
       "          6.28878891e-01, 9.02803063e-01, 7.41161227e-01],\n",
       "         [3.16474497e-01, 1.58499002e-01, 4.51821923e-01, ...,\n",
       "          4.13825512e-02, 7.05196202e-01, 2.28872299e-02],\n",
       "         ...,\n",
       "         [7.11444557e-01, 3.02173615e-01, 3.33395720e-01, ...,\n",
       "          4.53144372e-01, 6.98678136e-01, 7.86424220e-01],\n",
       "         [7.74807572e-01, 4.39179361e-01, 8.50038886e-01, ...,\n",
       "          7.24635303e-01, 8.00551772e-01, 4.44044828e-01],\n",
       "         [6.37727678e-01, 4.09447849e-01, 3.53840113e-01, ...,\n",
       "          3.79358709e-01, 3.16112757e-01, 5.21174252e-01]],\n",
       "\n",
       "        [[3.35067451e-01, 2.48314440e-01, 5.92721999e-01, ...,\n",
       "          6.28164172e-01, 5.89037836e-01, 6.60545468e-01],\n",
       "         [9.45457041e-01, 1.36599302e-01, 6.59931242e-01, ...,\n",
       "          6.34467363e-01, 6.77047133e-01, 6.46432459e-01],\n",
       "         [1.38990223e-01, 7.44165063e-01, 8.56433213e-01, ...,\n",
       "          5.58973312e-01, 7.91052759e-01, 2.01048791e-01],\n",
       "         ...,\n",
       "         [7.56303787e-01, 3.95326376e-01, 6.83392107e-01, ...,\n",
       "          2.19974279e-01, 5.22963941e-01, 1.22425318e-01],\n",
       "         [9.10062850e-01, 3.55740309e-01, 6.51116550e-01, ...,\n",
       "          2.75725842e-01, 8.96849036e-02, 5.88618279e-01],\n",
       "         [8.22748721e-01, 6.68440521e-01, 5.73458254e-01, ...,\n",
       "          8.38894844e-01, 3.76215458e-01, 1.40820324e-01]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[2.06579328e-01, 2.64373839e-01, 6.93222582e-01, ...,\n",
       "          4.85378921e-01, 8.62375975e-01, 6.04307652e-03],\n",
       "         [5.81577361e-01, 5.94674408e-01, 6.46774292e-01, ...,\n",
       "          5.22269130e-01, 6.63059413e-01, 2.45652914e-01],\n",
       "         [2.28880823e-01, 8.22688699e-01, 8.55445981e-01, ...,\n",
       "          2.27382123e-01, 4.57123339e-01, 2.19503403e-01],\n",
       "         ...,\n",
       "         [8.86026263e-01, 5.00792265e-02, 5.76865137e-01, ...,\n",
       "          9.53728497e-01, 5.65961778e-01, 7.02015400e-01],\n",
       "         [4.59835231e-01, 4.64118540e-01, 9.97940898e-01, ...,\n",
       "          3.71786892e-01, 3.48064303e-02, 2.27239549e-01],\n",
       "         [4.77254510e-01, 4.44816828e-01, 5.11164665e-01, ...,\n",
       "          4.73133326e-02, 7.46710122e-01, 5.90087473e-01]],\n",
       "\n",
       "        [[3.65044951e-01, 4.88065958e-01, 1.18968844e-01, ...,\n",
       "          7.35141695e-01, 9.70093906e-01, 8.86276186e-01],\n",
       "         [3.61043155e-01, 2.99213409e-01, 7.96572983e-01, ...,\n",
       "          7.59061813e-01, 1.40876472e-01, 3.43012333e-01],\n",
       "         [6.82896197e-01, 2.46237516e-02, 4.16135252e-01, ...,\n",
       "          5.13905346e-01, 7.74653375e-01, 1.44842267e-02],\n",
       "         ...,\n",
       "         [2.48822689e-01, 9.34422612e-02, 4.30276096e-01, ...,\n",
       "          2.49113977e-01, 3.34150195e-01, 9.96227860e-01],\n",
       "         [7.80646205e-01, 6.50152147e-01, 4.68660116e-01, ...,\n",
       "          9.60525274e-01, 9.04280543e-02, 1.72439516e-01],\n",
       "         [1.25346124e-01, 1.58166111e-01, 8.97972345e-01, ...,\n",
       "          8.46753120e-02, 5.07496953e-01, 9.10547495e-01]],\n",
       "\n",
       "        [[3.35554779e-01, 8.06398988e-02, 2.32926607e-02, ...,\n",
       "          1.47630215e-01, 6.57919943e-01, 3.91933024e-01],\n",
       "         [6.39547110e-02, 1.27668679e-01, 4.16036785e-01, ...,\n",
       "          9.61141765e-01, 6.43844545e-01, 3.73123467e-01],\n",
       "         [2.02180684e-01, 3.19633126e-01, 1.54030502e-01, ...,\n",
       "          9.48750854e-01, 9.06172395e-01, 4.18349683e-01],\n",
       "         ...,\n",
       "         [8.91119838e-02, 6.88425899e-01, 7.71209359e-01, ...,\n",
       "          1.05060995e-01, 3.56945693e-01, 2.81581879e-01],\n",
       "         [3.71276557e-01, 4.24569845e-01, 7.17732012e-01, ...,\n",
       "          7.94409275e-01, 6.66215837e-01, 7.78570175e-01],\n",
       "         [5.08554816e-01, 7.23099709e-03, 7.21460342e-01, ...,\n",
       "          8.77849519e-01, 8.46899867e-01, 9.33720648e-01]]],\n",
       "\n",
       "\n",
       "       [[[7.48275936e-01, 9.83762383e-01, 2.55354047e-02, ...,\n",
       "          5.47810197e-02, 3.78141701e-01, 2.69841015e-01],\n",
       "         [3.95129979e-01, 6.43223882e-01, 9.61271763e-01, ...,\n",
       "          1.49139345e-01, 6.31802559e-01, 6.04226053e-01],\n",
       "         [9.87480819e-01, 4.32363093e-01, 1.61277831e-01, ...,\n",
       "          8.02276433e-01, 2.81558812e-01, 9.22826529e-01],\n",
       "         ...,\n",
       "         [5.22155941e-01, 8.67277086e-01, 2.77550519e-01, ...,\n",
       "          9.71083939e-01, 3.63223255e-01, 4.75192785e-01],\n",
       "         [1.15025699e-01, 8.90054405e-01, 8.14340532e-01, ...,\n",
       "          6.44948125e-01, 7.55577624e-01, 1.48721874e-01],\n",
       "         [2.69016445e-01, 7.63736725e-01, 7.62710571e-02, ...,\n",
       "          4.75139380e-01, 9.86750305e-01, 4.56548810e-01]],\n",
       "\n",
       "        [[6.64433420e-01, 9.18527961e-01, 1.68271065e-02, ...,\n",
       "          2.79630065e-01, 4.17962015e-01, 5.76943159e-02],\n",
       "         [5.06228149e-01, 5.31543732e-01, 1.57074332e-01, ...,\n",
       "          6.27217829e-01, 4.37466264e-01, 5.05235136e-01],\n",
       "         [8.56217206e-01, 6.61922812e-01, 1.39090121e-01, ...,\n",
       "          2.76768148e-01, 3.67371917e-01, 7.28144944e-01],\n",
       "         ...,\n",
       "         [8.26502144e-01, 3.36751461e-01, 6.61732197e-01, ...,\n",
       "          6.09483480e-01, 1.04546547e-01, 2.50060797e-01],\n",
       "         [4.20609117e-02, 5.51258802e-01, 7.08255470e-01, ...,\n",
       "          9.50076640e-01, 2.23621964e-01, 4.87282991e-01],\n",
       "         [3.21526408e-01, 1.02816701e-01, 6.97130263e-01, ...,\n",
       "          2.68149972e-02, 6.64107144e-01, 9.20418501e-02]],\n",
       "\n",
       "        [[7.95866430e-01, 8.64633024e-01, 7.45080709e-02, ...,\n",
       "          9.88183022e-02, 9.18149352e-02, 2.02636480e-01],\n",
       "         [9.16087449e-01, 8.16448331e-02, 3.42953801e-01, ...,\n",
       "          6.27421737e-01, 6.47970319e-01, 7.11016655e-02],\n",
       "         [7.61286616e-01, 4.55639124e-01, 6.55666709e-01, ...,\n",
       "          5.07305622e-01, 2.61200070e-02, 4.93712008e-01],\n",
       "         ...,\n",
       "         [9.94256377e-01, 6.17432356e-01, 2.03265786e-01, ...,\n",
       "          4.14408445e-02, 2.09659338e-01, 3.32731009e-01],\n",
       "         [9.04930830e-01, 8.53665113e-01, 4.04944837e-01, ...,\n",
       "          3.58262122e-01, 5.62668741e-01, 6.97188973e-02],\n",
       "         [8.73301089e-01, 2.60202169e-01, 6.87872708e-01, ...,\n",
       "          3.31817269e-02, 8.25702667e-01, 3.18746030e-01]]],\n",
       "\n",
       "\n",
       "       [[[5.58247745e-01, 3.19881022e-01, 5.94800949e-01, ...,\n",
       "          8.61054718e-01, 2.87540257e-01, 5.72145045e-01],\n",
       "         [6.17767990e-01, 3.97423804e-01, 2.09810376e-01, ...,\n",
       "          5.49974442e-01, 5.14682531e-01, 3.01983237e-01],\n",
       "         [6.26466632e-01, 5.70929527e-01, 1.45660758e-01, ...,\n",
       "          2.45071113e-01, 6.68108642e-01, 2.32668817e-01],\n",
       "         ...,\n",
       "         [5.72947741e-01, 8.89182091e-01, 1.78952515e-01, ...,\n",
       "          2.96413898e-04, 7.73635983e-01, 4.15017486e-01],\n",
       "         [7.51536071e-01, 6.19980335e-01, 2.66460061e-01, ...,\n",
       "          1.26215637e-01, 2.85340369e-01, 5.80043077e-01],\n",
       "         [7.45627224e-01, 4.51747954e-01, 7.72259653e-01, ...,\n",
       "          3.74665260e-02, 4.21398342e-01, 9.15142953e-01]],\n",
       "\n",
       "        [[9.05373812e-01, 9.37873960e-01, 7.59107828e-01, ...,\n",
       "          5.30645013e-01, 8.04605722e-01, 6.31314516e-02],\n",
       "         [3.36721599e-01, 6.00205243e-01, 8.14908803e-01, ...,\n",
       "          4.67616379e-01, 9.67615068e-01, 9.08058882e-02],\n",
       "         [9.48368132e-01, 9.91944551e-01, 1.20561123e-02, ...,\n",
       "          3.12574625e-01, 9.26309824e-01, 4.72928464e-01],\n",
       "         ...,\n",
       "         [3.86651337e-01, 7.57925034e-01, 1.24914467e-01, ...,\n",
       "          3.12908292e-01, 3.07456732e-01, 7.39009023e-01],\n",
       "         [5.87303281e-01, 3.41226101e-01, 8.29510212e-01, ...,\n",
       "          2.84344018e-01, 8.01634967e-01, 9.04340923e-01],\n",
       "         [4.61063206e-01, 4.77034867e-01, 3.47210765e-02, ...,\n",
       "          8.54204416e-01, 5.60637116e-01, 5.29496551e-01]],\n",
       "\n",
       "        [[5.21061063e-01, 5.95600724e-01, 9.90404487e-02, ...,\n",
       "          7.87002981e-01, 9.58633542e-01, 3.66659701e-01],\n",
       "         [1.55268312e-01, 7.14681149e-02, 8.24530423e-01, ...,\n",
       "          4.38208818e-01, 7.38885760e-01, 6.13134325e-01],\n",
       "         [6.62879765e-01, 9.99319553e-02, 9.91468489e-01, ...,\n",
       "          2.14262605e-01, 1.09187245e-01, 5.20199001e-01],\n",
       "         ...,\n",
       "         [4.20305014e-01, 7.50304461e-01, 7.30637193e-01, ...,\n",
       "          7.28672445e-01, 8.10523272e-01, 2.84403801e-01],\n",
       "         [3.78164411e-01, 4.89055336e-01, 2.83882916e-01, ...,\n",
       "          4.54597831e-01, 8.81716013e-01, 6.61477447e-02],\n",
       "         [9.20128882e-01, 2.28628874e-01, 6.88109398e-01, ...,\n",
       "          9.15777862e-01, 1.85372531e-01, 6.40194654e-01]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c35a7eb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Sequential:\n\tMissing key(s) in state_dict: \"0.weight\", \"1.weight\", \"1.bias\", \"1.running_mean\", \"1.running_var\", \"4.0.conv1.weight\", \"4.0.bn1.weight\", \"4.0.bn1.bias\", \"4.0.bn1.running_mean\", \"4.0.bn1.running_var\", \"4.0.conv2.weight\", \"4.0.bn2.weight\", \"4.0.bn2.bias\", \"4.0.bn2.running_mean\", \"4.0.bn2.running_var\", \"4.0.conv3.weight\", \"4.0.bn3.weight\", \"4.0.bn3.bias\", \"4.0.bn3.running_mean\", \"4.0.bn3.running_var\", \"4.0.downsample.0.weight\", \"4.0.downsample.1.weight\", \"4.0.downsample.1.bias\", \"4.0.downsample.1.running_mean\", \"4.0.downsample.1.running_var\", \"4.1.conv1.weight\", \"4.1.bn1.weight\", \"4.1.bn1.bias\", \"4.1.bn1.running_mean\", \"4.1.bn1.running_var\", \"4.1.conv2.weight\", \"4.1.bn2.weight\", \"4.1.bn2.bias\", \"4.1.bn2.running_mean\", \"4.1.bn2.running_var\", \"4.1.conv3.weight\", \"4.1.bn3.weight\", \"4.1.bn3.bias\", \"4.1.bn3.running_mean\", \"4.1.bn3.running_var\", \"4.2.conv1.weight\", \"4.2.bn1.weight\", \"4.2.bn1.bias\", \"4.2.bn1.running_mean\", \"4.2.bn1.running_var\", \"4.2.conv2.weight\", \"4.2.bn2.weight\", \"4.2.bn2.bias\", \"4.2.bn2.running_mean\", \"4.2.bn2.running_var\", \"4.2.conv3.weight\", \"4.2.bn3.weight\", \"4.2.bn3.bias\", \"4.2.bn3.running_mean\", \"4.2.bn3.running_var\", \"5.0.conv1.weight\", \"5.0.bn1.weight\", \"5.0.bn1.bias\", \"5.0.bn1.running_mean\", \"5.0.bn1.running_var\", \"5.0.conv2.weight\", \"5.0.bn2.weight\", \"5.0.bn2.bias\", \"5.0.bn2.running_mean\", \"5.0.bn2.running_var\", \"5.0.conv3.weight\", \"5.0.bn3.weight\", \"5.0.bn3.bias\", \"5.0.bn3.running_mean\", \"5.0.bn3.running_var\", \"5.0.downsample.0.weight\", \"5.0.downsample.1.weight\", \"5.0.downsample.1.bias\", \"5.0.downsample.1.running_mean\", \"5.0.downsample.1.running_var\", \"5.1.conv1.weight\", \"5.1.bn1.weight\", \"5.1.bn1.bias\", \"5.1.bn1.running_mean\", \"5.1.bn1.running_var\", \"5.1.conv2.weight\", \"5.1.bn2.weight\", \"5.1.bn2.bias\", \"5.1.bn2.running_mean\", \"5.1.bn2.running_var\", \"5.1.conv3.weight\", \"5.1.bn3.weight\", \"5.1.bn3.bias\", \"5.1.bn3.running_mean\", \"5.1.bn3.running_var\", \"5.2.conv1.weight\", \"5.2.bn1.weight\", \"5.2.bn1.bias\", \"5.2.bn1.running_mean\", \"5.2.bn1.running_var\", \"5.2.conv2.weight\", \"5.2.bn2.weight\", \"5.2.bn2.bias\", \"5.2.bn2.running_mean\", \"5.2.bn2.running_var\", \"5.2.conv3.weight\", \"5.2.bn3.weight\", \"5.2.bn3.bias\", \"5.2.bn3.running_mean\", \"5.2.bn3.running_var\", \"5.3.conv1.weight\", \"5.3.bn1.weight\", \"5.3.bn1.bias\", \"5.3.bn1.running_mean\", \"5.3.bn1.running_var\", \"5.3.conv2.weight\", \"5.3.bn2.weight\", \"5.3.bn2.bias\", \"5.3.bn2.running_mean\", \"5.3.bn2.running_var\", \"5.3.conv3.weight\", \"5.3.bn3.weight\", \"5.3.bn3.bias\", \"5.3.bn3.running_mean\", \"5.3.bn3.running_var\", \"6.0.conv1.weight\", \"6.0.bn1.weight\", \"6.0.bn1.bias\", \"6.0.bn1.running_mean\", \"6.0.bn1.running_var\", \"6.0.conv2.weight\", \"6.0.bn2.weight\", \"6.0.bn2.bias\", \"6.0.bn2.running_mean\", \"6.0.bn2.running_var\", \"6.0.conv3.weight\", \"6.0.bn3.weight\", \"6.0.bn3.bias\", \"6.0.bn3.running_mean\", \"6.0.bn3.running_var\", \"6.0.downsample.0.weight\", \"6.0.downsample.1.weight\", \"6.0.downsample.1.bias\", \"6.0.downsample.1.running_mean\", \"6.0.downsample.1.running_var\", \"6.1.conv1.weight\", \"6.1.bn1.weight\", \"6.1.bn1.bias\", \"6.1.bn1.running_mean\", \"6.1.bn1.running_var\", \"6.1.conv2.weight\", \"6.1.bn2.weight\", \"6.1.bn2.bias\", \"6.1.bn2.running_mean\", \"6.1.bn2.running_var\", \"6.1.conv3.weight\", \"6.1.bn3.weight\", \"6.1.bn3.bias\", \"6.1.bn3.running_mean\", \"6.1.bn3.running_var\", \"6.2.conv1.weight\", \"6.2.bn1.weight\", \"6.2.bn1.bias\", \"6.2.bn1.running_mean\", \"6.2.bn1.running_var\", \"6.2.conv2.weight\", \"6.2.bn2.weight\", \"6.2.bn2.bias\", \"6.2.bn2.running_mean\", \"6.2.bn2.running_var\", \"6.2.conv3.weight\", \"6.2.bn3.weight\", \"6.2.bn3.bias\", \"6.2.bn3.running_mean\", \"6.2.bn3.running_var\", \"6.3.conv1.weight\", \"6.3.bn1.weight\", \"6.3.bn1.bias\", \"6.3.bn1.running_mean\", \"6.3.bn1.running_var\", \"6.3.conv2.weight\", \"6.3.bn2.weight\", \"6.3.bn2.bias\", \"6.3.bn2.running_mean\", \"6.3.bn2.running_var\", \"6.3.conv3.weight\", \"6.3.bn3.weight\", \"6.3.bn3.bias\", \"6.3.bn3.running_mean\", \"6.3.bn3.running_var\", \"6.4.conv1.weight\", \"6.4.bn1.weight\", \"6.4.bn1.bias\", \"6.4.bn1.running_mean\", \"6.4.bn1.running_var\", \"6.4.conv2.weight\", \"6.4.bn2.weight\", \"6.4.bn2.bias\", \"6.4.bn2.running_mean\", \"6.4.bn2.running_var\", \"6.4.conv3.weight\", \"6.4.bn3.weight\", \"6.4.bn3.bias\", \"6.4.bn3.running_mean\", \"6.4.bn3.running_var\", \"6.5.conv1.weight\", \"6.5.bn1.weight\", \"6.5.bn1.bias\", \"6.5.bn1.running_mean\", \"6.5.bn1.running_var\", \"6.5.conv2.weight\", \"6.5.bn2.weight\", \"6.5.bn2.bias\", \"6.5.bn2.running_mean\", \"6.5.bn2.running_var\", \"6.5.conv3.weight\", \"6.5.bn3.weight\", \"6.5.bn3.bias\", \"6.5.bn3.running_mean\", \"6.5.bn3.running_var\", \"7.0.conv1.weight\", \"7.0.bn1.weight\", \"7.0.bn1.bias\", \"7.0.bn1.running_mean\", \"7.0.bn1.running_var\", \"7.0.conv2.weight\", \"7.0.bn2.weight\", \"7.0.bn2.bias\", \"7.0.bn2.running_mean\", \"7.0.bn2.running_var\", \"7.0.conv3.weight\", \"7.0.bn3.weight\", \"7.0.bn3.bias\", \"7.0.bn3.running_mean\", \"7.0.bn3.running_var\", \"7.0.downsample.0.weight\", \"7.0.downsample.1.weight\", \"7.0.downsample.1.bias\", \"7.0.downsample.1.running_mean\", \"7.0.downsample.1.running_var\", \"7.1.conv1.weight\", \"7.1.bn1.weight\", \"7.1.bn1.bias\", \"7.1.bn1.running_mean\", \"7.1.bn1.running_var\", \"7.1.conv2.weight\", \"7.1.bn2.weight\", \"7.1.bn2.bias\", \"7.1.bn2.running_mean\", \"7.1.bn2.running_var\", \"7.1.conv3.weight\", \"7.1.bn3.weight\", \"7.1.bn3.bias\", \"7.1.bn3.running_mean\", \"7.1.bn3.running_var\", \"7.2.conv1.weight\", \"7.2.bn1.weight\", \"7.2.bn1.bias\", \"7.2.bn1.running_mean\", \"7.2.bn1.running_var\", \"7.2.conv2.weight\", \"7.2.bn2.weight\", \"7.2.bn2.bias\", \"7.2.bn2.running_mean\", \"7.2.bn2.running_var\", \"7.2.conv3.weight\", \"7.2.bn3.weight\", \"7.2.bn3.bias\", \"7.2.bn3.running_mean\", \"7.2.bn3.running_var\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"arch\", \"state_dict\", \"optimizer\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../pyDort/representation/image_models/chkpts/checkpoint_0100.pth.tar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/clort/lib/python3.10/site-packages/torch/nn/modules/module.py:1618\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1613\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1614\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1618\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1619\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Sequential:\n\tMissing key(s) in state_dict: \"0.weight\", \"1.weight\", \"1.bias\", \"1.running_mean\", \"1.running_var\", \"4.0.conv1.weight\", \"4.0.bn1.weight\", \"4.0.bn1.bias\", \"4.0.bn1.running_mean\", \"4.0.bn1.running_var\", \"4.0.conv2.weight\", \"4.0.bn2.weight\", \"4.0.bn2.bias\", \"4.0.bn2.running_mean\", \"4.0.bn2.running_var\", \"4.0.conv3.weight\", \"4.0.bn3.weight\", \"4.0.bn3.bias\", \"4.0.bn3.running_mean\", \"4.0.bn3.running_var\", \"4.0.downsample.0.weight\", \"4.0.downsample.1.weight\", \"4.0.downsample.1.bias\", \"4.0.downsample.1.running_mean\", \"4.0.downsample.1.running_var\", \"4.1.conv1.weight\", \"4.1.bn1.weight\", \"4.1.bn1.bias\", \"4.1.bn1.running_mean\", \"4.1.bn1.running_var\", \"4.1.conv2.weight\", \"4.1.bn2.weight\", \"4.1.bn2.bias\", \"4.1.bn2.running_mean\", \"4.1.bn2.running_var\", \"4.1.conv3.weight\", \"4.1.bn3.weight\", \"4.1.bn3.bias\", \"4.1.bn3.running_mean\", \"4.1.bn3.running_var\", \"4.2.conv1.weight\", \"4.2.bn1.weight\", \"4.2.bn1.bias\", \"4.2.bn1.running_mean\", \"4.2.bn1.running_var\", \"4.2.conv2.weight\", \"4.2.bn2.weight\", \"4.2.bn2.bias\", \"4.2.bn2.running_mean\", \"4.2.bn2.running_var\", \"4.2.conv3.weight\", \"4.2.bn3.weight\", \"4.2.bn3.bias\", \"4.2.bn3.running_mean\", \"4.2.bn3.running_var\", \"5.0.conv1.weight\", \"5.0.bn1.weight\", \"5.0.bn1.bias\", \"5.0.bn1.running_mean\", \"5.0.bn1.running_var\", \"5.0.conv2.weight\", \"5.0.bn2.weight\", \"5.0.bn2.bias\", \"5.0.bn2.running_mean\", \"5.0.bn2.running_var\", \"5.0.conv3.weight\", \"5.0.bn3.weight\", \"5.0.bn3.bias\", \"5.0.bn3.running_mean\", \"5.0.bn3.running_var\", \"5.0.downsample.0.weight\", \"5.0.downsample.1.weight\", \"5.0.downsample.1.bias\", \"5.0.downsample.1.running_mean\", \"5.0.downsample.1.running_var\", \"5.1.conv1.weight\", \"5.1.bn1.weight\", \"5.1.bn1.bias\", \"5.1.bn1.running_mean\", \"5.1.bn1.running_var\", \"5.1.conv2.weight\", \"5.1.bn2.weight\", \"5.1.bn2.bias\", \"5.1.bn2.running_mean\", \"5.1.bn2.running_var\", \"5.1.conv3.weight\", \"5.1.bn3.weight\", \"5.1.bn3.bias\", \"5.1.bn3.running_mean\", \"5.1.bn3.running_var\", \"5.2.conv1.weight\", \"5.2.bn1.weight\", \"5.2.bn1.bias\", \"5.2.bn1.running_mean\", \"5.2.bn1.running_var\", \"5.2.conv2.weight\", \"5.2.bn2.weight\", \"5.2.bn2.bias\", \"5.2.bn2.running_mean\", \"5.2.bn2.running_var\", \"5.2.conv3.weight\", \"5.2.bn3.weight\", \"5.2.bn3.bias\", \"5.2.bn3.running_mean\", \"5.2.bn3.running_var\", \"5.3.conv1.weight\", \"5.3.bn1.weight\", \"5.3.bn1.bias\", \"5.3.bn1.running_mean\", \"5.3.bn1.running_var\", \"5.3.conv2.weight\", \"5.3.bn2.weight\", \"5.3.bn2.bias\", \"5.3.bn2.running_mean\", \"5.3.bn2.running_var\", \"5.3.conv3.weight\", \"5.3.bn3.weight\", \"5.3.bn3.bias\", \"5.3.bn3.running_mean\", \"5.3.bn3.running_var\", \"6.0.conv1.weight\", \"6.0.bn1.weight\", \"6.0.bn1.bias\", \"6.0.bn1.running_mean\", \"6.0.bn1.running_var\", \"6.0.conv2.weight\", \"6.0.bn2.weight\", \"6.0.bn2.bias\", \"6.0.bn2.running_mean\", \"6.0.bn2.running_var\", \"6.0.conv3.weight\", \"6.0.bn3.weight\", \"6.0.bn3.bias\", \"6.0.bn3.running_mean\", \"6.0.bn3.running_var\", \"6.0.downsample.0.weight\", \"6.0.downsample.1.weight\", \"6.0.downsample.1.bias\", \"6.0.downsample.1.running_mean\", \"6.0.downsample.1.running_var\", \"6.1.conv1.weight\", \"6.1.bn1.weight\", \"6.1.bn1.bias\", \"6.1.bn1.running_mean\", \"6.1.bn1.running_var\", \"6.1.conv2.weight\", \"6.1.bn2.weight\", \"6.1.bn2.bias\", \"6.1.bn2.running_mean\", \"6.1.bn2.running_var\", \"6.1.conv3.weight\", \"6.1.bn3.weight\", \"6.1.bn3.bias\", \"6.1.bn3.running_mean\", \"6.1.bn3.running_var\", \"6.2.conv1.weight\", \"6.2.bn1.weight\", \"6.2.bn1.bias\", \"6.2.bn1.running_mean\", \"6.2.bn1.running_var\", \"6.2.conv2.weight\", \"6.2.bn2.weight\", \"6.2.bn2.bias\", \"6.2.bn2.running_mean\", \"6.2.bn2.running_var\", \"6.2.conv3.weight\", \"6.2.bn3.weight\", \"6.2.bn3.bias\", \"6.2.bn3.running_mean\", \"6.2.bn3.running_var\", \"6.3.conv1.weight\", \"6.3.bn1.weight\", \"6.3.bn1.bias\", \"6.3.bn1.running_mean\", \"6.3.bn1.running_var\", \"6.3.conv2.weight\", \"6.3.bn2.weight\", \"6.3.bn2.bias\", \"6.3.bn2.running_mean\", \"6.3.bn2.running_var\", \"6.3.conv3.weight\", \"6.3.bn3.weight\", \"6.3.bn3.bias\", \"6.3.bn3.running_mean\", \"6.3.bn3.running_var\", \"6.4.conv1.weight\", \"6.4.bn1.weight\", \"6.4.bn1.bias\", \"6.4.bn1.running_mean\", \"6.4.bn1.running_var\", \"6.4.conv2.weight\", \"6.4.bn2.weight\", \"6.4.bn2.bias\", \"6.4.bn2.running_mean\", \"6.4.bn2.running_var\", \"6.4.conv3.weight\", \"6.4.bn3.weight\", \"6.4.bn3.bias\", \"6.4.bn3.running_mean\", \"6.4.bn3.running_var\", \"6.5.conv1.weight\", \"6.5.bn1.weight\", \"6.5.bn1.bias\", \"6.5.bn1.running_mean\", \"6.5.bn1.running_var\", \"6.5.conv2.weight\", \"6.5.bn2.weight\", \"6.5.bn2.bias\", \"6.5.bn2.running_mean\", \"6.5.bn2.running_var\", \"6.5.conv3.weight\", \"6.5.bn3.weight\", \"6.5.bn3.bias\", \"6.5.bn3.running_mean\", \"6.5.bn3.running_var\", \"7.0.conv1.weight\", \"7.0.bn1.weight\", \"7.0.bn1.bias\", \"7.0.bn1.running_mean\", \"7.0.bn1.running_var\", \"7.0.conv2.weight\", \"7.0.bn2.weight\", \"7.0.bn2.bias\", \"7.0.bn2.running_mean\", \"7.0.bn2.running_var\", \"7.0.conv3.weight\", \"7.0.bn3.weight\", \"7.0.bn3.bias\", \"7.0.bn3.running_mean\", \"7.0.bn3.running_var\", \"7.0.downsample.0.weight\", \"7.0.downsample.1.weight\", \"7.0.downsample.1.bias\", \"7.0.downsample.1.running_mean\", \"7.0.downsample.1.running_var\", \"7.1.conv1.weight\", \"7.1.bn1.weight\", \"7.1.bn1.bias\", \"7.1.bn1.running_mean\", \"7.1.bn1.running_var\", \"7.1.conv2.weight\", \"7.1.bn2.weight\", \"7.1.bn2.bias\", \"7.1.bn2.running_mean\", \"7.1.bn2.running_var\", \"7.1.conv3.weight\", \"7.1.bn3.weight\", \"7.1.bn3.bias\", \"7.1.bn3.running_mean\", \"7.1.bn3.running_var\", \"7.2.conv1.weight\", \"7.2.bn1.weight\", \"7.2.bn1.bias\", \"7.2.bn1.running_mean\", \"7.2.bn1.running_var\", \"7.2.conv2.weight\", \"7.2.bn2.weight\", \"7.2.bn2.bias\", \"7.2.bn2.running_mean\", \"7.2.bn2.running_var\", \"7.2.conv3.weight\", \"7.2.bn3.weight\", \"7.2.bn3.bias\", \"7.2.bn3.running_mean\", \"7.2.bn3.running_var\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"arch\", \"state_dict\", \"optimizer\". "
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../pyDort/representation/image_models/chkpts/checkpoint_0100.pth.tar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83d862e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDort.representation.image_models.contrastive import ResNetSimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61b09ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "model = ResNetSimCLR(\"resnet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06f07451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetSimCLR(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0f70b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.load(\"../pyDort/representation/image_models/chkpts/resnet18_cifar10_cl.tar\", map_location=\"cuda:0\")[\"state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b6e1cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357e217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
